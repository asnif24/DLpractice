{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "x_train = mnist.train.images\n",
    "y_train = mnist.train.labels\n",
    "x_test = mnist.test.images\n",
    "y_test = mnist.test.labels\n",
    "batch_size = 256\n",
    "g_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 2, 2, 1], padding = 'SAME')\n",
    "def deconv2d(x, W, output_shape):\n",
    "    return tf.nn.conv2d_transpose(x, W, output_shape, strides = [1, 2, 2, 1], padding = 'SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class layer:\n",
    "    def __init__(self, in_size, out_size):\n",
    "        self.W = tf.Variable(tf.random_normal([in_size, out_size], mean=0.0, stddev=0.1))\n",
    "        self.b = tf.Variable(tf.random_normal([1, out_size], mean=0.0, stddev=0.1))\n",
    "    def output(self, inputs, activation_function=None):\n",
    "        if activation_function == None:\n",
    "            return tf.matmul(inputs, self.W) + self.b\n",
    "        else :\n",
    "            return activation_function(tf.matmul(inputs, self.W) + self.b)\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.random_normal(shape, mean=0.0, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.random_normal(shape, mean=0.0, stddev=0.1)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_e = layer(4*4*64, g_dim)\n",
    "layer_d = layer(g_dim, 4*4*64)\n",
    "\n",
    "encoder_var = {\n",
    "    \"W_e_conv1\" : weight_variable([3,3, 1,16]),\n",
    "    \"W_e_conv2\" : weight_variable([3,3,16,32]),\n",
    "    \"W_e_conv3\" : weight_variable([3,3,32,64]),\n",
    "    \"b_e_conv1\" : bias_variable([16]),   \n",
    "    \"b_e_conv2\" : bias_variable([32]),\n",
    "    \"b_e_conv3\" : bias_variable([64])\n",
    "}\n",
    "\n",
    "decoder_var = {\n",
    "    \"W_d_conv1\" : weight_variable([3,3,32,64]),\n",
    "    \"W_d_conv2\" : weight_variable([3,3,16,32]),\n",
    "    \"W_d_conv3\" : weight_variable([3,3, 1,16]),\n",
    "    \"b_d_conv1\" : bias_variable([32]),\n",
    "    \"b_d_conv2\" : bias_variable([16]),\n",
    "    \"b_d_conv3\" : bias_variable([1])\n",
    "}\n",
    "\n",
    "generator_var = {\n",
    "    \"W_d_conv1\" : weight_variable([3,3,32,64]),\n",
    "    \"W_d_conv2\" : weight_variable([3,3,16,32]),\n",
    "    \"W_d_conv3\" : weight_variable([3,3, 1,16]),\n",
    "    \"b_d_conv1\" : bias_variable([32]),\n",
    "    \"b_d_conv2\" : bias_variable([16]),\n",
    "    \"b_d_conv3\" : bias_variable([1])\n",
    "}\n",
    "\n",
    "var_d = [encoder_var[e] for e in encoder_var]+[decoder_var[d] for d in decoder_var]\n",
    "var_g = [generator_var[g] for g in generator_var]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(x):\n",
    "    x_origin = tf.reshape(x, [-1,28,28,1])      #28x28x1\n",
    "    h_e_conv1 = tf.nn.relu(tf.add(conv2d(x_origin, encoder_var[\"W_e_conv1\"]), encoder_var[\"b_e_conv1\"]))     #14x14x16\n",
    "    h_e_conv2 = tf.nn.relu(tf.add(conv2d(h_e_conv1, encoder_var[\"W_e_conv2\"]), encoder_var[\"b_e_conv2\"]))    #7x7x32\n",
    "    h_e_conv3 = tf.nn.relu(tf.add(conv2d(h_e_conv2, encoder_var[\"W_e_conv3\"]), encoder_var[\"b_e_conv3\"]))    #4x4x64\n",
    "    h_e_conv3_reshape = tf.reshape(h_e_conv3, [-1,4*4*64])\n",
    "    h_e_layer = layer_e.output(h_e_conv3_reshape, tf.nn.relu)\n",
    "#     h_e_layer = layer_e.output(h_e_conv3_reshape, tf.nn.sigmoid)\n",
    "    return h_e_layer\n",
    "    \n",
    "def decoder(z):\n",
    "    h_d_layer = layer_d.output(z, tf.nn.relu)\n",
    "#     h_d_layer = layer_d.output(z, tf.nn.sigmoid)\n",
    "    h_d_layer_reshape = tf.reshape(h_d_layer, [-1,4,4,64])\n",
    "    \n",
    "    output_shape_d_conv1 = tf.stack([tf.shape(z)[0], 7, 7, 32])\n",
    "    h_d_conv1 = tf.nn.relu(deconv2d(h_d_layer_reshape, decoder_var[\"W_d_conv1\"], output_shape_d_conv1)+decoder_var[\"b_d_conv1\"])\n",
    "\n",
    "    output_shape_d_conv1 = tf.stack([tf.shape(z)[0], 14, 14, 16])\n",
    "    h_d_conv2 = tf.nn.relu(deconv2d(h_d_conv1, decoder_var[\"W_d_conv2\"], output_shape_d_conv1)+decoder_var[\"b_d_conv2\"])\n",
    "\n",
    "    output_shape_d_conv2 = tf.stack([tf.shape(z)[0], 28, 28, 1])\n",
    "    h_d_conv3 = tf.nn.relu(deconv2d(h_d_conv2, decoder_var[\"W_d_conv3\"], output_shape_d_conv2)+decoder_var[\"b_d_conv3\"])\n",
    "    return h_d_conv3\n",
    "\n",
    "def generator(z):\n",
    "    h_d_layer = layer_d.output(z, tf.nn.relu)\n",
    "#     h_d_layer = layer_d.output(z, tf.nn.sigmoid)\n",
    "    h_d_layer_reshape = tf.reshape(h_d_layer, [-1,4,4,64])\n",
    "    \n",
    "    output_shape_d_conv1 = tf.stack([tf.shape(z)[0], 7, 7, 32])\n",
    "    h_d_conv1 = tf.nn.relu(deconv2d(h_d_layer_reshape, generator_var[\"W_d_conv1\"], output_shape_d_conv1)+generator_var[\"b_d_conv1\"])\n",
    "\n",
    "    output_shape_d_conv1 = tf.stack([tf.shape(z)[0], 14, 14, 16])\n",
    "    h_d_conv2 = tf.nn.relu(deconv2d(h_d_conv1, generator_var[\"W_d_conv2\"], output_shape_d_conv1)+generator_var[\"b_d_conv2\"])\n",
    "\n",
    "    output_shape_d_conv2 = tf.stack([tf.shape(z)[0], 28, 28, 1])\n",
    "    h_d_conv3 = tf.nn.relu(deconv2d(h_d_conv2, generator_var[\"W_d_conv3\"], output_shape_d_conv2)+generator_var[\"b_d_conv3\"])\n",
    "    return h_d_conv3\n",
    "\n",
    "def discriminator(x):\n",
    "    return decoder(encoder(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_Z(m, n):\n",
    "    return np.random.uniform(-1., 1., size=[m, n])\n",
    "\n",
    "def loss(x):\n",
    "#     return tf.reduce_mean(tf.pow(tf.reshape(x, [-1, 784]) - tf.reshape(discriminator(x), [-1, 784]), 2))\n",
    "    return tf.reduce_mean(tf.abs(tf.reshape(x, [-1, 784]) - tf.reshape(discriminator(x), [-1, 784])))\n",
    "#     return tf.pow(tf.reshape(x, [-1, 784]) - tf.reshape(discriminator(x), [-1, 784]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_d = tf.placeholder(tf.float32, shape = [None, 784])\n",
    "x_g = tf.placeholder(tf.float32, shape = [None, g_dim])\n",
    "\n",
    "gamma = 0.5\n",
    "# k_t = 0.\n",
    "k_t = tf.Variable(0.0, tf.float32)\n",
    "\n",
    "# d_loss = loss(x_d)-k_t*loss(generator(x_g))\n",
    "# d_loss = loss(x_d)\n",
    "d_loss = tf.reduce_mean(loss(x_d)-k_t*loss(generator(x_g)))\n",
    "# g_loss = loss(generator(x_g))\n",
    "g_loss = tf.reduce_mean(loss(generator(x_g)))\n",
    "\n",
    "g_sample = generator(x_g)\n",
    "\n",
    "M_global = loss(x_d) + tf.abs(gamma*loss(x_d) - loss(generator(x_g)))\n",
    "\n",
    "d_optimizer = tf.train.AdamOptimizer(0.00001).minimize(d_loss, var_list= var_d)\n",
    "g_optimizer = tf.train.AdamOptimizer(0.00001).minimize(g_loss, var_list= var_g)\n",
    "\n",
    "# balancer = gamma*loss(x_d) - loss(generator(x_g))\n",
    "balancer = tf.reduce_mean(gamma*loss(x_d) - loss(generator(x_g)))\n",
    "update_k = k_t.assign(k_t + 0.001 * balancer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0  d-loss: 0.134451  g-loss: 0.0344266 k_t: 3.27936e-05 M_global: 0.167252\n",
      "step: 1000  d-loss: 0.127866  g-loss: 0.00156098 k_t: 0.0579128 M_global: 0.190374\n",
      "step: 2000  d-loss: 0.128244  g-loss: 0.0111386 k_t: 0.118697 M_global: 0.183211\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(10001):\n",
    "    batch_x = mnist.train.next_batch(batch_size)[0]\n",
    "    z_D = sample_Z(batch_size, g_dim)\n",
    "    sess.run([d_optimizer, g_optimizer], feed_dict={x_d: batch_x, x_g: z_D})\n",
    "    z_G = sample_Z(batch_size, g_dim)\n",
    "    sess.run(g_optimizer, feed_dict={x_g: z_G})\n",
    "#     k_t = np.maximum(np.minimum(1., k_t + 0.001*(sess.run(balancer, feed_dict={x_d: batch_x, x_g: z_G}))), 0.)\n",
    "    sess.run(update_k, feed_dict={x_d: batch_x, x_g: z_G})\n",
    "    if step%1000==0:\n",
    "        d_loss_train, g_loss_train, M_global_train = sess.run([d_loss, g_loss, M_global], feed_dict=\n",
    "                            {x_d: batch_x, x_g: sample_Z(batch_size, g_dim)})\n",
    "#         print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_t,\"M_global:\", M_global_train\n",
    "        print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', sess.run(k_t),\"M_global:\", M_global_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz = sample_Z(batch_size, g_dim)\n",
    "# gg = sess.run(g_sample, feed_dict = {x_g: zz})\n",
    "gg = sess.run(discriminator(g_sample), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(x_d), feed_dict = {x_d: x_train})\n",
    "gg_pic = np.array([np.reshape(m,(28,28)) for m in gg])\n",
    "fig, ax = plt.subplots(nrows=3, ncols=3)\n",
    "for i,row in enumerate(ax):\n",
    "    for j,col in enumerate(row):\n",
    "        ax[i][j].imshow(gg_pic[i*3+j], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0  d-loss: 0.0832852  g-loss: 0.0307827 k_t: 0.00366534 M_global: 0.0943143\n",
      "step: 1000  d-loss: 0.0833875  g-loss: 0.0495293 k_t: 0.00614094 M_global: 0.0913751\n",
      "step: 2000  d-loss: 0.0805388  g-loss: 0.0321505 k_t: 0.00899321 M_global: 0.0890914\n",
      "step: 3000  d-loss: 0.0814881  g-loss: 0.0347336 k_t: 0.0109764 M_global: 0.0880705\n",
      "step: 4000  d-loss: 0.0789851  g-loss: 0.0512237 k_t: 0.0101904 M_global: 0.0909773\n",
      "step: 5000  d-loss: 0.0787875  g-loss: 0.0331193 k_t: 0.00602325 M_global: 0.0853612\n",
      "step: 6000  d-loss: 0.0780999  g-loss: 0.0405743 k_t: 0.000949099 M_global: 0.0796435\n",
      "step: 7000  d-loss: 0.0785003  g-loss: 0.0382582 k_t: 0.000936719 M_global: 0.0795461\n",
      "step: 8000  d-loss: 0.0770937  g-loss: 0.0395787 k_t: 0.000653723 M_global: 0.0781385\n",
      "step: 9000  d-loss: 0.078134  g-loss: 0.0364919 k_t: 0.00409848 M_global: 0.0809334\n",
      "step: 10000  d-loss: 0.0798303  g-loss: 0.0330525 k_t: 0.00870075 M_global: 0.0871243\n"
     ]
    }
   ],
   "source": [
    "for step in range(10001):\n",
    "    batch_x = mnist.train.next_batch(batch_size)[0]\n",
    "    z_D = sample_Z(batch_size, g_dim)\n",
    "    sess.run([d_optimizer, g_optimizer], feed_dict={x_d: batch_x, x_g: z_D})\n",
    "    z_G = sample_Z(batch_size, g_dim)\n",
    "    sess.run(g_optimizer, feed_dict={x_g: z_G})\n",
    "#     k_t = np.maximum(np.minimum(1., k_t + 0.001*(sess.run(balancer, feed_dict={x_d: batch_x, x_g: z_G}))), 0.)\n",
    "    sess.run(update_k, feed_dict={x_d: batch_x, x_g: z_G})\n",
    "    if step%1000==0:\n",
    "        d_loss_train, g_loss_train, k_tt, M_global_train = sess.run([d_loss, g_loss, k_t, M_global], feed_dict=\n",
    "                            {x_d: batch_x, x_g: sample_Z(batch_size, g_dim)})\n",
    "#         print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_t,\"M_global:\", M_global_train\n",
    "        print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_tt,\"M_global:\", M_global_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAD8CAYAAADOg5fGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJIL/A+sEm9iua3MWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1b5a6bb650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gg = sess.run(g_sample, feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(g_sample), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(decoder(x_g), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(x_d), feed_dict = {x_d: x_train})\n",
    "gg_pic = np.array([np.reshape(m,(28,28)) for m in gg])\n",
    "fig, ax = plt.subplots(nrows=3, ncols=3)\n",
    "for i,row in enumerate(ax):\n",
    "    for j,col in enumerate(row):\n",
    "        ax[i][j].imshow(gg_pic[i*3+j], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0  d-loss: 0.0792711  g-loss: 0.0328262 k_t: 0.00870769 M_global: 0.0865092\n",
      "step: 1000  d-loss: 0.0800405  g-loss: 0.0428469 k_t: 0.0134532 M_global: 0.0831554\n",
      "step: 2000  d-loss: 0.0816002  g-loss: 0.0405542 k_t: 0.0085856 M_global: 0.0823683\n",
      "step: 3000  d-loss: 0.075896  g-loss: 0.0306594 k_t: 0.0184133 M_global: 0.0840314\n",
      "step: 4000  d-loss: 0.0757164  g-loss: 0.0207639 k_t: 0.0233376 M_global: 0.0935376\n",
      "step: 5000  d-loss: 0.0736848  g-loss: 0.0363859 k_t: 0.0311481 M_global: 0.0758412\n",
      "step: 6000  d-loss: 0.0747294  g-loss: 0.0312377 k_t: 0.0326966 M_global: 0.0823885\n",
      "step: 7000  d-loss: 0.0730856  g-loss: 0.0484091 k_t: 0.0376767 M_global: 0.0858638\n",
      "step: 8000  d-loss: 0.0730846  g-loss: 0.0239913 k_t: 0.0378701 M_global: 0.0869985\n",
      "step: 9000  d-loss: 0.0733152  g-loss: 0.0323484 k_t: 0.0380616 M_global: 0.0794712\n",
      "step: 10000  d-loss: 0.0709913  g-loss: 0.0201262 k_t: 0.0367253 M_global: 0.0874694\n"
     ]
    }
   ],
   "source": [
    "for step in range(10001):\n",
    "    batch_x = mnist.train.next_batch(batch_size)[0]\n",
    "    z_D = sample_Z(batch_size, g_dim)\n",
    "    sess.run([d_optimizer, g_optimizer], feed_dict={x_d: batch_x, x_g: z_D})\n",
    "    z_G = sample_Z(batch_size, g_dim)\n",
    "    sess.run(g_optimizer, feed_dict={x_g: z_G})\n",
    "#     k_t = np.maximum(np.minimum(1., k_t + 0.001*(sess.run(balancer, feed_dict={x_d: batch_x, x_g: z_G}))), 0.)\n",
    "    sess.run(update_k, feed_dict={x_d: batch_x, x_g: z_G})\n",
    "    if step%1000==0:\n",
    "        d_loss_train, g_loss_train, k_tt, M_global_train = sess.run([d_loss, g_loss, k_t, M_global], feed_dict=\n",
    "                            {x_d: batch_x, x_g: sample_Z(batch_size, g_dim)})\n",
    "#         print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_t,\"M_global:\", M_global_train\n",
    "        print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_tt,\"M_global:\", M_global_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAD8CAYAAADOg5fGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1b5a5c5990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gg = sess.run(g_sample, feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(g_sample), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(decoder(x_g), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(x_d), feed_dict = {x_d: x_train})\n",
    "gg_pic = np.array([np.reshape(m,(28,28)) for m in gg])\n",
    "fig, ax = plt.subplots(nrows=3, ncols=3)\n",
    "for i,row in enumerate(ax):\n",
    "    for j,col in enumerate(row):\n",
    "        ax[i][j].imshow(gg_pic[i*3+j], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0  d-loss: 0.0727567  g-loss: 0.0205304 k_t: 0.0367415 M_global: 0.0897361\n",
      "step: 1000  d-loss: 0.0733368  g-loss: 0.0247697 k_t: 0.0355511 M_global: 0.0865564\n",
      "step: 2000  d-loss: 0.0729073  g-loss: 0.0587642 k_t: 0.0403159 M_global: 0.0964025\n",
      "step: 3000  d-loss: 0.0698976  g-loss: 0.0535406 k_t: 0.0324562 M_global: 0.0893583\n",
      "step: 4000  d-loss: 0.0697217  g-loss: 0.0396629 k_t: 0.0218598 M_global: 0.0749572\n",
      "step: 5000  d-loss: 0.0711224  g-loss: 0.0209014 k_t: 0.0269593 M_global: 0.0866274\n",
      "step: 6000  d-loss: 0.0698783  g-loss: 0.0209957 k_t: 0.0194017 M_global: 0.0844327\n",
      "step: 7000  d-loss: 0.0682822  g-loss: 0.0440241 k_t: 0.0244078 M_global: 0.0787025\n",
      "step: 8000  d-loss: 0.0742944  g-loss: 0.0403934 k_t: 0.0247117 M_global: 0.0780397\n",
      "step: 9000  d-loss: 0.0694526  g-loss: 0.0208374 k_t: 0.0178228 M_global: 0.0838985\n",
      "step: 10000  d-loss: 0.0714611  g-loss: 0.0301872 k_t: 0.0222376 M_global: 0.0780114\n",
      "step: 11000  d-loss: 0.0706307  g-loss: 0.0235635 k_t: 0.0171313 M_global: 0.0829881\n",
      "step: 12000  d-loss: 0.0690893  g-loss: 0.0257388 k_t: 0.0191757 M_global: 0.0786355\n",
      "step: 13000  d-loss: 0.0682234  g-loss: 0.0176957 k_t: 0.0291005 M_global: 0.0854118\n",
      "step: 14000  d-loss: 0.0678928  g-loss: 0.0400194 k_t: 0.0304142 M_global: 0.0745744\n",
      "step: 15000  d-loss: 0.071055  g-loss: 0.0492389 k_t: 0.0267787 M_global: 0.0854257\n",
      "step: 16000  d-loss: 0.0705096  g-loss: 0.0347679 k_t: 0.0165666 M_global: 0.0718604\n",
      "step: 17000  d-loss: 0.0709  g-loss: 0.0308603 k_t: 0.016945 M_global: 0.0762741\n",
      "step: 18000  d-loss: 0.0681653  g-loss: 0.035404 k_t: 0.0133198 M_global: 0.0697224\n",
      "step: 19000  d-loss: 0.0674891  g-loss: 0.0251765 k_t: 0.0191766 M_global: 0.0767814\n",
      "step: 20000  d-loss: 0.0699632  g-loss: 0.0389828 k_t: 0.0247127 M_global: 0.0744461\n",
      "step: 21000  d-loss: 0.0670244  g-loss: 0.0226875 k_t: 0.0259839 M_global: 0.0787333\n",
      "step: 22000  d-loss: 0.0685158  g-loss: 0.0384642 k_t: 0.0257104 M_global: 0.0732165\n",
      "step: 23000  d-loss: 0.0687084  g-loss: 0.0547295 k_t: 0.0249087 M_global: 0.0897653\n",
      "step: 24000  d-loss: 0.0672675  g-loss: 0.0500718 k_t: 0.0252943 M_global: 0.0843388\n",
      "step: 25000  d-loss: 0.0660221  g-loss: 0.0479086 k_t: 0.0255935 M_global: 0.0815327\n",
      "step: 26000  d-loss: 0.0686467  g-loss: 0.032754 k_t: 0.0236964 M_global: 0.0713802\n",
      "step: 27000  d-loss: 0.0679525  g-loss: 0.0541341 k_t: 0.0219259 M_global: 0.0887038\n",
      "step: 28000  d-loss: 0.0663456  g-loss: 0.03391 k_t: 0.0167992 M_global: 0.0673676\n",
      "step: 29000  d-loss: 0.0671351  g-loss: 0.0298019 k_t: 0.0182336 M_global: 0.0717158\n",
      "step: 30000  d-loss: 0.0639854  g-loss: 0.0341466 k_t: 0.0202589 M_global: 0.0664852\n",
      "step: 31000  d-loss: 0.0641756  g-loss: 0.0462905 k_t: 0.0251445 M_global: 0.0789603\n",
      "step: 32000  d-loss: 0.0650601  g-loss: 0.0410037 k_t: 0.0175253 M_global: 0.0738931\n",
      "step: 33000  d-loss: 0.0635023  g-loss: 0.0139709 k_t: 0.0194252 M_global: 0.0816896\n",
      "step: 34000  d-loss: 0.0597561  g-loss: 0.0349172 k_t: 0.0213513 M_global: 0.0651681\n",
      "step: 35000  d-loss: 0.0625136  g-loss: 0.0103396 k_t: 0.0186668 M_global: 0.0837203\n",
      "step: 36000  d-loss: 0.0589049  g-loss: 0.0491018 k_t: 0.022569 M_global: 0.0791083\n",
      "step: 37000  d-loss: 0.0598142  g-loss: 0.0304149 k_t: 0.0221727 M_global: 0.0606592\n",
      "step: 38000  d-loss: 0.0600635  g-loss: 0.0278676 k_t: 0.0237425 M_global: 0.0632201\n",
      "step: 39000  d-loss: 0.0609779  g-loss: 0.0532327 k_t: 0.0217179 M_global: 0.0842997\n",
      "step: 40000  d-loss: 0.0579753  g-loss: 0.0480569 k_t: 0.0164701 M_global: 0.0774403\n",
      "step: 41000  d-loss: 0.0610437  g-loss: 0.0304719 k_t: 0.0102604 M_global: 0.0615626\n",
      "step: 42000  d-loss: 0.0587687  g-loss: 0.0339245 k_t: 0.00659968 M_global: 0.0634207\n",
      "step: 43000  d-loss: 0.060922  g-loss: 0.0403571 k_t: 0.00279074 M_global: 0.0708745\n",
      "step: 44000  d-loss: 0.0591808  g-loss: 0.0266689 k_t: 0.00582293 M_global: 0.0623352\n",
      "step: 45000  d-loss: 0.0568778  g-loss: 0.0272223 k_t: 0.00451703 M_global: 0.0582788\n",
      "step: 46000  d-loss: 0.0605303  g-loss: 0.0439644 k_t: 0.0050743 M_global: 0.0743411\n",
      "step: 47000  d-loss: 0.0593673  g-loss: 0.0206122 k_t: 0.00867666 M_global: 0.068707\n",
      "step: 48000  d-loss: 0.0602442  g-loss: 0.034946 k_t: 0.010027 M_global: 0.0652432\n",
      "step: 49000  d-loss: 0.0576222  g-loss: 0.0285793 k_t: 0.00596466 M_global: 0.0581098\n",
      "step: 50000  d-loss: 0.059682  g-loss: 0.0321772 k_t: 0.0056332 M_global: 0.0621088\n"
     ]
    }
   ],
   "source": [
    "for step in range(50001):\n",
    "    batch_x = mnist.train.next_batch(batch_size)[0]\n",
    "    z_D = sample_Z(batch_size, g_dim)\n",
    "    sess.run([d_optimizer, g_optimizer], feed_dict={x_d: batch_x, x_g: z_D})\n",
    "    z_G = sample_Z(batch_size, g_dim)\n",
    "    sess.run(g_optimizer, feed_dict={x_g: z_G})\n",
    "#     k_t = np.maximum(np.minimum(1., k_t + 0.001*(sess.run(balancer, feed_dict={x_d: batch_x, x_g: z_G}))), 0.)\n",
    "    sess.run(update_k, feed_dict={x_d: batch_x, x_g: z_G})\n",
    "    if step%1000==0:\n",
    "        d_loss_train, g_loss_train, k_tt, M_global_train = sess.run([d_loss, g_loss, k_t, M_global], feed_dict=\n",
    "                            {x_d: batch_x, x_g: sample_Z(batch_size, g_dim)})\n",
    "#         print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_t,\"M_global:\", M_global_train\n",
    "        print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_tt,\"M_global:\", M_global_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAD8CAYAAADOg5fGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1b5a97aa10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gg = sess.run(g_sample, feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(g_sample), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(decoder(x_g), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(x_d), feed_dict = {x_d: x_train})\n",
    "gg_pic = np.array([np.reshape(m,(28,28)) for m in gg])\n",
    "fig, ax = plt.subplots(nrows=3, ncols=3)\n",
    "for i,row in enumerate(ax):\n",
    "    for j,col in enumerate(row):\n",
    "        ax[i][j].imshow(gg_pic[i*3+j], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0  d-loss: 0.0598133  g-loss: 0.0325591 k_t: 0.00563063 M_global: 0.0625575\n",
      "step: 1000  d-loss: 0.0588897  g-loss: 0.0258945 k_t: 0.00393988 M_global: 0.0625931\n",
      "step: 2000  d-loss: 0.055478  g-loss: 0.0290811 k_t: 0.00500536 M_global: 0.0568929\n",
      "step: 3000  d-loss: 0.0568675  g-loss: 0.027297 k_t: 0.00308396 M_global: 0.0581305\n",
      "step: 4000  d-loss: 0.0574291  g-loss: 0.027749 k_t: 0.00418609 M_global: 0.058569\n",
      "step: 5000  d-loss: 0.0567243  g-loss: 0.0311495 k_t: 0.00548863 M_global: 0.0595971\n",
      "step: 6000  d-loss: 0.059643  g-loss: 0.0318521 k_t: 0.00187315 M_global: 0.0617034\n",
      "step: 7000  d-loss: 0.056206  g-loss: 0.0200681 k_t: 0.00234442 M_global: 0.0643115\n",
      "step: 8000  d-loss: 0.0579899  g-loss: 0.0260566 k_t: 0.00337662 M_global: 0.0610602\n",
      "step: 9000  d-loss: 0.0588597  g-loss: 0.0269031 k_t: 0.00347306 M_global: 0.0615265\n",
      "step: 10000  d-loss: 0.0570976  g-loss: 0.029517 k_t: 0.00473305 M_global: 0.0581357\n",
      "step: 11000  d-loss: 0.0556159  g-loss: 0.0289794 k_t: 0.00728079 M_global: 0.0568929\n",
      "step: 12000  d-loss: 0.0549563  g-loss: 0.0188381 k_t: 0.0122585 M_global: 0.0639428\n",
      "step: 13000  d-loss: 0.0573591  g-loss: 0.023295 k_t: 0.0132331 M_global: 0.0632061\n",
      "step: 14000  d-loss: 0.0532224  g-loss: 0.0308529 k_t: 0.0206 M_global: 0.0577819\n",
      "step: 15000  d-loss: 0.0530569  g-loss: 0.0126948 k_t: 0.0275081 M_global: 0.0674145\n",
      "step: 16000  d-loss: 0.0528181  g-loss: 0.0119917 k_t: 0.0274712 M_global: 0.0677296\n",
      "step: 17000  d-loss: 0.0562725  g-loss: 0.0548519 k_t: 0.0217974 M_global: 0.083586\n",
      "step: 18000  d-loss: 0.0540776  g-loss: 0.0198055 k_t: 0.0241686 M_global: 0.0620289\n",
      "step: 19000  d-loss: 0.0549876  g-loss: 0.01772 k_t: 0.0367193 M_global: 0.0657374\n",
      "step: 20000  d-loss: 0.0544313  g-loss: 0.0649036 k_t: 0.0333054 M_global: 0.0932001\n",
      "step: 21000  d-loss: 0.0523064  g-loss: 0.0141071 k_t: 0.0286821 M_global: 0.0649593\n",
      "step: 22000  d-loss: 0.0534532  g-loss: 0.0111522 k_t: 0.0306176 M_global: 0.0695399\n",
      "step: 23000  d-loss: 0.0523101  g-loss: 0.0450454 k_t: 0.0269709 M_global: 0.0718079\n",
      "step: 24000  d-loss: 0.0517063  g-loss: 0.0400523 k_t: 0.0216263 M_global: 0.0663386\n",
      "step: 25000  d-loss: 0.0509181  g-loss: 0.0349765 k_t: 0.0205589 M_global: 0.0607951\n",
      "step: 26000  d-loss: 0.0510471  g-loss: 0.0178162 k_t: 0.0274743 M_global: 0.0594886\n",
      "step: 27000  d-loss: 0.0500693  g-loss: 0.0299748 k_t: 0.0218629 M_global: 0.0553371\n",
      "step: 28000  d-loss: 0.0486534  g-loss: 0.0250812 k_t: 0.0185397 M_global: 0.0496404\n",
      "step: 29000  d-loss: 0.0506974  g-loss: 0.0298107 k_t: 0.0211936 M_global: 0.0554752\n",
      "step: 30000  d-loss: 0.0486882  g-loss: 0.0316118 k_t: 0.0153152 M_global: 0.056198\n",
      "step: 31000  d-loss: 0.0499094  g-loss: 0.0170498 k_t: 0.0201537 M_global: 0.0583296\n",
      "step: 32000  d-loss: 0.0480009  g-loss: 0.0271075 k_t: 0.0245432 M_global: 0.0514406\n",
      "step: 33000  d-loss: 0.0501855  g-loss: 0.0402213 k_t: 0.0159092 M_global: 0.065634\n",
      "step: 34000  d-loss: 0.0485475  g-loss: 0.0229358 k_t: 0.00453533 M_global: 0.0500415\n",
      "step: 35000  d-loss: 0.0492902  g-loss: 0.0255018 k_t: 0.0072489 M_global: 0.0502393\n",
      "step: 36000  d-loss: 0.0488237  g-loss: 0.0242225 k_t: 0.00764579 M_global: 0.0492908\n",
      "step: 37000  d-loss: 0.0481754  g-loss: 0.0360587 k_t: 0.00607669 M_global: 0.060256\n",
      "step: 38000  d-loss: 0.0492406  g-loss: 0.016837 k_t: 0.00638882 M_global: 0.0571853\n",
      "step: 39000  d-loss: 0.0493378  g-loss: 0.0169973 k_t: 0.00287241 M_global: 0.0570826\n",
      "step: 40000  d-loss: 0.0458606  g-loss: 0.0237191 k_t: 0.000866986 M_global: 0.0466597\n",
      "step: 41000  d-loss: 0.0441745  g-loss: 0.0152618 k_t: 0.00229932 M_global: 0.0510525\n",
      "step: 42000  d-loss: 0.0460711  g-loss: 0.0298942 k_t: 0.00354462 M_global: 0.0529828\n",
      "step: 43000  d-loss: 0.0454156  g-loss: 0.0113443 k_t: 0.00257553 M_global: 0.0568229\n",
      "step: 44000  d-loss: 0.0445402  g-loss: 0.0224151 k_t: 0.0128636 M_global: 0.0448293\n",
      "step: 45000  d-loss: 0.0448425  g-loss: 0.0089088 k_t: 0.0180034 M_global: 0.0585956\n",
      "step: 46000  d-loss: 0.0438875  g-loss: 0.0245157 k_t: 0.0207711 M_global: 0.0467141\n",
      "step: 47000  d-loss: 0.0435828  g-loss: 0.0106872 k_t: 0.033367 M_global: 0.0552219\n",
      "step: 48000  d-loss: 0.0460919  g-loss: 0.0116924 k_t: 0.0391988 M_global: 0.058133\n",
      "step: 49000  d-loss: 0.0452819  g-loss: 0.0116047 k_t: 0.0464917 M_global: 0.0571274\n",
      "step: 50000  d-loss: 0.0468789  g-loss: 0.0321443 k_t: 0.0494685 M_global: 0.0563788\n"
     ]
    }
   ],
   "source": [
    "for step in range(50001):\n",
    "    batch_x = mnist.train.next_batch(batch_size)[0]\n",
    "    z_D = sample_Z(batch_size, g_dim)\n",
    "    sess.run([d_optimizer, g_optimizer], feed_dict={x_d: batch_x, x_g: z_D})\n",
    "    z_G = sample_Z(batch_size, g_dim)\n",
    "    sess.run(g_optimizer, feed_dict={x_g: z_G})\n",
    "#     k_t = np.maximum(np.minimum(1., k_t + 0.001*(sess.run(balancer, feed_dict={x_d: batch_x, x_g: z_G}))), 0.)\n",
    "    sess.run(update_k, feed_dict={x_d: batch_x, x_g: z_G})\n",
    "    if step%1000==0:\n",
    "        d_loss_train, g_loss_train, k_tt, M_global_train = sess.run([d_loss, g_loss, k_t, M_global], feed_dict=\n",
    "                            {x_d: batch_x, x_g: sample_Z(batch_size, g_dim)})\n",
    "#         print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_t,\"M_global:\", M_global_train\n",
    "        print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_tt,\"M_global:\", M_global_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAD8CAYAAADOg5fGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEQMNokIIEYP/D0W8iu1BqAb8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1b5bc27150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gg = sess.run(g_sample, feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(g_sample), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(decoder(x_g), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(x_d), feed_dict = {x_d: x_train})\n",
    "gg_pic = np.array([np.reshape(m,(28,28)) for m in gg])\n",
    "fig, ax = plt.subplots(nrows=3, ncols=3)\n",
    "for i,row in enumerate(ax):\n",
    "    for j,col in enumerate(row):\n",
    "        ax[i][j].imshow(gg_pic[i*3+j], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0  d-loss: 0.0424335  g-loss: 0.0309044 k_t: 0.0494596 M_global: 0.0528854\n",
      "step: 1000  d-loss: 0.043901  g-loss: 0.0465764 k_t: 0.0508565 M_global: 0.0697112\n",
      "step: 2000  d-loss: 0.0431559  g-loss: 0.019188 k_t: 0.0536639 M_global: 0.0470904\n",
      "step: 3000  d-loss: 0.0443425  g-loss: 0.0420884 k_t: 0.0484422 M_global: 0.0652791\n",
      "step: 4000  d-loss: 0.0456061  g-loss: 0.0122127 k_t: 0.0498511 M_global: 0.0571097\n",
      "step: 5000  d-loss: 0.0446299  g-loss: 0.0211744 k_t: 0.0526166 M_global: 0.0474415\n",
      "step: 6000  d-loss: 0.0455291  g-loss: 0.0134985 k_t: 0.0494349 M_global: 0.055796\n",
      "step: 7000  d-loss: 0.0456932  g-loss: 0.0207122 k_t: 0.0443424 M_global: 0.0492053\n",
      "step: 8000  d-loss: 0.0449278  g-loss: 0.0137338 k_t: 0.0426304 M_global: 0.0545361\n",
      "step: 9000  d-loss: 0.0451739  g-loss: 0.0554261 k_t: 0.0349789 M_global: 0.0789824\n",
      "step: 10000  d-loss: 0.0452348  g-loss: 0.0164874 k_t: 0.0386027 M_global: 0.0523195\n",
      "step: 11000  d-loss: 0.0429715  g-loss: 0.0176165 k_t: 0.037237 M_global: 0.0478247\n",
      "step: 12000  d-loss: 0.0423409  g-loss: 0.0192975 k_t: 0.0440432 M_global: 0.0454888\n",
      "step: 13000  d-loss: 0.0435808  g-loss: 0.0172873 k_t: 0.048083 M_global: 0.0493307\n",
      "step: 14000  d-loss: 0.0438476  g-loss: 0.019745 k_t: 0.0454531 M_global: 0.0473726\n",
      "step: 15000  d-loss: 0.0453175  g-loss: 0.016229 k_t: 0.0477109 M_global: 0.0529086\n",
      "step: 16000  d-loss: 0.0457054  g-loss: 0.0250947 k_t: 0.0483689 M_global: 0.0485543\n",
      "step: 17000  d-loss: 0.0438357  g-loss: 0.0198967 k_t: 0.0403186 M_global: 0.0470602\n",
      "step: 18000  d-loss: 0.047721  g-loss: 0.0173509 k_t: 0.0451242 M_global: 0.0554051\n",
      "step: 19000  d-loss: 0.0452305  g-loss: 0.0138862 k_t: 0.0440047 M_global: 0.0548761\n",
      "step: 20000  d-loss: 0.0444097  g-loss: 0.020005 k_t: 0.0455356 M_global: 0.047976\n",
      "step: 21000  d-loss: 0.0446381  g-loss: 0.0204809 k_t: 0.0442212 M_global: 0.0478347\n",
      "step: 22000  d-loss: 0.0426983  g-loss: 0.0226165 k_t: 0.0235918 M_global: 0.0442324\n",
      "step: 23000  d-loss: 0.0431461  g-loss: 0.0141407 k_t: 0.0281877 M_global: 0.0511764\n",
      "step: 24000  d-loss: 0.0411681  g-loss: 0.0161123 k_t: 0.0330213 M_global: 0.046438\n",
      "step: 25000  d-loss: 0.0411595  g-loss: 0.0472079 k_t: 0.0336285 M_global: 0.0685814\n",
      "step: 26000  d-loss: 0.0428289  g-loss: 0.0120463 k_t: 0.0339891 M_global: 0.0528112\n",
      "step: 27000  d-loss: 0.0425097  g-loss: 0.0145792 k_t: 0.0399952 M_global: 0.05006\n",
      "step: 28000  d-loss: 0.0402981  g-loss: 0.0596228 k_t: 0.0452062 M_global: 0.0811196\n",
      "step: 29000  d-loss: 0.0407044  g-loss: 0.0184528 k_t: 0.0459332 M_global: 0.0438752\n",
      "step: 30000  d-loss: 0.0438418  g-loss: 0.0118618 k_t: 0.0483529 M_global: 0.0547613\n",
      "step: 31000  d-loss: 0.0404597  g-loss: 0.0194429 k_t: 0.0472843 M_global: 0.0426257\n",
      "step: 32000  d-loss: 0.0414402  g-loss: 0.0193677 k_t: 0.0451866 M_global: 0.0441054\n",
      "step: 33000  d-loss: 0.0390926  g-loss: 0.027564 k_t: 0.0395126 M_global: 0.0476549\n",
      "step: 34000  d-loss: 0.0401917  g-loss: 0.0168611 k_t: 0.0396033 M_global: 0.044428\n",
      "step: 35000  d-loss: 0.0410424  g-loss: 0.015441 k_t: 0.0396978 M_global: 0.047042\n",
      "step: 36000  d-loss: 0.0402122  g-loss: 0.0161641 k_t: 0.0417468 M_global: 0.0451664\n",
      "step: 37000  d-loss: 0.0399088  g-loss: 0.0201629 k_t: 0.0391915 M_global: 0.0408857\n",
      "step: 38000  d-loss: 0.0391889  g-loss: 0.0385571 k_t: 0.0300146 M_global: 0.0587303\n",
      "step: 39000  d-loss: 0.0404932  g-loss: 0.0330343 k_t: 0.0223279 M_global: 0.0536498\n",
      "step: 40000  d-loss: 0.0411864  g-loss: 0.0117991 k_t: 0.0288529 M_global: 0.0504911\n",
      "step: 41000  d-loss: 0.0396324  g-loss: 0.0150289 k_t: 0.0335259 M_global: 0.0451756\n",
      "step: 42000  d-loss: 0.0399627  g-loss: 0.0170522 k_t: 0.0327315 M_global: 0.0437291\n",
      "step: 43000  d-loss: 0.040826  g-loss: 0.01923 k_t: 0.0318387 M_global: 0.0429273\n",
      "step: 44000  d-loss: 0.0394748  g-loss: 0.0368751 k_t: 0.031038 M_global: 0.0571847\n",
      "step: 45000  d-loss: 0.0399351  g-loss: 0.00989856 k_t: 0.03524 M_global: 0.0505274\n",
      "step: 46000  d-loss: 0.0419811  g-loss: 0.018301 k_t: 0.0392388 M_global: 0.0457479\n",
      "step: 47000  d-loss: 0.038713  g-loss: 0.012504 k_t: 0.0437629 M_global: 0.0463863\n",
      "step: 48000  d-loss: 0.0372212  g-loss: 0.0194575 k_t: 0.0444501 M_global: 0.0385006\n",
      "step: 49000  d-loss: 0.0391693  g-loss: 0.0201965 k_t: 0.0442802 M_global: 0.0402283\n",
      "step: 50000  d-loss: 0.0383178  g-loss: 0.0351728 k_t: 0.0404447 M_global: 0.055043\n",
      "step: 51000  d-loss: 0.0386289  g-loss: 0.0187977 k_t: 0.0310373 M_global: 0.0400207\n",
      "step: 52000  d-loss: 0.0391101  g-loss: 0.0393299 k_t: 0.0321506 M_global: 0.0595172\n",
      "step: 53000  d-loss: 0.0380468  g-loss: 0.0273711 k_t: 0.0329572 M_global: 0.0468455\n",
      "step: 54000  d-loss: 0.0371671  g-loss: 0.0124672 k_t: 0.037479 M_global: 0.0439843\n",
      "step: 55000  d-loss: 0.0396702  g-loss: 0.0492203 k_t: 0.0390698 M_global: 0.0700169\n",
      "step: 56000  d-loss: 0.0388336  g-loss: 0.0145467 k_t: 0.0333861 M_global: 0.0444322\n",
      "step: 57000  d-loss: 0.0383813  g-loss: 0.0180071 k_t: 0.0361637 M_global: 0.0405417\n",
      "step: 58000  d-loss: 0.0375054  g-loss: 0.015725 k_t: 0.0360528 M_global: 0.0413835\n",
      "step: 59000  d-loss: 0.0376897  g-loss: 0.0144026 k_t: 0.0344467 M_global: 0.0428761\n",
      "step: 60000  d-loss: 0.0374114  g-loss: 0.0267481 k_t: 0.0270794 M_global: 0.0458159\n",
      "step: 61000  d-loss: 0.0372332  g-loss: 0.00787143 k_t: 0.026773 M_global: 0.0482945\n",
      "step: 62000  d-loss: 0.035538  g-loss: 0.00764021 k_t: 0.0342448 M_global: 0.0460592\n",
      "step: 63000  d-loss: 0.0383109  g-loss: 0.0206202 k_t: 0.0352991 M_global: 0.0401396\n",
      "step: 64000  d-loss: 0.037423  g-loss: 0.0141607 k_t: 0.0400642 M_global: 0.0428248\n",
      "step: 65000  d-loss: 0.03946  g-loss: 0.0186495 k_t: 0.0407957 M_global: 0.0416818\n",
      "step: 66000  d-loss: 0.0380517  g-loss: 0.0592975 k_t: 0.000129124 M_global: 0.0783272\n",
      "step: 67000  d-loss: 0.0376644  g-loss: 0.0244194 k_t: 0.000190239 M_global: 0.0432539\n",
      "step: 68000  d-loss: 0.0372925  g-loss: 0.0265031 k_t: 0.00597238 M_global: 0.0452285\n",
      "step: 69000  d-loss: 0.0375785  g-loss: 0.018895 k_t: 0.00299217 M_global: 0.0377125\n",
      "step: 70000  d-loss: 0.0360265  g-loss: 0.0231134 k_t: 0.0037585 M_global: 0.0411701\n",
      "step: 71000  d-loss: 0.0348378  g-loss: 0.00858533 k_t: 0.00680693 M_global: 0.043759\n",
      "step: 72000  d-loss: 0.0341603  g-loss: 0.0187149 k_t: 0.0117996 M_global: 0.0359055\n",
      "step: 73000  d-loss: 0.0366689  g-loss: 0.0134589 k_t: 0.0156348 M_global: 0.0418601\n",
      "step: 74000  d-loss: 0.0366821  g-loss: 0.013206 k_t: 0.0230017 M_global: 0.0422728\n",
      "step: 75000  d-loss: 0.0346001  g-loss: 0.0195394 k_t: 0.0275945 M_global: 0.037109\n",
      "step: 76000  d-loss: 0.0358389  g-loss: 0.0392608 k_t: 0.033796 M_global: 0.0578437\n",
      "step: 77000  d-loss: 0.0350715  g-loss: 0.0181309 k_t: 0.0346031 M_global: 0.0359804\n",
      "step: 78000  d-loss: 0.035857  g-loss: 0.0140679 k_t: 0.0357723 M_global: 0.0404725\n",
      "step: 79000  d-loss: 0.0370797  g-loss: 0.0137118 k_t: 0.0358392 M_global: 0.0426449\n",
      "step: 80000  d-loss: 0.0349729  g-loss: 0.0156236 k_t: 0.0334078 M_global: 0.0376186\n",
      "step: 81000  d-loss: 0.0358293  g-loss: 0.0208863 k_t: 0.032945 M_global: 0.0391449\n",
      "step: 82000  d-loss: 0.034578  g-loss: 0.0138628 k_t: 0.0377532 M_global: 0.0387893\n",
      "step: 83000  d-loss: 0.0366638  g-loss: 0.0302684 k_t: 0.0395506 M_global: 0.0491989\n",
      "step: 84000  d-loss: 0.0355819  g-loss: 0.0139645 k_t: 0.0353051 M_global: 0.0401479\n",
      "step: 85000  d-loss: 0.0375698  g-loss: 0.0368853 k_t: 0.0203816 M_global: 0.0560461\n",
      "step: 86000  d-loss: 0.034711  g-loss: 0.0312182 k_t: 0.0028958 M_global: 0.0486189\n",
      "step: 87000  d-loss: 0.0364573  g-loss: 0.0177307 k_t: 0.00142497 M_global: 0.036993\n",
      "step: 88000  d-loss: 0.0359908  g-loss: 0.0162957 k_t: 0.00209348 M_global: 0.0377417\n",
      "step: 89000  d-loss: 0.0355218  g-loss: 0.0143129 k_t: 0.00194587 M_global: 0.0390116\n",
      "step: 90000  d-loss: 0.033248  g-loss: 0.0197171 k_t: 0.00572217 M_global: 0.0363975\n",
      "step: 91000  d-loss: 0.0358706  g-loss: 0.0179099 k_t: 0.00249139 M_global: 0.0359629\n",
      "step: 92000  d-loss: 0.0363289  g-loss: 0.0188527 k_t: 0.00343701 M_global: 0.0370496\n",
      "step: 93000  d-loss: 0.0357505  g-loss: 0.0177424 k_t: 0.00376353 M_global: 0.0359836\n",
      "step: 94000  d-loss: 0.0361534  g-loss: 0.0137983 k_t: 0.0036224 M_global: 0.0405068\n",
      "step: 95000  d-loss: 0.032906  g-loss: 0.0171042 k_t: 0.00538395 M_global: 0.0336032\n",
      "step: 96000  d-loss: 0.0348729  g-loss: 0.0185182 k_t: 0.00553403 M_global: 0.0360059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 97000  d-loss: 0.0366037  g-loss: 0.0204286 k_t: 0.0036414 M_global: 0.0387676\n",
      "step: 98000  d-loss: 0.0338928  g-loss: 0.015568 k_t: 0.00292454 M_global: 0.0353395\n",
      "step: 99000  d-loss: 0.0357261  g-loss: 0.0167799 k_t: 0.00333627 M_global: 0.0368932\n",
      "step: 100000  d-loss: 0.0363393  g-loss: 0.0172539 k_t: 0.0032068 M_global: 0.037338\n"
     ]
    }
   ],
   "source": [
    "for step in range(100001):\n",
    "    batch_x = mnist.train.next_batch(batch_size)[0]\n",
    "    z_D = sample_Z(batch_size, g_dim)\n",
    "    sess.run([d_optimizer, g_optimizer], feed_dict={x_d: batch_x, x_g: z_D})\n",
    "    z_G = sample_Z(batch_size, g_dim)\n",
    "    sess.run(g_optimizer, feed_dict={x_g: z_G})\n",
    "#     k_t = np.maximum(np.minimum(1., k_t + 0.001*(sess.run(balancer, feed_dict={x_d: batch_x, x_g: z_G}))), 0.)\n",
    "    sess.run(update_k, feed_dict={x_d: batch_x, x_g: z_G})\n",
    "    if step%1000==0:\n",
    "        d_loss_train, g_loss_train, k_tt, M_global_train = sess.run([d_loss, g_loss, k_t, M_global], feed_dict=\n",
    "                            {x_d: batch_x, x_g: sample_Z(batch_size, g_dim)})\n",
    "#         print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_t,\"M_global:\", M_global_train\n",
    "        print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_tt,\"M_global:\", M_global_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAD8CAYAAADOg5fGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRlREJAQ1oiIiIagRFREJQY2oiEgI/x9hcU6tiz7+qgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1b5bc00550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gg = sess.run(g_sample, feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(g_sample), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(decoder(x_g), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(x_d), feed_dict = {x_d: x_train})\n",
    "gg_pic = np.array([np.reshape(m,(28,28)) for m in gg])\n",
    "fig, ax = plt.subplots(nrows=3, ncols=3)\n",
    "for i,row in enumerate(ax):\n",
    "    for j,col in enumerate(row):\n",
    "        ax[i][j].imshow(gg_pic[i*3+j], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0  d-loss: 0.0364674  g-loss: 0.0175201 k_t: 0.00320758 M_global: 0.0372653\n",
      "step: 1000  d-loss: 0.0354259  g-loss: 0.0194115 k_t: 0.00299673 M_global: 0.0371535\n",
      "step: 2000  d-loss: 0.0357751  g-loss: 0.00888002 k_t: 0.00725934 M_global: 0.0448793\n",
      "step: 3000  d-loss: 0.0363098  g-loss: 0.0103094 k_t: 0.0160285 M_global: 0.0444031\n",
      "step: 4000  d-loss: 0.0371717  g-loss: 0.0218108 k_t: 0.00636591 M_global: 0.0404661\n",
      "step: 5000  d-loss: 0.0341891  g-loss: 0.0227471 k_t: 0.00365083 M_global: 0.0398832\n",
      "step: 6000  d-loss: 0.0349706  g-loss: 0.0165761 k_t: 0.00178064 M_global: 0.0359241\n",
      "step: 7000  d-loss: 0.0354571  g-loss: 0.0180531 k_t: 0.0017514 M_global: 0.0357975\n",
      "step: 8000  d-loss: 0.0333772  g-loss: 0.016235 k_t: 0.00164126 M_global: 0.0338708\n",
      "step: 9000  d-loss: 0.0359487  g-loss: 0.0190029 k_t: 0.00151204 M_global: 0.0369916\n",
      "step: 10000  d-loss: 0.03583  g-loss: 0.0159153 k_t: 0.0015922 M_global: 0.0378676\n",
      "step: 11000  d-loss: 0.0338784  g-loss: 0.0187045 k_t: 0.0014125 M_global: 0.0356569\n",
      "step: 12000  d-loss: 0.0344448  g-loss: 0.0184365 k_t: 0.00149966 M_global: 0.0356727\n",
      "step: 13000  d-loss: 0.0324872  g-loss: 0.0165535 k_t: 0.00147327 M_global: 0.0328093\n",
      "step: 14000  d-loss: 0.0354883  g-loss: 0.016897 k_t: 0.00189216 M_global: 0.0363834\n",
      "step: 15000  d-loss: 0.0361801  g-loss: 0.0141765 k_t: 0.0033768 M_global: 0.0401654\n",
      "step: 16000  d-loss: 0.0341139  g-loss: 0.0157492 k_t: 0.00438483 M_global: 0.0355252\n",
      "step: 17000  d-loss: 0.0338382  g-loss: 0.00962919 k_t: 0.0105842 M_global: 0.0412809\n",
      "step: 18000  d-loss: 0.0337385  g-loss: 0.010066 k_t: 0.0143046 M_global: 0.0407578\n",
      "step: 19000  d-loss: 0.0353392  g-loss: 0.0117756 k_t: 0.022874 M_global: 0.0416371\n",
      "step: 20000  d-loss: 0.0327834  g-loss: 0.0217539 k_t: 0.018115 M_global: 0.0383426\n",
      "step: 21000  d-loss: 0.0346528  g-loss: 0.0229241 k_t: 0.0132975 M_global: 0.0404029\n",
      "step: 22000  d-loss: 0.0330119  g-loss: 0.0256746 k_t: 0.0071356 M_global: 0.0422722\n",
      "step: 23000  d-loss: 0.033479  g-loss: 0.00962516 k_t: 0.00697877 M_global: 0.0406941\n",
      "step: 24000  d-loss: 0.0350845  g-loss: 0.00763685 k_t: 0.0140966 M_global: 0.0451515\n",
      "step: 25000  d-loss: 0.0341415  g-loss: 0.00990633 k_t: 0.0220265 M_global: 0.0416333\n",
      "step: 26000  d-loss: 0.0355437  g-loss: 0.017861 k_t: 0.0233516 M_global: 0.0360802\n",
      "step: 27000  d-loss: 0.0340911  g-loss: 0.0199138 k_t: 0.0248505 M_global: 0.0372068\n",
      "step: 28000  d-loss: 0.033467  g-loss: 0.00859616 k_t: 0.0258518 M_global: 0.0419377\n",
      "step: 29000  d-loss: 0.0347692  g-loss: 0.0212043 k_t: 0.0258643 M_global: 0.0388631\n",
      "step: 30000  d-loss: 0.0339304  g-loss: 0.0106791 k_t: 0.0314484 M_global: 0.0407204\n",
      "step: 31000  d-loss: 0.0342212  g-loss: 0.0124482 k_t: 0.0386129 M_global: 0.0396046\n",
      "step: 32000  d-loss: 0.0337524  g-loss: 0.011404 k_t: 0.0433929 M_global: 0.0399669\n",
      "step: 33000  d-loss: 0.0338167  g-loss: 0.0472022 k_t: 0.0436436 M_global: 0.0651405\n",
      "step: 34000  d-loss: 0.0351227  g-loss: 0.0250328 k_t: 0.0370726 M_global: 0.0430581\n",
      "step: 35000  d-loss: 0.0349541  g-loss: 0.0182806 k_t: 0.0327062 M_global: 0.0360566\n",
      "step: 36000  d-loss: 0.0339602  g-loss: 0.0204639 k_t: 0.0337917 M_global: 0.0377898\n",
      "step: 37000  d-loss: 0.0347775  g-loss: 0.0197316 k_t: 0.0303338 M_global: 0.0374196\n",
      "step: 38000  d-loss: 0.0334269  g-loss: 0.0116298 k_t: 0.0325998 M_global: 0.0390793\n",
      "step: 39000  d-loss: 0.0358007  g-loss: 0.023441 k_t: 0.0290346 M_global: 0.0416816\n",
      "step: 40000  d-loss: 0.0334012  g-loss: 0.0128245 k_t: 0.027639 M_global: 0.037809\n",
      "step: 41000  d-loss: 0.0351772  g-loss: 0.011604 k_t: 0.0268805 M_global: 0.0416297\n",
      "step: 42000  d-loss: 0.0324588  g-loss: 0.0156366 k_t: 0.0298451 M_global: 0.0337516\n",
      "step: 43000  d-loss: 0.0340777  g-loss: 0.0130477 k_t: 0.0327019 M_global: 0.0387088\n",
      "step: 44000  d-loss: 0.0337122  g-loss: 0.018943 k_t: 0.0254238 M_global: 0.0360399\n",
      "step: 45000  d-loss: 0.0333925  g-loss: 0.0159483 k_t: 0.0286021 M_global: 0.0348246\n",
      "step: 46000  d-loss: 0.0340358  g-loss: 0.0176373 k_t: 0.0232442 M_global: 0.0348602\n",
      "step: 47000  d-loss: 0.0346194  g-loss: 0.0172996 k_t: 0.0260018 M_global: 0.0353043\n",
      "step: 48000  d-loss: 0.0325696  g-loss: 0.0141798 k_t: 0.0296685 M_global: 0.0353057\n",
      "step: 49000  d-loss: 0.0345447  g-loss: 0.0137065 k_t: 0.0324249 M_global: 0.0387772\n",
      "step: 50000  d-loss: 0.0349255  g-loss: 0.0152595 k_t: 0.0333763 M_global: 0.0378926\n",
      "step: 51000  d-loss: 0.0329921  g-loss: 0.0194186 k_t: 0.0304534 M_global: 0.0362104\n",
      "step: 52000  d-loss: 0.0335337  g-loss: 0.0197504 k_t: 0.0248748 M_global: 0.0367629\n",
      "step: 53000  d-loss: 0.0345432  g-loss: 0.0086236 k_t: 0.0271944 M_global: 0.043543\n",
      "step: 54000  d-loss: 0.0311624  g-loss: 0.0221502 k_t: 0.0287281 M_global: 0.0380495\n",
      "step: 55000  d-loss: 0.0328349  g-loss: 0.0221831 k_t: 0.0264007 M_global: 0.0388934\n",
      "step: 56000  d-loss: 0.034527  g-loss: 0.010063 k_t: 0.0242878 M_global: 0.0420941\n",
      "step: 57000  d-loss: 0.0348676  g-loss: 0.0141889 k_t: 0.0276503 M_global: 0.0387009\n",
      "step: 58000  d-loss: 0.0347796  g-loss: 0.0132767 k_t: 0.0277448 M_global: 0.0394452\n",
      "step: 59000  d-loss: 0.0331155  g-loss: 0.0187602 k_t: 0.0275159 M_global: 0.035576\n",
      "step: 60000  d-loss: 0.0335376  g-loss: 0.0123676 k_t: 0.0246691 M_global: 0.0383964\n",
      "step: 61000  d-loss: 0.03423  g-loss: 0.0164856 k_t: 0.0248521 M_global: 0.035474\n",
      "step: 62000  d-loss: 0.0323067  g-loss: 0.0213289 k_t: 0.0237451 M_global: 0.0377355\n",
      "step: 63000  d-loss: 0.034533  g-loss: 0.00892285 k_t: 0.024051 M_global: 0.0431986\n",
      "step: 64000  d-loss: 0.0352648  g-loss: 0.0136542 k_t: 0.0274429 M_global: 0.0398051\n",
      "step: 65000  d-loss: 0.0344784  g-loss: 0.0207649 k_t: 0.0280785 M_global: 0.0382956\n",
      "step: 66000  d-loss: 0.0334454  g-loss: 0.0127501 k_t: 0.0230239 M_global: 0.0378584\n",
      "step: 67000  d-loss: 0.0328669  g-loss: 0.0178164 k_t: 0.0233296 M_global: 0.0344576\n",
      "step: 68000  d-loss: 0.0336314  g-loss: 0.0150493 k_t: 0.0242973 M_global: 0.0359463\n",
      "step: 69000  d-loss: 0.0339311  g-loss: 0.0123611 k_t: 0.0236613 M_global: 0.0389743\n",
      "step: 70000  d-loss: 0.0333196  g-loss: 0.0123259 k_t: 0.0286768 M_global: 0.0381837\n",
      "step: 71000  d-loss: 0.0344632  g-loss: 0.0112455 k_t: 0.0326753 M_global: 0.0410005\n",
      "step: 72000  d-loss: 0.0327001  g-loss: 0.00969556 k_t: 0.0358137 M_global: 0.0398754\n",
      "step: 73000  d-loss: 0.0344575  g-loss: 0.014925 k_t: 0.0396324 M_global: 0.0376484\n",
      "step: 74000  d-loss: 0.0333432  g-loss: 0.0107078 k_t: 0.039941 M_global: 0.0399485\n",
      "step: 75000  d-loss: 0.0336291  g-loss: 0.0209608 k_t: 0.0288036 M_global: 0.0380773\n",
      "step: 76000  d-loss: 0.0346446  g-loss: 0.0124657 k_t: 0.0300462 M_global: 0.040063\n",
      "step: 77000  d-loss: 0.0330933  g-loss: 0.0133154 k_t: 0.0349645 M_global: 0.0370229\n",
      "step: 78000  d-loss: 0.0323787  g-loss: 0.02384 k_t: 0.0337118 M_global: 0.0404312\n",
      "step: 79000  d-loss: 0.0356892  g-loss: 0.035377 k_t: 0.0260752 M_global: 0.0536828\n",
      "step: 80000  d-loss: 0.0337516  g-loss: 0.0137099 k_t: 0.0274755 M_global: 0.0374825\n",
      "step: 81000  d-loss: 0.0330674  g-loss: 0.0152606 k_t: 0.0303205 M_global: 0.0350345\n",
      "step: 82000  d-loss: 0.032456  g-loss: 0.0132931 k_t: 0.0333913 M_global: 0.0360567\n",
      "step: 83000  d-loss: 0.0324518  g-loss: 0.0129469 k_t: 0.0380135 M_global: 0.0364691\n",
      "step: 84000  d-loss: 0.0327958  g-loss: 0.0115866 k_t: 0.0404363 M_global: 0.0383099\n",
      "step: 85000  d-loss: 0.0329593  g-loss: 0.0153605 k_t: 0.036272 M_global: 0.0349143\n",
      "step: 86000  d-loss: 0.03354  g-loss: 0.0163825 k_t: 0.0344223 M_global: 0.0347734\n",
      "step: 87000  d-loss: 0.0330393  g-loss: 0.0125613 k_t: 0.0364328 M_global: 0.0376841\n",
      "step: 88000  d-loss: 0.0314774  g-loss: 0.015418 k_t: 0.0347883 M_global: 0.0326026\n",
      "step: 89000  d-loss: 0.0323275  g-loss: 0.0225824 k_t: 0.0324618 M_global: 0.0391127\n",
      "step: 90000  d-loss: 0.0318878  g-loss: 0.0125375 k_t: 0.0283404 M_global: 0.0358271\n",
      "step: 91000  d-loss: 0.0344983  g-loss: 0.0168064 k_t: 0.0295867 M_global: 0.0356869\n",
      "step: 92000  d-loss: 0.0324416  g-loss: 0.00899576 k_t: 0.0219158 M_global: 0.0399624\n",
      "step: 93000  d-loss: 0.0327583  g-loss: 0.0110541 k_t: 0.0286146 M_global: 0.0385578\n",
      "step: 94000  d-loss: 0.0327381  g-loss: 0.0172168 k_t: 0.0302037 M_global: 0.0338458\n",
      "step: 95000  d-loss: 0.0319478  g-loss: 0.0132998 k_t: 0.0318691 M_global: 0.0352576\n",
      "step: 96000  d-loss: 0.0332291  g-loss: 0.0131677 k_t: 0.0326025 M_global: 0.0373199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 97000  d-loss: 0.0333663  g-loss: 0.013276 k_t: 0.0326131 M_global: 0.0374228\n",
      "step: 98000  d-loss: 0.0325548  g-loss: 0.0194554 k_t: 0.0294565 M_global: 0.0360194\n",
      "step: 99000  d-loss: 0.0341747  g-loss: 0.0391648 k_t: 0.0147836 M_global: 0.0565417\n",
      "step: 100000  d-loss: 0.0310562  g-loss: 0.0121183 k_t: 0.0138056 M_global: 0.034717\n"
     ]
    }
   ],
   "source": [
    "for step in range(100001):\n",
    "    batch_x = mnist.train.next_batch(batch_size)[0]\n",
    "    z_D = sample_Z(batch_size, g_dim)\n",
    "    sess.run([d_optimizer, g_optimizer], feed_dict={x_d: batch_x, x_g: z_D})\n",
    "    z_G = sample_Z(batch_size, g_dim)\n",
    "    sess.run(g_optimizer, feed_dict={x_g: z_G})\n",
    "#     k_t = np.maximum(np.minimum(1., k_t + 0.001*(sess.run(balancer, feed_dict={x_d: batch_x, x_g: z_G}))), 0.)\n",
    "    sess.run(update_k, feed_dict={x_d: batch_x, x_g: z_G})\n",
    "    if step%1000==0:\n",
    "        d_loss_train, g_loss_train, k_tt, M_global_train = sess.run([d_loss, g_loss, k_t, M_global], feed_dict=\n",
    "                            {x_d: batch_x, x_g: sample_Z(batch_size, g_dim)})\n",
    "#         print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_t,\"M_global:\", M_global_train\n",
    "        print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_tt,\"M_global:\", M_global_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAD8CAYAAADOg5fGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1b5ac44110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gg = sess.run(g_sample, feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(g_sample), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(decoder(x_g), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(x_d), feed_dict = {x_d: x_train})\n",
    "gg_pic = np.array([np.reshape(m,(28,28)) for m in gg])\n",
    "fig, ax = plt.subplots(nrows=3, ncols=3)\n",
    "for i,row in enumerate(ax):\n",
    "    for j,col in enumerate(row):\n",
    "        ax[i][j].imshow(gg_pic[i*3+j], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0  d-loss: 0.0323887  g-loss: 0.01325 k_t: 0.0138086 M_global: 0.0356075\n",
      "step: 1000  d-loss: 0.0334099  g-loss: 0.00876409 k_t: 0.0205591 M_global: 0.041621\n",
      "step: 2000  d-loss: 0.0339567  g-loss: 0.00935336 k_t: 0.0275938 M_global: 0.0419688\n",
      "step: 3000  d-loss: 0.0324903  g-loss: 0.0129712 k_t: 0.0307374 M_global: 0.0363623\n",
      "step: 4000  d-loss: 0.0330256  g-loss: 0.0104332 k_t: 0.033762 M_global: 0.0396335\n",
      "step: 5000  d-loss: 0.0321762  g-loss: 0.0185335 k_t: 0.0359976 M_global: 0.0349551\n",
      "step: 6000  d-loss: 0.0322258  g-loss: 0.0105706 k_t: 0.0347342 M_global: 0.0383189\n",
      "step: 7000  d-loss: 0.0302979  g-loss: 0.017679 k_t: 0.0357139 M_global: 0.0331437\n",
      "step: 8000  d-loss: 0.034757  g-loss: 0.0227509 k_t: 0.0300715 M_global: 0.0404715\n",
      "step: 9000  d-loss: 0.0329453  g-loss: 0.0117116 k_t: 0.0277922 M_global: 0.0381946\n",
      "step: 10000  d-loss: 0.0324702  g-loss: 0.0206094 k_t: 0.0271147 M_global: 0.0371239\n",
      "step: 11000  d-loss: 0.0326912  g-loss: 0.0176466 k_t: 0.0252419 M_global: 0.0342149\n",
      "step: 12000  d-loss: 0.0316143  g-loss: 0.0474531 k_t: 0.0137223 M_global: 0.0635858\n",
      "step: 13000  d-loss: 0.0306729  g-loss: 0.020077 k_t: 0.0015697 M_global: 0.0354293\n",
      "step: 14000  d-loss: 0.0324511  g-loss: 0.0147503 k_t: 0.0010956 M_global: 0.0339506\n",
      "step: 15000  d-loss: 0.0331073  g-loss: 0.0150259 k_t: 0.00142755 M_global: 0.0346672\n",
      "step: 16000  d-loss: 0.0324443  g-loss: 0.0149749 k_t: 0.00164934 M_global: 0.0337286\n",
      "step: 17000  d-loss: 0.033666  g-loss: 0.0189359 k_t: 0.00371866 M_global: 0.0358041\n",
      "step: 18000  d-loss: 0.034502  g-loss: 0.0167114 k_t: 0.00254418 M_global: 0.0351053\n",
      "step: 19000  d-loss: 0.0317631  g-loss: 0.016405 k_t: 0.000910652 M_global: 0.032294\n",
      "step: 20000  d-loss: 0.0337886  g-loss: 0.0140334 k_t: 0.00295885 M_global: 0.0367117\n",
      "step: 21000  d-loss: 0.0322169  g-loss: 0.01862 k_t: 0.0035616 M_global: 0.0347616\n",
      "step: 22000  d-loss: 0.0326209  g-loss: 0.0123255 k_t: 0.00315139 M_global: 0.0366641\n",
      "step: 23000  d-loss: 0.0313934  g-loss: 0.0170321 k_t: 0.00492861 M_global: 0.0327708\n",
      "step: 24000  d-loss: 0.0338548  g-loss: 0.0143222 k_t: 0.00446531 M_global: 0.0365559\n",
      "step: 25000  d-loss: 0.032568  g-loss: 0.0106872 k_t: 0.00458436 M_global: 0.0382383\n",
      "step: 26000  d-loss: 0.0322788  g-loss: 0.0101054 k_t: 0.0115376 M_global: 0.0384877\n",
      "step: 27000  d-loss: 0.0318702  g-loss: 0.0182586 k_t: 0.0131928 M_global: 0.0343141\n",
      "step: 28000  d-loss: 0.0310255  g-loss: 0.00973513 k_t: 0.0167205 M_global: 0.0370473\n",
      "step: 29000  d-loss: 0.0323759  g-loss: 0.00894325 k_t: 0.0235058 M_global: 0.039936\n",
      "step: 30000  d-loss: 0.0329972  g-loss: 0.0127772 k_t: 0.0261175 M_global: 0.0372192\n",
      "step: 31000  d-loss: 0.032848  g-loss: 0.0197218 k_t: 0.0263886 M_global: 0.036406\n",
      "step: 32000  d-loss: 0.0320911  g-loss: 0.0230225 k_t: 0.0244282 M_global: 0.0393493\n",
      "step: 33000  d-loss: 0.0327812  g-loss: 0.0188592 k_t: 0.0208238 M_global: 0.0354461\n",
      "step: 34000  d-loss: 0.0319553  g-loss: 0.0177749 k_t: 0.0198168 M_global: 0.0339287\n",
      "step: 35000  d-loss: 0.0336669  g-loss: 0.020985 k_t: 0.019427 M_global: 0.0380223\n",
      "step: 36000  d-loss: 0.0320125  g-loss: 0.0562246 k_t: 0.0163697 M_global: 0.072691\n",
      "step: 37000  d-loss: 0.0320381  g-loss: 0.0160888 k_t: 0.00555786 M_global: 0.0321526\n",
      "step: 38000  d-loss: 0.0322488  g-loss: 0.0181802 k_t: 0.00642288 M_global: 0.034363\n",
      "step: 39000  d-loss: 0.0332724  g-loss: 0.0182248 k_t: 0.00542058 M_global: 0.0349104\n",
      "step: 40000  d-loss: 0.0323936  g-loss: 0.013254 k_t: 0.00775125 M_global: 0.0354905\n",
      "step: 41000  d-loss: 0.0317953  g-loss: 0.0132229 k_t: 0.0100702 M_global: 0.0346699\n",
      "step: 42000  d-loss: 0.0323377  g-loss: 0.0175723 k_t: 0.0089678 M_global: 0.03382\n",
      "step: 43000  d-loss: 0.0330031  g-loss: 0.00465968 k_t: 0.00957515 M_global: 0.044912\n",
      "step: 44000  d-loss: 0.0319379  g-loss: 0.0106756 k_t: 0.0186361 M_global: 0.0375297\n",
      "step: 45000  d-loss: 0.0328102  g-loss: 0.0133789 k_t: 0.0227926 M_global: 0.0362938\n",
      "step: 46000  d-loss: 0.0324795  g-loss: 0.0131876 k_t: 0.0294429 M_global: 0.0361141\n",
      "step: 47000  d-loss: 0.031385  g-loss: 0.0151564 k_t: 0.0342209 M_global: 0.0326992\n",
      "step: 48000  d-loss: 0.0316176  g-loss: 0.0106521 k_t: 0.0365393 M_global: 0.0373582\n",
      "step: 49000  d-loss: 0.0317091  g-loss: 0.0200484 k_t: 0.0340397 M_global: 0.0362441\n",
      "step: 50000  d-loss: 0.0319063  g-loss: 0.0109879 k_t: 0.0347861 M_global: 0.0374449\n",
      "step: 51000  d-loss: 0.0307959  g-loss: 0.0238874 k_t: 0.0344015 M_global: 0.0396962\n",
      "step: 52000  d-loss: 0.0303926  g-loss: 0.0153719 k_t: 0.0356763 M_global: 0.0310397\n",
      "step: 53000  d-loss: 0.0330654  g-loss: 0.0122866 k_t: 0.0379031 M_global: 0.03801\n",
      "step: 54000  d-loss: 0.0333991  g-loss: 0.01358 k_t: 0.0367648 M_global: 0.0372675\n",
      "step: 55000  d-loss: 0.0304576  g-loss: 0.0182519 k_t: 0.036763 M_global: 0.0338162\n",
      "step: 56000  d-loss: 0.0309766  g-loss: 0.0127119 k_t: 0.0372537 M_global: 0.0344634\n",
      "step: 57000  d-loss: 0.0314534  g-loss: 0.0237349 k_t: 0.0331199 M_global: 0.0398546\n",
      "step: 58000  d-loss: 0.0327433  g-loss: 0.0150783 k_t: 0.0312679 M_global: 0.0347439\n",
      "step: 59000  d-loss: 0.0318613  g-loss: 0.0175453 k_t: 0.019461 M_global: 0.0336467\n",
      "step: 60000  d-loss: 0.0324841  g-loss: 0.0182937 k_t: 0.0185766 M_global: 0.0347057\n",
      "step: 61000  d-loss: 0.0320611  g-loss: 0.0122819 k_t: 0.022074 M_global: 0.0362163\n",
      "step: 62000  d-loss: 0.0299998  g-loss: 0.0114189 k_t: 0.0270566 M_global: 0.0340442\n",
      "step: 63000  d-loss: 0.0318057  g-loss: 0.0117112 k_t: 0.030987 M_global: 0.0365416\n",
      "step: 64000  d-loss: 0.0313714  g-loss: 0.0316795 k_t: 0.0327738 M_global: 0.0478844\n",
      "step: 65000  d-loss: 0.0345237  g-loss: 0.0223594 k_t: 0.0311081 M_global: 0.0399691\n",
      "step: 66000  d-loss: 0.0326339  g-loss: 0.021479 k_t: 0.0281657 M_global: 0.0380985\n",
      "step: 67000  d-loss: 0.0317744  g-loss: 0.012034 k_t: 0.0293198 M_global: 0.0361568\n",
      "step: 68000  d-loss: 0.0321578  g-loss: 0.0148567 k_t: 0.0292749 M_global: 0.0340324\n",
      "step: 69000  d-loss: 0.0324291  g-loss: 0.0299595 k_t: 0.0273984 M_global: 0.0465845\n",
      "step: 70000  d-loss: 0.0322308  g-loss: 0.0192153 k_t: 0.0244059 M_global: 0.0355652\n",
      "step: 71000  d-loss: 0.0310916  g-loss: 0.0140108 k_t: 0.0266414 M_global: 0.0331865\n",
      "step: 72000  d-loss: 0.0312852  g-loss: 0.0125438 k_t: 0.0265125 M_global: 0.0348829\n",
      "step: 73000  d-loss: 0.032619  g-loss: 0.0143337 k_t: 0.0274144 M_global: 0.0351843\n",
      "step: 74000  d-loss: 0.0333411  g-loss: 0.011709 k_t: 0.0266261 M_global: 0.0387703\n",
      "step: 75000  d-loss: 0.0329687  g-loss: 0.0253907 k_t: 0.0236972 M_global: 0.0421759\n",
      "step: 76000  d-loss: 0.0298969  g-loss: 0.0193931 k_t: 0.0212159 M_global: 0.0345473\n",
      "step: 77000  d-loss: 0.0317368  g-loss: 0.0220516 k_t: 0.011656 M_global: 0.0380485\n",
      "step: 78000  d-loss: 0.0326971  g-loss: 0.015758 k_t: 0.00464749 M_global: 0.0333975\n",
      "step: 79000  d-loss: 0.0321002  g-loss: 0.0110001 k_t: 0.00705493 M_global: 0.0372667\n",
      "step: 80000  d-loss: 0.031287  g-loss: 0.0122353 k_t: 0.00644667 M_global: 0.0348135\n",
      "step: 81000  d-loss: 0.0301632  g-loss: 0.00861072 k_t: 0.0117868 M_global: 0.0367863\n",
      "step: 82000  d-loss: 0.0316538  g-loss: 0.0208236 k_t: 0.0125628 M_global: 0.0367813\n",
      "step: 83000  d-loss: 0.0309212  g-loss: 0.00966307 k_t: 0.0151441 M_global: 0.0369383\n",
      "step: 84000  d-loss: 0.0315662  g-loss: 0.0168759 k_t: 0.0183784 M_global: 0.032814\n",
      "step: 85000  d-loss: 0.0319853  g-loss: 0.0188082 k_t: 0.017412 M_global: 0.0349646\n",
      "step: 86000  d-loss: 0.0301836  g-loss: 0.0175177 k_t: 0.015815 M_global: 0.032748\n",
      "step: 87000  d-loss: 0.0318964  g-loss: 0.0137501 k_t: 0.0136438 M_global: 0.0343758\n",
      "step: 88000  d-loss: 0.0318385  g-loss: 0.0169118 k_t: 0.0128333 M_global: 0.0329395\n",
      "step: 89000  d-loss: 0.03056  g-loss: 0.0152708 k_t: 0.0161739 M_global: 0.0309397\n",
      "step: 90000  d-loss: 0.0308898  g-loss: 0.0121153 k_t: 0.0208685 M_global: 0.0345987\n",
      "step: 91000  d-loss: 0.0309326  g-loss: 0.0109725 k_t: 0.0239631 M_global: 0.0358208\n",
      "step: 92000  d-loss: 0.0313609  g-loss: 0.0226864 k_t: 0.0191635 M_global: 0.0385843\n",
      "step: 93000  d-loss: 0.0311148  g-loss: 0.014489 k_t: 0.0204106 M_global: 0.0326268\n",
      "step: 94000  d-loss: 0.0313769  g-loss: 0.0422411 k_t: 0.0228808 M_global: 0.0584128\n",
      "step: 95000  d-loss: 0.0323902  g-loss: 0.0108288 k_t: 0.0213877 M_global: 0.0381039\n",
      "step: 96000  d-loss: 0.0314771  g-loss: 0.015961 k_t: 0.0182708 M_global: 0.0318453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 97000  d-loss: 0.0308075  g-loss: 0.0146206 k_t: 0.016103 M_global: 0.0319439\n",
      "step: 98000  d-loss: 0.030305  g-loss: 0.0187153 k_t: 0.0153131 M_global: 0.0340111\n",
      "step: 99000  d-loss: 0.0302585  g-loss: 0.0235347 k_t: 0.0126686 M_global: 0.0388131\n",
      "step: 100000  d-loss: 0.031327  g-loss: 0.0168871 k_t: 0.00964654 M_global: 0.0326321\n"
     ]
    }
   ],
   "source": [
    "for step in range(100001):\n",
    "    batch_x = mnist.train.next_batch(batch_size)[0]\n",
    "    z_D = sample_Z(batch_size, g_dim)\n",
    "    sess.run([d_optimizer, g_optimizer], feed_dict={x_d: batch_x, x_g: z_D})\n",
    "    z_G = sample_Z(batch_size, g_dim)\n",
    "    sess.run(g_optimizer, feed_dict={x_g: z_G})\n",
    "#     k_t = np.maximum(np.minimum(1., k_t + 0.001*(sess.run(balancer, feed_dict={x_d: batch_x, x_g: z_G}))), 0.)\n",
    "    sess.run(update_k, feed_dict={x_d: batch_x, x_g: z_G})\n",
    "    if step%1000==0:\n",
    "        d_loss_train, g_loss_train, k_tt, M_global_train = sess.run([d_loss, g_loss, k_t, M_global], feed_dict=\n",
    "                            {x_d: batch_x, x_g: sample_Z(batch_size, g_dim)})\n",
    "#         print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_t,\"M_global:\", M_global_train\n",
    "        print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_tt,\"M_global:\", M_global_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAD8CAYAAADOg5fGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1b885d7f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gg = sess.run(g_sample, feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(g_sample), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(decoder(x_g), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(x_d), feed_dict = {x_d: x_train})\n",
    "gg_pic = np.array([np.reshape(m,(28,28)) for m in gg])\n",
    "fig, ax = plt.subplots(nrows=3, ncols=3)\n",
    "for i,row in enumerate(ax):\n",
    "    for j,col in enumerate(row):\n",
    "        ax[i][j].imshow(gg_pic[i*3+j], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0  d-loss: 0.0307634  g-loss: 0.0168936 k_t: 0.00964507 M_global: 0.0323568\n",
      "step: 1000  d-loss: 0.0315141  g-loss: 0.0217758 k_t: 0.00785393 M_global: 0.0376183\n",
      "step: 2000  d-loss: 0.0321538  g-loss: 0.0140907 k_t: 0.00615741 M_global: 0.0342701\n",
      "step: 3000  d-loss: 0.0317924  g-loss: 0.0173982 k_t: 0.00678315 M_global: 0.0333534\n",
      "step: 4000  d-loss: 0.0315408  g-loss: 0.0101243 k_t: 0.00806059 M_global: 0.0373092\n",
      "step: 5000  d-loss: 0.0310727  g-loss: 0.0117967 k_t: 0.0125216 M_global: 0.0350339\n",
      "step: 6000  d-loss: 0.0313728  g-loss: 0.0288112 k_t: 0.01244 M_global: 0.0446768\n",
      "step: 7000  d-loss: 0.0314398  g-loss: 0.0129572 k_t: 0.00968117 M_global: 0.0343907\n",
      "step: 8000  d-loss: 0.0320332  g-loss: 0.0161761 k_t: 0.010428 M_global: 0.032277\n",
      "step: 9000  d-loss: 0.0323819  g-loss: 0.0118645 k_t: 0.0117357 M_global: 0.0369171\n",
      "step: 10000  d-loss: 0.0312243  g-loss: 0.0155916 k_t: 0.0151511 M_global: 0.0315993\n",
      "step: 11000  d-loss: 0.0314078  g-loss: 0.0160842 k_t: 0.0123776 M_global: 0.0318877\n",
      "step: 12000  d-loss: 0.0310555  g-loss: 0.0179329 k_t: 0.00857294 M_global: 0.0335375\n",
      "step: 13000  d-loss: 0.0308451  g-loss: 0.0107721 k_t: 0.0102083 M_global: 0.0356605\n",
      "step: 14000  d-loss: 0.0320187  g-loss: 0.0163293 k_t: 0.011763 M_global: 0.0324347\n",
      "step: 15000  d-loss: 0.0314414  g-loss: 0.0176759 k_t: 0.00824149 M_global: 0.0334695\n",
      "step: 16000  d-loss: 0.0315852  g-loss: 0.0189753 k_t: 0.00536353 M_global: 0.0348188\n",
      "step: 17000  d-loss: 0.0322808  g-loss: 0.0203321 k_t: 0.0045768 M_global: 0.036519\n",
      "step: 18000  d-loss: 0.0316204  g-loss: 0.0164119 k_t: 0.00404475 M_global: 0.0322553\n",
      "step: 19000  d-loss: 0.0327314  g-loss: 0.0160517 k_t: 0.0051565 M_global: 0.0331695\n",
      "step: 20000  d-loss: 0.0303623  g-loss: 0.00866553 k_t: 0.00785095 M_global: 0.03698\n",
      "step: 21000  d-loss: 0.0298707  g-loss: 0.0173587 k_t: 0.0105862 M_global: 0.0323859\n",
      "step: 22000  d-loss: 0.0305926  g-loss: 0.0295485 k_t: 0.0117189 M_global: 0.045018\n",
      "step: 23000  d-loss: 0.0307057  g-loss: 0.0214932 k_t: 0.00325404 M_global: 0.036881\n",
      "step: 24000  d-loss: 0.0291855  g-loss: 0.014157 k_t: 0.00589771 M_global: 0.0297466\n",
      "step: 25000  d-loss: 0.0312942  g-loss: 0.0171751 k_t: 0.00343001 M_global: 0.0328516\n",
      "step: 26000  d-loss: 0.0300018  g-loss: 0.0119906 k_t: 0.00495349 M_global: 0.0331013\n",
      "step: 27000  d-loss: 0.0321033  g-loss: 0.0197795 k_t: 0.00346511 M_global: 0.0358654\n",
      "step: 28000  d-loss: 0.0291778  g-loss: 0.014978 k_t: 0.00194655 M_global: 0.0295814\n",
      "step: 29000  d-loss: 0.0306509  g-loss: 0.013272 k_t: 0.00413402 M_global: 0.0327867\n",
      "step: 30000  d-loss: 0.0304703  g-loss: 0.0166445 k_t: 0.0036568 M_global: 0.0319101\n",
      "step: 31000  d-loss: 0.0299408  g-loss: 0.0162303 k_t: 0.00246938 M_global: 0.0312207\n",
      "step: 32000  d-loss: 0.0300515  g-loss: 0.0144479 k_t: 0.00214363 M_global: 0.0306758\n",
      "step: 33000  d-loss: 0.0304843  g-loss: 0.0133888 k_t: 0.00357791 M_global: 0.0324095\n",
      "step: 34000  d-loss: 0.031473  g-loss: 0.0160472 k_t: 0.00431691 M_global: 0.0318183\n",
      "step: 35000  d-loss: 0.0292763  g-loss: 0.0161606 k_t: 0.00261334 M_global: 0.0308199\n",
      "step: 36000  d-loss: 0.0309453  g-loss: 0.0156018 k_t: 0.00287211 M_global: 0.0310969\n",
      "step: 37000  d-loss: 0.0298825  g-loss: 0.0126916 k_t: 0.00262536 M_global: 0.0321821\n",
      "step: 38000  d-loss: 0.0308433  g-loss: 0.0164099 k_t: 0.00288409 M_global: 0.0318552\n",
      "step: 39000  d-loss: 0.0308676  g-loss: 0.0148164 k_t: 0.00332221 M_global: 0.0315587\n",
      "step: 40000  d-loss: 0.0310951  g-loss: 0.0157457 k_t: 0.00290718 M_global: 0.0313161\n",
      "step: 41000  d-loss: 0.0302491  g-loss: 0.0111173 k_t: 0.00275463 M_global: 0.0343023\n",
      "step: 42000  d-loss: 0.0320089  g-loss: 0.0165339 k_t: 0.00401819 M_global: 0.0325716\n",
      "step: 43000  d-loss: 0.0307227  g-loss: 0.0145616 k_t: 0.00414816 M_global: 0.0316131\n",
      "step: 44000  d-loss: 0.0302126  g-loss: 0.0144344 k_t: 0.00410711 M_global: 0.0309733\n",
      "step: 45000  d-loss: 0.0304505  g-loss: 0.0159429 k_t: 0.00322932 M_global: 0.0311938\n",
      "step: 46000  d-loss: 0.0292778  g-loss: 0.0147921 k_t: 0.00288803 M_global: 0.0294524\n",
      "step: 47000  d-loss: 0.0302089  g-loss: 0.0102792 k_t: 0.00460949 M_global: 0.0351052\n",
      "step: 48000  d-loss: 0.0304661  g-loss: 0.00912728 k_t: 0.012456 M_global: 0.0367424\n",
      "step: 49000  d-loss: 0.0311227  g-loss: 0.00848623 k_t: 0.0187676 M_global: 0.0384368\n",
      "step: 50000  d-loss: 0.0323803  g-loss: 0.00638299 k_t: 0.0251632 M_global: 0.0424284\n",
      "step: 51000  d-loss: 0.0308143  g-loss: 0.00259162 k_t: 0.0351117 M_global: 0.0437663\n",
      "step: 52000  d-loss: 0.0295916  g-loss: 0.0937069 k_t: 0.00230244 M_global: 0.108611\n",
      "step: 53000  d-loss: 0.0318553  g-loss: 0.0421202 k_t: -0.000921669 M_global: 0.0580284\n",
      "step: 54000  d-loss: 0.0313179  g-loss: 0.0442691 k_t: -0.000182454 M_global: 0.059924\n",
      "step: 55000  d-loss: 0.0304912  g-loss: 0.0462324 k_t: -0.000172984 M_global: 0.061474\n",
      "step: 56000  d-loss: 0.0317595  g-loss: 0.0323417 k_t: -0.000963535 M_global: 0.0482058\n",
      "step: 57000  d-loss: 0.0318056  g-loss: 0.000719398 k_t: -0.000914702 M_global: 0.046988\n",
      "step: 58000  d-loss: 0.0315239  g-loss: 0.000396279 k_t: 0.000337448 M_global: 0.0468898\n",
      "step: 59000  d-loss: 0.0296527  g-loss: 0.0345636 k_t: 0.00135345 M_global: 0.0494133\n",
      "step: 60000  d-loss: 0.0298038  g-loss: 0.0118544 k_t: -0.00102624 M_global: 0.0328331\n",
      "step: 61000  d-loss: 0.0308955  g-loss: 0.000246376 k_t: 0.000690698 M_global: 0.0460972\n",
      "step: 62000  d-loss: 0.0305871  g-loss: 0.0420312 k_t: 0.000371368 M_global: 0.0573326\n",
      "step: 63000  d-loss: 0.0300104  g-loss: 0.00137734 k_t: -0.00041364 M_global: 0.0436374\n",
      "step: 64000  d-loss: 0.0310563  g-loss: 0.0393882 k_t: 0.000612327 M_global: 0.0549284\n",
      "step: 65000  d-loss: 0.0317121  g-loss: 0.0125983 k_t: -0.000899888 M_global: 0.0349528\n",
      "step: 66000  d-loss: 0.0320414  g-loss: 0.0 k_t: 0.000519528 M_global: 0.048062\n",
      "step: 67000  d-loss: 0.0303351  g-loss: 0.0383688 k_t: -0.000122382 M_global: 0.053534\n",
      "step: 68000  d-loss: 0.0310702  g-loss: 0.000254993 k_t: -0.000277881 M_global: 0.0463503\n",
      "step: 69000  d-loss: 0.0295542  g-loss: 0.0372531 k_t: 0.00102596 M_global: 0.0520493\n",
      "step: 70000  d-loss: 0.0304551  g-loss: 0.0252508 k_t: -0.000755031 M_global: 0.0404688\n",
      "step: 71000  d-loss: 0.0292799  g-loss: 0.0 k_t: 0.00029039 M_global: 0.0439199\n",
      "step: 72000  d-loss: 0.0317028  g-loss: 0.00379502 k_t: 0.00101663 M_global: 0.043765\n",
      "step: 73000  d-loss: 0.0298539  g-loss: 0.0313973 k_t: -0.000517405 M_global: 0.0463161\n",
      "step: 74000  d-loss: 0.031469  g-loss: 0.0 k_t: -0.000549957 M_global: 0.0472035\n",
      "step: 75000  d-loss: 0.0303683  g-loss: 0.0185356 k_t: 0.00114463 M_global: 0.0337304\n",
      "step: 76000  d-loss: 0.0313916  g-loss: 0.0226851 k_t: -0.000779806 M_global: 0.038372\n",
      "step: 77000  d-loss: 0.0296866  g-loss: 0.0 k_t: 0.000281491 M_global: 0.04453\n",
      "step: 78000  d-loss: 0.0308213  g-loss: 0.0 k_t: 9.95568e-05 M_global: 0.0462319\n",
      "step: 79000  d-loss: 0.0294815  g-loss: 0.000624049 k_t: 0.00108876 M_global: 0.0435992\n",
      "step: 80000  d-loss: 0.0318431  g-loss: 0.0381262 k_t: 0.0010081 M_global: 0.054067\n",
      "step: 81000  d-loss: 0.0309897  g-loss: 0.037922 k_t: 0.00042828 M_global: 0.053425\n",
      "step: 82000  d-loss: 0.0320211  g-loss: 0.000977947 k_t: -0.000669024 M_global: 0.0470527\n",
      "step: 83000  d-loss: 0.0311799  g-loss: 0.0 k_t: -0.000332697 M_global: 0.0467699\n",
      "step: 84000  d-loss: 0.0317426  g-loss: 0.0 k_t: 5.5284e-05 M_global: 0.0476139\n",
      "step: 85000  d-loss: 0.0303445  g-loss: 0.0 k_t: -5.99669e-05 M_global: 0.0455168\n",
      "step: 86000  d-loss: 0.0318187  g-loss: 0.0 k_t: 0.000640951 M_global: 0.0477281\n",
      "step: 87000  d-loss: 0.0314194  g-loss: 0.0375265 k_t: 0.0003993 M_global: 0.0532437\n",
      "step: 88000  d-loss: 0.0306265  g-loss: 0.0312967 k_t: -0.000581781 M_global: 0.0466008\n",
      "step: 89000  d-loss: 0.0301616  g-loss: 0.0315937 k_t: -0.000777215 M_global: 0.0466622\n",
      "step: 90000  d-loss: 0.0299954  g-loss: 0.0350136 k_t: -0.000315442 M_global: 0.0500058\n",
      "step: 91000  d-loss: 0.0303127  g-loss: 0.0323699 k_t: -0.000462929 M_global: 0.0475188\n",
      "step: 92000  d-loss: 0.0302987  g-loss: 0.0309278 k_t: -0.000750724 M_global: 0.0460655\n",
      "step: 93000  d-loss: 0.029694  g-loss: 0.037896 k_t: 0.000606235 M_global: 0.0527545\n",
      "step: 94000  d-loss: 0.0306608  g-loss: 0.0375797 k_t: 0.000380871 M_global: 0.0529172\n",
      "step: 95000  d-loss: 0.0307677  g-loss: 0.0296748 k_t: -0.00062303 M_global: 0.0450494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 96000  d-loss: 0.0297082  g-loss: 0.0363576 k_t: 0.00100751 M_global: 0.05123\n",
      "step: 97000  d-loss: 0.0295528  g-loss: 0.0376114 k_t: 0.000454865 M_global: 0.0523964\n",
      "step: 98000  d-loss: 0.0302055  g-loss: 1.40374e-05 k_t: 0.00086221 M_global: 0.0452943\n",
      "step: 99000  d-loss: 0.029992  g-loss: 0.0 k_t: 0.00144157 M_global: 0.044988\n",
      "step: 100000  d-loss: 0.0305125  g-loss: 8.62144e-07 k_t: -0.000211251 M_global: 0.0457679\n"
     ]
    }
   ],
   "source": [
    "for step in range(100001):\n",
    "    batch_x = mnist.train.next_batch(batch_size)[0]\n",
    "    z_D = sample_Z(batch_size, g_dim)\n",
    "    sess.run([d_optimizer, g_optimizer], feed_dict={x_d: batch_x, x_g: z_D})\n",
    "    z_G = sample_Z(batch_size, g_dim)\n",
    "    sess.run(g_optimizer, feed_dict={x_g: z_G})\n",
    "#     k_t = np.maximum(np.minimum(1., k_t + 0.001*(sess.run(balancer, feed_dict={x_d: batch_x, x_g: z_G}))), 0.)\n",
    "    sess.run(update_k, feed_dict={x_d: batch_x, x_g: z_G})\n",
    "    if step%1000==0:\n",
    "        d_loss_train, g_loss_train, k_tt, M_global_train = sess.run([d_loss, g_loss, k_t, M_global], feed_dict=\n",
    "                            {x_d: batch_x, x_g: sample_Z(batch_size, g_dim)})\n",
    "#         print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_t,\"M_global:\", M_global_train\n",
    "        print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_tt,\"M_global:\", M_global_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAD8CAYAAADOg5fGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1b5ae60950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gg = sess.run(g_sample, feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(g_sample), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(decoder(x_g), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(x_d), feed_dict = {x_d: x_train})\n",
    "gg_pic = np.array([np.reshape(m,(28,28)) for m in gg])\n",
    "fig, ax = plt.subplots(nrows=3, ncols=3)\n",
    "for i,row in enumerate(ax):\n",
    "    for j,col in enumerate(row):\n",
    "        ax[i][j].imshow(gg_pic[i*3+j], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0  d-loss: 0.0302666  g-loss: 3.32747e-05 k_t: -0.000196151 M_global: 0.0453666\n",
      "step: 1000  d-loss: 0.030076  g-loss: 0.0 k_t: -0.000212417 M_global: 0.0451141\n",
      "step: 2000  d-loss: 0.0304685  g-loss: 0.0357063 k_t: -0.000165151 M_global: 0.0509376\n",
      "step: 3000  d-loss: 0.0288192  g-loss: 0.0137574 k_t: 0.00130985 M_global: 0.0294984\n",
      "step: 4000  d-loss: 0.028956  g-loss: 0.0371196 k_t: 0.000855876 M_global: 0.0516135\n",
      "step: 5000  d-loss: 0.0296152  g-loss: 0.0 k_t: 0.0017007 M_global: 0.0444228\n",
      "step: 6000  d-loss: 0.0291948  g-loss: 0.0188446 k_t: -0.00104597 M_global: 0.0334322\n",
      "step: 7000  d-loss: 0.0294825  g-loss: 0.0102495 k_t: -0.00103003 M_global: 0.0339584\n",
      "step: 8000  d-loss: 0.0293925  g-loss: 0.032814 k_t: -0.000347795 M_global: 0.0475046\n",
      "step: 9000  d-loss: 0.0315898  g-loss: 3.93555e-05 k_t: 0.00210848 M_global: 0.0473454\n",
      "step: 10000  d-loss: 0.0290327  g-loss: 0.0359668 k_t: -0.000188326 M_global: 0.0504798\n",
      "step: 11000  d-loss: 0.0303848  g-loss: 0.0363901 k_t: 0.00067783 M_global: 0.0515948\n",
      "step: 12000  d-loss: 0.0289879  g-loss: 0.000418192 k_t: -0.00127336 M_global: 0.0430628\n",
      "step: 13000  d-loss: 0.0300718  g-loss: 0.0323686 k_t: 0.00132722 M_global: 0.047426\n",
      "step: 14000  d-loss: 0.0307298  g-loss: 0.0 k_t: 0.00117212 M_global: 0.0460946\n",
      "step: 15000  d-loss: 0.0296681  g-loss: 0.0148493 k_t: -0.00105167 M_global: 0.0296755\n",
      "step: 16000  d-loss: 0.0304059  g-loss: 0.0376773 k_t: 0.000823509 M_global: 0.0528957\n",
      "step: 17000  d-loss: 0.0292474  g-loss: 0.0 k_t: -0.000583199 M_global: 0.0438711\n",
      "step: 18000  d-loss: 0.0293184  g-loss: 0.0259463 k_t: -0.00106902 M_global: 0.0405917\n",
      "step: 19000  d-loss: 0.0300874  g-loss: 0.0363374 k_t: 0.000443523 M_global: 0.0513891\n",
      "step: 20000  d-loss: 0.0305651  g-loss: 0.0 k_t: 0.000309928 M_global: 0.0458476\n",
      "step: 21000  d-loss: 0.0306486  g-loss: 2.52656e-05 k_t: 0.000693632 M_global: 0.0459477\n",
      "step: 22000  d-loss: 0.0302826  g-loss: 0.0319286 k_t: -0.000529931 M_global: 0.0470614\n",
      "step: 23000  d-loss: 0.0297569  g-loss: 0.00845734 k_t: 0.00230671 M_global: 0.0362072\n",
      "step: 24000  d-loss: 0.0295291  g-loss: 0.00031037 k_t: -0.00076732 M_global: 0.0439829\n",
      "step: 25000  d-loss: 0.0314702  g-loss: 0.0137618 k_t: -0.00112635 M_global: 0.0334201\n",
      "step: 26000  d-loss: 0.0310706  g-loss: 0.0384355 k_t: 0.000626756 M_global: 0.0539828\n",
      "step: 27000  d-loss: 0.0318591  g-loss: 0.0 k_t: -0.00101064 M_global: 0.0477887\n",
      "step: 28000  d-loss: 0.0297139  g-loss: 0.0 k_t: 0.000229083 M_global: 0.0445709\n",
      "step: 29000  d-loss: 0.0290555  g-loss: 0.028287 k_t: 0.00188504 M_global: 0.0428414\n",
      "step: 30000  d-loss: 0.0287262  g-loss: 0.0 k_t: -0.000120673 M_global: 0.0430893\n",
      "step: 31000  d-loss: 0.0307006  g-loss: 0.0358275 k_t: 4.2914e-05 M_global: 0.0511785\n",
      "step: 32000  d-loss: 0.0293939  g-loss: 7.18462e-06 k_t: 0.00119377 M_global: 0.0440837\n",
      "step: 33000  d-loss: 0.0284991  g-loss: 0.0 k_t: -0.000284293 M_global: 0.0427486\n",
      "step: 34000  d-loss: 0.0290151  g-loss: 0.032117 k_t: -0.000662394 M_global: 0.0466139\n",
      "step: 35000  d-loss: 0.02845  g-loss: 0.0 k_t: 0.00070067 M_global: 0.042675\n",
      "step: 36000  d-loss: 0.0293452  g-loss: 0.034637 k_t: -0.000169839 M_global: 0.0493066\n",
      "step: 37000  d-loss: 0.0297192  g-loss: 0.0 k_t: -0.000903434 M_global: 0.0445787\n",
      "step: 38000  d-loss: 0.0305688  g-loss: 0.0339229 k_t: 0.00107735 M_global: 0.0492255\n",
      "step: 39000  d-loss: 0.0300033  g-loss: 0.0 k_t: 0.000311886 M_global: 0.0450049\n",
      "step: 40000  d-loss: 0.0301239  g-loss: 0.0319399 k_t: 0.00204494 M_global: 0.0470345\n",
      "step: 41000  d-loss: 0.0289942  g-loss: 0.0213479 k_t: -0.00132622 M_global: 0.0358308\n",
      "step: 42000  d-loss: 0.0309308  g-loss: 0.0 k_t: 0.00106205 M_global: 0.0463961\n",
      "step: 43000  d-loss: 0.0294935  g-loss: 0.0360763 k_t: 0.000348407 M_global: 0.0508294\n",
      "step: 44000  d-loss: 0.0291966  g-loss: 0.0125785 k_t: -0.00122361 M_global: 0.0311933\n",
      "step: 45000  d-loss: 0.029193  g-loss: 0.0 k_t: -9.82779e-06 M_global: 0.0437895\n",
      "step: 46000  d-loss: 0.0285099  g-loss: 0.0281319 k_t: -0.000721737 M_global: 0.0423767\n",
      "step: 47000  d-loss: 0.0292171  g-loss: 0.00724065 k_t: 0.00171947 M_global: 0.0366037\n",
      "step: 48000  d-loss: 0.0292407  g-loss: 0.0135084 k_t: -0.00131629 M_global: 0.030326\n",
      "step: 49000  d-loss: 0.0279056  g-loss: 0.0 k_t: -0.000891358 M_global: 0.0418583\n",
      "step: 50000  d-loss: 0.0309137  g-loss: 0.0336712 k_t: -0.000540882 M_global: 0.049119\n",
      "step: 51000  d-loss: 0.028026  g-loss: 0.0 k_t: 0.000949338 M_global: 0.0420389\n",
      "step: 52000  d-loss: 0.0286299  g-loss: 0.0362901 k_t: 0.000874939 M_global: 0.0506209\n",
      "step: 53000  d-loss: 0.0287179  g-loss: 0.0356866 k_t: 0.000107606 M_global: 0.0500475\n",
      "step: 54000  d-loss: 0.0292462  g-loss: 0.0 k_t: -0.000571967 M_global: 0.0438693\n",
      "step: 55000  d-loss: 0.0287249  g-loss: 0.0215682 k_t: -0.00141065 M_global: 0.0359155\n",
      "step: 56000  d-loss: 0.0299784  g-loss: 0.0 k_t: 0.000381862 M_global: 0.0449676\n",
      "step: 57000  d-loss: 0.0298289  g-loss: 0.0 k_t: 0.000167318 M_global: 0.0447433\n",
      "step: 58000  d-loss: 0.0283918  g-loss: 0.0325178 k_t: 0.00152191 M_global: 0.0467384\n",
      "step: 59000  d-loss: 0.0276639  g-loss: 0.0360312 k_t: 0.000505934 M_global: 0.0498722\n",
      "step: 60000  d-loss: 0.0288719  g-loss: 0.0364066 k_t: 0.00178797 M_global: 0.0508751\n",
      "step: 61000  d-loss: 0.029411  g-loss: 0.0283118 k_t: -0.0012007 M_global: 0.0430003\n",
      "step: 62000  d-loss: 0.0281022  g-loss: 0.0 k_t: 4.08811e-05 M_global: 0.0421533\n",
      "step: 63000  d-loss: 0.0287502  g-loss: 0.0359043 k_t: 0.00169919 M_global: 0.0503099\n",
      "step: 64000  d-loss: 0.0288514  g-loss: 0.0302003 k_t: -0.000966731 M_global: 0.0446114\n",
      "step: 65000  d-loss: 0.0281391  g-loss: 0.0 k_t: 0.000502729 M_global: 0.0422087\n",
      "step: 66000  d-loss: 0.029044  g-loss: 0.0329498 k_t: 0.00155436 M_global: 0.0474974\n",
      "step: 67000  d-loss: 0.0284825  g-loss: 0.0 k_t: -0.00127666 M_global: 0.0427238\n",
      "step: 68000  d-loss: 0.0283996  g-loss: 0.0 k_t: -0.00107109 M_global: 0.0425995\n",
      "step: 69000  d-loss: 0.0277273  g-loss: 0.0 k_t: -0.000977844 M_global: 0.0415909\n",
      "step: 70000  d-loss: 0.0291727  g-loss: 0.0 k_t: 0.00097093 M_global: 0.0437591\n",
      "step: 71000  d-loss: 0.0279168  g-loss: 0.0225258 k_t: -0.0013099 M_global: 0.0364694\n",
      "step: 72000  d-loss: 0.0281398  g-loss: 5.72671e-05 k_t: -0.00132666 M_global: 0.0421523\n",
      "step: 73000  d-loss: 0.0281028  g-loss: 0.0 k_t: -0.0010872 M_global: 0.0421541\n",
      "step: 74000  d-loss: 0.0280841  g-loss: 0.0 k_t: 0.000125269 M_global: 0.0421261\n",
      "step: 75000  d-loss: 0.0289152  g-loss: 0.00797312 k_t: 0.0023715 M_global: 0.035428\n",
      "step: 76000  d-loss: 0.0289195  g-loss: 0.0289189 k_t: 0.00160452 M_global: 0.0434018\n",
      "step: 77000  d-loss: 0.0278696  g-loss: 0.000286915 k_t: 0.00106981 M_global: 0.041518\n",
      "step: 78000  d-loss: 0.0278721  g-loss: 0.04178 k_t: 0.000602703 M_global: 0.0557287\n",
      "step: 79000  d-loss: 0.0284932  g-loss: 0.000566574 k_t: 0.00185688 M_global: 0.0421749\n",
      "step: 80000  d-loss: 0.0292405  g-loss: 0.0087666 k_t: -0.00134753 M_global: 0.0350765\n",
      "step: 81000  d-loss: 0.0273022  g-loss: 0.025725 k_t: -0.00153026 M_global: 0.0393565\n",
      "step: 82000  d-loss: 0.0282162  g-loss: 0.0 k_t: -0.000774711 M_global: 0.0423243\n",
      "step: 83000  d-loss: 0.0294109  g-loss: 0.0 k_t: -0.00139682 M_global: 0.0441163\n",
      "step: 84000  d-loss: 0.0283499  g-loss: 0.0 k_t: -0.000338462 M_global: 0.0425249\n",
      "step: 85000  d-loss: 0.0277469  g-loss: 0.04672 k_t: 0.00642351 M_global: 0.0607435\n",
      "step: 86000  d-loss: 0.0276824  g-loss: 0.0313103 k_t: 0.000916242 M_global: 0.0451659\n",
      "step: 87000  d-loss: 0.0262192  g-loss: 0.0 k_t: -0.00138256 M_global: 0.0393289\n",
      "step: 88000  d-loss: 0.0286912  g-loss: 0.0362224 k_t: -0.00108293 M_global: 0.0505484\n",
      "step: 89000  d-loss: 0.026745  g-loss: 0.0405723 k_t: 0.00162683 M_global: 0.0539778\n",
      "step: 90000  d-loss: 0.0289311  g-loss: 0.024818 k_t: 0.00251974 M_global: 0.0393148\n",
      "step: 91000  d-loss: 0.0271719  g-loss: 0.0090027 k_t: 0.00185153 M_global: 0.0317801\n",
      "step: 92000  d-loss: 0.0286522  g-loss: 0.0 k_t: 0.00099922 M_global: 0.0429784\n",
      "step: 93000  d-loss: 0.0282981  g-loss: 0.0 k_t: -0.000360158 M_global: 0.0424471\n",
      "step: 94000  d-loss: 0.027133  g-loss: 0.0 k_t: 0.000786011 M_global: 0.0406994\n",
      "step: 95000  d-loss: 0.0282252  g-loss: 0.0 k_t: -0.000710784 M_global: 0.0423378\n",
      "step: 96000  d-loss: 0.0282041  g-loss: 0.0 k_t: -0.000503346 M_global: 0.0423062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 97000  d-loss: 0.027872  g-loss: 0.0 k_t: -0.0010185 M_global: 0.041808\n",
      "step: 98000  d-loss: 0.0278294  g-loss: 0.0 k_t: -0.00053671 M_global: 0.0417441\n",
      "step: 99000  d-loss: 0.0276932  g-loss: 0.0 k_t: -0.00148112 M_global: 0.0415398\n",
      "step: 100000  d-loss: 0.0272787  g-loss: 0.0374983 k_t: -0.000812262 M_global: 0.0511224\n"
     ]
    }
   ],
   "source": [
    "for step in range(100001):\n",
    "    batch_x = mnist.train.next_batch(batch_size)[0]\n",
    "    z_D = sample_Z(batch_size, g_dim)\n",
    "    sess.run([d_optimizer, g_optimizer], feed_dict={x_d: batch_x, x_g: z_D})\n",
    "    z_G = sample_Z(batch_size, g_dim)\n",
    "    sess.run(g_optimizer, feed_dict={x_g: z_G})\n",
    "#     k_t = np.maximum(np.minimum(1., k_t + 0.001*(sess.run(balancer, feed_dict={x_d: batch_x, x_g: z_G}))), 0.)\n",
    "    sess.run(update_k, feed_dict={x_d: batch_x, x_g: z_G})\n",
    "    if step%1000==0:\n",
    "        d_loss_train, g_loss_train, k_tt, M_global_train = sess.run([d_loss, g_loss, k_t, M_global], feed_dict=\n",
    "                            {x_d: batch_x, x_g: sample_Z(batch_size, g_dim)})\n",
    "#         print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_t,\"M_global:\", M_global_train\n",
    "        print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_tt,\"M_global:\", M_global_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAD8CAYAAADOg5fGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1b5a25cc90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gg = sess.run(g_sample, feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(g_sample), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(decoder(x_g), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(x_d), feed_dict = {x_d: x_train})\n",
    "gg_pic = np.array([np.reshape(m,(28,28)) for m in gg])\n",
    "fig, ax = plt.subplots(nrows=3, ncols=3)\n",
    "for i,row in enumerate(ax):\n",
    "    for j,col in enumerate(row):\n",
    "        ax[i][j].imshow(gg_pic[i*3+j], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0  d-loss: 0.028183  g-loss: 0.0370366 k_t: -0.000835222 M_global: 0.0511126\n",
      "step: 1000  d-loss: 0.027264  g-loss: 0.025989 k_t: -0.00173008 M_global: 0.0395985\n",
      "step: 2000  d-loss: 0.0287475  g-loss: 0.0 k_t: -0.00147514 M_global: 0.0431212\n",
      "step: 3000  d-loss: 0.0281996  g-loss: 0.0297466 k_t: 0.000601366 M_global: 0.0438554\n",
      "step: 4000  d-loss: 0.0269658  g-loss: 0.0271674 k_t: -0.001614 M_global: 0.0406284\n",
      "step: 5000  d-loss: 0.027706  g-loss: 0.0389232 k_t: -7.57431e-06 M_global: 0.052776\n",
      "step: 6000  d-loss: 0.0285723  g-loss: 0.031883 k_t: 0.00182798 M_global: 0.0461983\n",
      "step: 7000  d-loss: 0.0284994  g-loss: 0.041886 k_t: 0.000421054 M_global: 0.0561445\n",
      "step: 8000  d-loss: 0.0275893  g-loss: 0.000112811 k_t: 0.00226066 M_global: 0.0412716\n",
      "step: 9000  d-loss: 0.0272828  g-loss: 5.38603e-05 k_t: 0.00107521 M_global: 0.0408705\n",
      "step: 10000  d-loss: 0.0273722  g-loss: 0.00750861 k_t: 0.00199594 M_global: 0.0335722\n",
      "step: 11000  d-loss: 0.0283885  g-loss: 0.0408211 k_t: 0.000131002 M_global: 0.055018\n",
      "step: 12000  d-loss: 0.0280382  g-loss: 0.0 k_t: -0.000310011 M_global: 0.0420574\n",
      "step: 13000  d-loss: 0.0271422  g-loss: 0.0 k_t: 0.00189195 M_global: 0.0407134\n",
      "step: 14000  d-loss: 0.0289036  g-loss: 0.0270174 k_t: -0.0010577 M_global: 0.0414549\n",
      "step: 15000  d-loss: 0.028074  g-loss: 0.0 k_t: 0.00175336 M_global: 0.042111\n",
      "step: 16000  d-loss: 0.0284468  g-loss: 0.0 k_t: 0.000911632 M_global: 0.0426702\n",
      "step: 17000  d-loss: 0.0291293  g-loss: 0.0 k_t: -0.00105946 M_global: 0.043694\n",
      "step: 18000  d-loss: 0.0291973  g-loss: 0.0 k_t: -5.44807e-05 M_global: 0.043796\n",
      "step: 19000  d-loss: 0.0271448  g-loss: 8.25644e-05 k_t: 0.000275446 M_global: 0.0406346\n",
      "step: 20000  d-loss: 0.0260307  g-loss: 0.0246578 k_t: 0.00218832 M_global: 0.0377001\n",
      "step: 21000  d-loss: 0.0271186  g-loss: 0.0396859 k_t: 0.000274155 M_global: 0.0532507\n",
      "step: 22000  d-loss: 0.0275634  g-loss: 0.0 k_t: -0.000426011 M_global: 0.0413452\n",
      "step: 23000  d-loss: 0.0281452  g-loss: 0.0 k_t: 0.00021008 M_global: 0.0422179\n",
      "step: 24000  d-loss: 0.0273295  g-loss: 0.000308362 k_t: 0.000386132 M_global: 0.0406861\n",
      "step: 25000  d-loss: 0.0283735  g-loss: 0.00149457 k_t: -0.00123138 M_global: 0.0410629\n",
      "step: 26000  d-loss: 0.0263371  g-loss: 0.0 k_t: -0.00138186 M_global: 0.0395057\n",
      "step: 27000  d-loss: 0.0267464  g-loss: 0.0403797 k_t: 0.00193345 M_global: 0.053792\n",
      "step: 28000  d-loss: 0.0274152  g-loss: 0.0 k_t: 0.00291007 M_global: 0.0411229\n",
      "step: 29000  d-loss: 0.0272441  g-loss: 0.0 k_t: 0.00152602 M_global: 0.0408661\n",
      "step: 30000  d-loss: 0.0268536  g-loss: 0.0 k_t: 0.00179014 M_global: 0.0402804\n",
      "step: 31000  d-loss: 0.0284979  g-loss: 0.022612 k_t: -0.00136843 M_global: 0.0368454\n",
      "step: 32000  d-loss: 0.0270157  g-loss: 0.0410221 k_t: 0.00221251 M_global: 0.0545754\n",
      "step: 33000  d-loss: 0.0270995  g-loss: 0.0399245 k_t: 0.00143008 M_global: 0.0535027\n",
      "step: 34000  d-loss: 0.0279985  g-loss: 0.0128918 k_t: 0.00257831 M_global: 0.0291559\n",
      "step: 35000  d-loss: 0.0266586  g-loss: 0.0103235 k_t: -0.00200322 M_global: 0.0296334\n",
      "step: 36000  d-loss: 0.0282618  g-loss: 0.0 k_t: -0.000309247 M_global: 0.0423927\n",
      "step: 37000  d-loss: 0.0270542  g-loss: 0.0326801 k_t: -0.000785479 M_global: 0.0461944\n",
      "step: 38000  d-loss: 0.0267273  g-loss: 0.0409523 k_t: 0.00202232 M_global: 0.0543573\n",
      "step: 39000  d-loss: 0.0272877  g-loss: 0.0279664 k_t: 0.00238551 M_global: 0.0416436\n",
      "step: 40000  d-loss: 0.0267341  g-loss: 0.039185 k_t: 0.0002582 M_global: 0.0525571\n",
      "step: 41000  d-loss: 0.0269303  g-loss: 0.0 k_t: -0.000832244 M_global: 0.0403954\n",
      "step: 42000  d-loss: 0.027209  g-loss: 0.0 k_t: 0.00098168 M_global: 0.0408135\n",
      "step: 43000  d-loss: 0.027384  g-loss: 0.0382268 k_t: 8.05452e-06 M_global: 0.051919\n",
      "step: 44000  d-loss: 0.0275388  g-loss: 0.0213563 k_t: -0.00168473 M_global: 0.0351077\n",
      "step: 45000  d-loss: 0.0279664  g-loss: 0.036922 k_t: -0.000111816 M_global: 0.0509031\n",
      "step: 46000  d-loss: 0.0279576  g-loss: 0.0 k_t: -0.00012171 M_global: 0.0419364\n",
      "step: 47000  d-loss: 0.0271879  g-loss: 0.0334359 k_t: -0.00136455 M_global: 0.0470071\n",
      "step: 48000  d-loss: 0.0265631  g-loss: 0.0 k_t: 0.0036038 M_global: 0.0398446\n",
      "step: 49000  d-loss: 0.0281885  g-loss: 0.0 k_t: -0.00077973 M_global: 0.0422828\n",
      "step: 50000  d-loss: 0.026526  g-loss: 0.036134 k_t: -0.000610585 M_global: 0.049386\n",
      "step: 51000  d-loss: 0.0274841  g-loss: 0.0377054 k_t: 0.00239361 M_global: 0.0514925\n",
      "step: 52000  d-loss: 0.0283618  g-loss: 0.0 k_t: -9.80096e-05 M_global: 0.0425427\n",
      "step: 53000  d-loss: 0.0268945  g-loss: 0.0 k_t: 0.000762613 M_global: 0.0403417\n",
      "step: 54000  d-loss: 0.0280835  g-loss: 0.038033 k_t: -1.50872e-05 M_global: 0.0520744\n",
      "step: 55000  d-loss: 0.0281563  g-loss: 0.0 k_t: 0.000538267 M_global: 0.0422345\n",
      "step: 56000  d-loss: 0.0270839  g-loss: 0.0 k_t: -0.00178492 M_global: 0.0406258\n",
      "step: 57000  d-loss: 0.0273024  g-loss: 0.0279369 k_t: -0.000712224 M_global: 0.0415781\n",
      "step: 58000  d-loss: 0.0270954  g-loss: 0.0392551 k_t: 0.00114156 M_global: 0.0528252\n",
      "step: 59000  d-loss: 0.0276253  g-loss: 0.0 k_t: 0.000934441 M_global: 0.041438\n",
      "step: 60000  d-loss: 0.0269552  g-loss: 0.0414866 k_t: 0.00514457 M_global: 0.0550709\n",
      "step: 61000  d-loss: 0.0279559  g-loss: 0.0270835 k_t: 0.000559118 M_global: 0.0410691\n",
      "step: 62000  d-loss: 0.0253924  g-loss: 0.0383058 k_t: 0.000714286 M_global: 0.0510157\n",
      "step: 63000  d-loss: 0.0273064  g-loss: 0.0 k_t: 0.00158329 M_global: 0.0409596\n",
      "step: 64000  d-loss: 0.0274698  g-loss: 0.0 k_t: -0.00100742 M_global: 0.0412047\n",
      "step: 65000  d-loss: 0.0273803  g-loss: 0.029292 k_t: 0.00145583 M_global: 0.0430035\n",
      "step: 66000  d-loss: 0.0274345  g-loss: 0.0 k_t: 0.00130092 M_global: 0.0411517\n",
      "step: 67000  d-loss: 0.0269311  g-loss: 0.0 k_t: -0.00136739 M_global: 0.0403967\n",
      "step: 68000  d-loss: 0.0265125  g-loss: 0.0 k_t: -0.00130786 M_global: 0.0397687\n",
      "step: 69000  d-loss: 0.0265544  g-loss: 0.0 k_t: 0.000473983 M_global: 0.0398315\n",
      "step: 70000  d-loss: 0.0262528  g-loss: 0.0 k_t: 0.00542785 M_global: 0.0393792\n",
      "step: 71000  d-loss: 0.0274931  g-loss: 0.0 k_t: 0.000156919 M_global: 0.0412396\n",
      "step: 72000  d-loss: 0.0273132  g-loss: 0.0 k_t: -0.0018949 M_global: 0.0409698\n",
      "step: 73000  d-loss: 0.0280293  g-loss: 0.0 k_t: 0.0115576 M_global: 0.042044\n",
      "step: 74000  d-loss: 0.0265217  g-loss: 0.0244264 k_t: -0.000847114 M_global: 0.0376769\n",
      "step: 75000  d-loss: 0.0264683  g-loss: 0.029822 k_t: 0.000433305 M_global: 0.0430626\n",
      "step: 76000  d-loss: 0.0261686  g-loss: 0.0 k_t: 0.00288279 M_global: 0.0392529\n",
      "step: 77000  d-loss: 0.0281209  g-loss: 0.0299378 k_t: -0.00158917 M_global: 0.0439745\n",
      "step: 78000  d-loss: 0.0270544  g-loss: 0.0370898 k_t: -0.000250259 M_global: 0.0506123\n",
      "step: 79000  d-loss: 0.0266381  g-loss: 0.0 k_t: -0.00053114 M_global: 0.0399572\n",
      "step: 80000  d-loss: 0.026318  g-loss: 0.0378647 k_t: 0.000178529 M_global: 0.0510271\n",
      "step: 81000  d-loss: 0.0264189  g-loss: 0.021652 k_t: -0.00246494 M_global: 0.0348347\n",
      "step: 82000  d-loss: 0.0282285  g-loss: 0.0 k_t: 1.38748e-05 M_global: 0.0423427\n",
      "step: 83000  d-loss: 0.027054  g-loss: 0.0385213 k_t: 0.00236105 M_global: 0.0520938\n",
      "step: 84000  d-loss: 0.0271018  g-loss: 0.0 k_t: 0.00173558 M_global: 0.0406527\n",
      "step: 85000  d-loss: 0.0273959  g-loss: 0.0268211 k_t: -0.00162605 M_global: 0.0404972\n",
      "step: 86000  d-loss: 0.0261934  g-loss: 0.0393537 k_t: 0.00218101 M_global: 0.0524933\n",
      "step: 87000  d-loss: 0.0268689  g-loss: 0.010718 k_t: -0.00207554 M_global: 0.0295521\n",
      "step: 88000  d-loss: 0.0267276  g-loss: 0.0 k_t: 0.00355596 M_global: 0.0400913\n",
      "step: 89000  d-loss: 0.0268188  g-loss: 0.0 k_t: -0.000768361 M_global: 0.0402282\n",
      "step: 90000  d-loss: 0.0261807  g-loss: 0.0276666 k_t: 0.00456329 M_global: 0.04082\n",
      "step: 91000  d-loss: 0.0277443  g-loss: 0.0 k_t: -0.000196144 M_global: 0.0416164\n",
      "step: 92000  d-loss: 0.0279918  g-loss: 0.0346557 k_t: 0.00172189 M_global: 0.0486814\n",
      "step: 93000  d-loss: 0.0276733  g-loss: 0.0 k_t: 0.00114563 M_global: 0.0415099\n",
      "step: 94000  d-loss: 0.0261441  g-loss: 0.0263963 k_t: -0.00241466 M_global: 0.0394365\n",
      "step: 95000  d-loss: 0.0262781  g-loss: 0.0 k_t: 0.000229154 M_global: 0.0394171\n",
      "step: 96000  d-loss: 0.0270613  g-loss: 0.0150657 k_t: -0.00209894 M_global: 0.0285805\n",
      "step: 97000  d-loss: 0.0264904  g-loss: 0.0 k_t: 8.50794e-05 M_global: 0.0397357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 98000  d-loss: 0.0264299  g-loss: 0.0 k_t: -0.0013582 M_global: 0.0396449\n",
      "step: 99000  d-loss: 0.026554  g-loss: 0.0 k_t: 0.000287094 M_global: 0.0398309\n",
      "step: 100000  d-loss: 0.0270775  g-loss: 0.0376752 k_t: -0.000146524 M_global: 0.0512111\n"
     ]
    }
   ],
   "source": [
    "for step in range(100001):\n",
    "    batch_x = mnist.train.next_batch(batch_size)[0]\n",
    "    z_D = sample_Z(batch_size, g_dim)\n",
    "    sess.run([d_optimizer, g_optimizer], feed_dict={x_d: batch_x, x_g: z_D})\n",
    "    z_G = sample_Z(batch_size, g_dim)\n",
    "    sess.run(g_optimizer, feed_dict={x_g: z_G})\n",
    "#     k_t = np.maximum(np.minimum(1., k_t + 0.001*(sess.run(balancer, feed_dict={x_d: batch_x, x_g: z_G}))), 0.)\n",
    "    sess.run(update_k, feed_dict={x_d: batch_x, x_g: z_G})\n",
    "    if step%1000==0:\n",
    "        d_loss_train, g_loss_train, k_tt, M_global_train = sess.run([d_loss, g_loss, k_t, M_global], feed_dict=\n",
    "                            {x_d: batch_x, x_g: sample_Z(batch_size, g_dim)})\n",
    "#         print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_t,\"M_global:\", M_global_train\n",
    "        print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_tt,\"M_global:\", M_global_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAD8CAYAAADOg5fGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1b5abc0b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gg = sess.run(g_sample, feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(g_sample), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(decoder(x_g), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(x_d), feed_dict = {x_d: x_train})\n",
    "gg_pic = np.array([np.reshape(m,(28,28)) for m in gg])\n",
    "fig, ax = plt.subplots(nrows=3, ncols=3)\n",
    "for i,row in enumerate(ax):\n",
    "    for j,col in enumerate(row):\n",
    "        ax[i][j].imshow(gg_pic[i*3+j], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0  d-loss: 0.0258801  g-loss: 0.0374464 k_t: -0.000171034 M_global: 0.0503832\n",
      "step: 1000  d-loss: 0.0282302  g-loss: 0.0352172 k_t: -0.000562854 M_global: 0.0493224\n",
      "step: 2000  d-loss: 0.0277262  g-loss: 0.0020884 k_t: -0.00203683 M_global: 0.0394945\n",
      "step: 3000  d-loss: 0.0270318  g-loss: 0.0 k_t: 9.04852e-05 M_global: 0.0405476\n",
      "step: 4000  d-loss: 0.0269525  g-loss: 0.0380462 k_t: 0.00336595 M_global: 0.0515864\n",
      "step: 5000  d-loss: 0.0264395  g-loss: 0.00576342 k_t: -0.00211548 M_global: 0.0338775\n",
      "step: 6000  d-loss: 0.026651  g-loss: 0.0380733 k_t: 0.00235965 M_global: 0.0514437\n",
      "step: 7000  d-loss: 0.0255438  g-loss: 0.0 k_t: -0.00163333 M_global: 0.0383157\n",
      "step: 8000  d-loss: 0.0267887  g-loss: 0.0354036 k_t: -0.000486698 M_global: 0.0487894\n",
      "step: 9000  d-loss: 0.0273751  g-loss: 0.0 k_t: -2.15252e-07 M_global: 0.0410627\n",
      "step: 10000  d-loss: 0.0271008  g-loss: 0.0358643 k_t: -8.67419e-05 M_global: 0.0494131\n",
      "step: 11000  d-loss: 0.0269081  g-loss: 0.0 k_t: -0.000195642 M_global: 0.0403622\n",
      "step: 12000  d-loss: 0.0267891  g-loss: 0.0 k_t: 0.00163448 M_global: 0.0401837\n",
      "step: 13000  d-loss: 0.0261917  g-loss: 0.0 k_t: -0.00174561 M_global: 0.0392875\n",
      "step: 14000  d-loss: 0.027547  g-loss: 0.0 k_t: 0.000854264 M_global: 0.0413206\n",
      "step: 15000  d-loss: 0.0262152  g-loss: 0.0380811 k_t: 0.0043555 M_global: 0.0512717\n",
      "step: 16000  d-loss: 0.0273  g-loss: 0.0 k_t: 0.000417157 M_global: 0.04095\n",
      "step: 17000  d-loss: 0.0262332  g-loss: 0.023076 k_t: -0.00196647 M_global: 0.0361699\n",
      "step: 18000  d-loss: 0.0270925  g-loss: 0.0 k_t: 0.0106393 M_global: 0.0406388\n",
      "step: 19000  d-loss: 0.0277289  g-loss: 0.0154443 k_t: 0.000785007 M_global: 0.0293148\n",
      "step: 20000  d-loss: 0.0262228  g-loss: 0.0223989 k_t: 0.000885446 M_global: 0.0355202\n",
      "step: 21000  d-loss: 0.0278816  g-loss: 0.0355645 k_t: 0.000334146 M_global: 0.0495112\n",
      "step: 22000  d-loss: 0.0265791  g-loss: 0.0280198 k_t: -0.00196718 M_global: 0.0412818\n",
      "step: 23000  d-loss: 0.0268963  g-loss: 0.0 k_t: -0.000913149 M_global: 0.0403445\n",
      "step: 24000  d-loss: 0.0250476  g-loss: 0.0 k_t: 0.00268858 M_global: 0.0375714\n",
      "step: 25000  d-loss: 0.0256456  g-loss: 0.0361049 k_t: 0.000725455 M_global: 0.0489408\n",
      "step: 26000  d-loss: 0.0265964  g-loss: 0.0 k_t: 9.70725e-05 M_global: 0.0398946\n",
      "step: 27000  d-loss: 0.0263592  g-loss: 0.0382119 k_t: 0.00537435 M_global: 0.0514943\n",
      "step: 28000  d-loss: 0.0268536  g-loss: 0.0 k_t: 0.000432661 M_global: 0.0402804\n",
      "step: 29000  d-loss: 0.0261575  g-loss: 0.025311 k_t: -0.00178494 M_global: 0.0383671\n",
      "step: 30000  d-loss: 0.026898  g-loss: 0.0264894 k_t: 0.000894137 M_global: 0.0399503\n",
      "step: 31000  d-loss: 0.0258033  g-loss: 0.00103965 k_t: -0.00244765 M_global: 0.0376614\n",
      "step: 32000  d-loss: 0.0257084  g-loss: 0.0 k_t: 0.00225394 M_global: 0.0385626\n",
      "step: 33000  d-loss: 0.0261615  g-loss: 0.0363555 k_t: 0.00246996 M_global: 0.0494812\n",
      "step: 34000  d-loss: 0.0252875  g-loss: 0.0 k_t: 0.000985903 M_global: 0.0379312\n",
      "step: 35000  d-loss: 0.025836  g-loss: 0.0 k_t: 0.00472186 M_global: 0.038754\n",
      "step: 36000  d-loss: 0.0259601  g-loss: 0.000370149 k_t: 0.000584758 M_global: 0.0385703\n",
      "step: 37000  d-loss: 0.0264783  g-loss: 0.0017407 k_t: 0.00345535 M_global: 0.0379858\n",
      "step: 38000  d-loss: 0.0261683  g-loss: 0.0 k_t: 0.0068174 M_global: 0.0392525\n",
      "step: 39000  d-loss: 0.0267238  g-loss: 0.0161665 k_t: -0.000702063 M_global: 0.0295227\n",
      "step: 40000  d-loss: 0.0271385  g-loss: 0.0244009 k_t: 0.00123057 M_global: 0.0379851\n",
      "step: 41000  d-loss: 0.0253257  g-loss: 0.0180244 k_t: -0.00217754 M_global: 0.0306677\n",
      "step: 42000  d-loss: 0.0260752  g-loss: 0.0354699 k_t: 0.000806855 M_global: 0.0485218\n",
      "step: 43000  d-loss: 0.0270046  g-loss: 0.0 k_t: 0.00180692 M_global: 0.0405069\n",
      "step: 44000  d-loss: 0.0256915  g-loss: 0.0 k_t: -0.000567056 M_global: 0.0385372\n",
      "step: 45000  d-loss: 0.0262256  g-loss: 0.0 k_t: 0.00624048 M_global: 0.0393384\n",
      "step: 46000  d-loss: 0.0252527  g-loss: 0.00103798 k_t: 0.000516783 M_global: 0.0368419\n",
      "step: 47000  d-loss: 0.0273101  g-loss: 0.0 k_t: -0.00108491 M_global: 0.0409651\n",
      "step: 48000  d-loss: 0.0256195  g-loss: 0.0343533 k_t: -0.000325241 M_global: 0.0471575\n",
      "step: 49000  d-loss: 0.0268764  g-loss: 0.0216361 k_t: -0.00208069 M_global: 0.0350518\n",
      "step: 50000  d-loss: 0.0253713  g-loss: 0.0309844 k_t: -0.000687906 M_global: 0.0436594\n",
      "step: 51000  d-loss: 0.0268674  g-loss: 0.0 k_t: 0.00113341 M_global: 0.0403011\n",
      "step: 52000  d-loss: 0.0241013  g-loss: 0.0168088 k_t: -0.00126265 M_global: 0.0288488\n",
      "step: 53000  d-loss: 0.0254053  g-loss: 0.00160846 k_t: 0.000917471 M_global: 0.0365017\n",
      "step: 54000  d-loss: 0.026072  g-loss: 0.0225487 k_t: -0.00128261 M_global: 0.0355703\n",
      "step: 55000  d-loss: 0.0267449  g-loss: 0.0 k_t: 0.0108737 M_global: 0.0401173\n",
      "step: 56000  d-loss: 0.0243744  g-loss: 0.0377354 k_t: 0.00385352 M_global: 0.0499953\n",
      "step: 57000  d-loss: 0.0246597  g-loss: 0.0230181 k_t: 0.000460476 M_global: 0.0353533\n",
      "step: 58000  d-loss: 0.026838  g-loss: 0.0180263 k_t: 0.000952484 M_global: 0.0314538\n",
      "step: 59000  d-loss: 0.0261492  g-loss: 0.0 k_t: 0.00329788 M_global: 0.0392238\n",
      "step: 60000  d-loss: 0.0260734  g-loss: 0.0 k_t: 0.000780836 M_global: 0.0391102\n",
      "step: 61000  d-loss: 0.0257403  g-loss: 0.0 k_t: 0.00192728 M_global: 0.0386105\n",
      "step: 62000  d-loss: 0.0258044  g-loss: 0.0322809 k_t: 0.000609452 M_global: 0.0451929\n",
      "step: 63000  d-loss: 0.0252753  g-loss: 0.0 k_t: 0.00306515 M_global: 0.0379129\n",
      "step: 64000  d-loss: 0.0267637  g-loss: 0.0345864 k_t: -0.00024834 M_global: 0.047964\n",
      "step: 65000  d-loss: 0.0255538  g-loss: 0.0 k_t: -0.000666826 M_global: 0.0383307\n",
      "step: 66000  d-loss: 0.0267723  g-loss: 0.0 k_t: -8.27841e-05 M_global: 0.0401584\n",
      "step: 67000  d-loss: 0.0248317  g-loss: 0.0210697 k_t: 0.00299617 M_global: 0.0335171\n",
      "step: 68000  d-loss: 0.0267343  g-loss: 0.0 k_t: -0.000900814 M_global: 0.0401015\n",
      "step: 69000  d-loss: 0.0262922  g-loss: 0.0 k_t: 0.00229253 M_global: 0.0394383\n",
      "step: 70000  d-loss: 0.0254229  g-loss: 0.0298136 k_t: -0.00124109 M_global: 0.0425065\n",
      "step: 71000  d-loss: 0.0261244  g-loss: 0.0351448 k_t: 0.00182763 M_global: 0.0482391\n",
      "step: 72000  d-loss: 0.0252494  g-loss: 0.0 k_t: 0.000138732 M_global: 0.0378741\n",
      "step: 73000  d-loss: 0.0272349  g-loss: 0.0 k_t: 0.00552825 M_global: 0.0408524\n",
      "step: 74000  d-loss: 0.025921  g-loss: 0.000180141 k_t: 0.000479419 M_global: 0.0387014\n",
      "step: 75000  d-loss: 0.0252977  g-loss: 0.0 k_t: -0.000876033 M_global: 0.0379465\n",
      "step: 76000  d-loss: 0.0258622  g-loss: 0.00322911 k_t: 0.000782698 M_global: 0.035568\n",
      "step: 77000  d-loss: 0.0246204  g-loss: 0.0 k_t: 0.00321476 M_global: 0.0369305\n",
      "step: 78000  d-loss: 0.0260034  g-loss: 0.0231582 k_t: 0.000250449 M_global: 0.0361628\n",
      "step: 79000  d-loss: 0.0257234  g-loss: 0.0 k_t: -5.41264e-05 M_global: 0.0385851\n",
      "step: 80000  d-loss: 0.0251991  g-loss: 0.0352452 k_t: -0.000337994 M_global: 0.0478388\n",
      "step: 81000  d-loss: 0.0249331  g-loss: 0.00947903 k_t: -0.000907256 M_global: 0.0279078\n",
      "step: 82000  d-loss: 0.0261091  g-loss: 0.0 k_t: -0.000290825 M_global: 0.0391636\n",
      "step: 83000  d-loss: 0.0257977  g-loss: 0.0 k_t: 0.00196464 M_global: 0.0386966\n",
      "step: 84000  d-loss: 0.0256043  g-loss: 0.0 k_t: -0.000120489 M_global: 0.0384065\n",
      "step: 85000  d-loss: 0.0258155  g-loss: 0.0258569 k_t: 0.000854261 M_global: 0.0387757\n",
      "step: 86000  d-loss: 0.0261132  g-loss: 0.0 k_t: -0.000115649 M_global: 0.0391698\n",
      "step: 87000  d-loss: 0.0241899  g-loss: 0.0353028 k_t: 0.0026705 M_global: 0.0474449\n",
      "step: 88000  d-loss: 0.0253201  g-loss: 0.0 k_t: -0.000424004 M_global: 0.0379802\n",
      "step: 89000  d-loss: 0.0245675  g-loss: 0.0349663 k_t: 0.00190206 M_global: 0.0472834\n",
      "step: 90000  d-loss: 0.0259767  g-loss: 0.0 k_t: 0.00124318 M_global: 0.0389651\n",
      "step: 91000  d-loss: 0.0261452  g-loss: 0.0 k_t: 0.00464867 M_global: 0.0392177\n",
      "step: 92000  d-loss: 0.0268407  g-loss: 0.0 k_t: -0.000242075 M_global: 0.0402611\n",
      "step: 93000  d-loss: 0.025897  g-loss: 0.0156869 k_t: -0.00105966 M_global: 0.0286271\n",
      "step: 94000  d-loss: 0.0241444  g-loss: 0.0 k_t: -0.00159652 M_global: 0.0362166\n",
      "step: 95000  d-loss: 0.0256898  g-loss: 0.0 k_t: -0.000490773 M_global: 0.0385346\n",
      "step: 96000  d-loss: 0.0250853  g-loss: 0.0 k_t: 0.00112759 M_global: 0.037628\n",
      "step: 97000  d-loss: 0.0267574  g-loss: 0.0302623 k_t: 0.000738496 M_global: 0.0436522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 98000  d-loss: 0.0252193  g-loss: 0.0 k_t: 0.00170456 M_global: 0.037829\n",
      "step: 99000  d-loss: 0.0258061  g-loss: 0.0 k_t: 0.00664153 M_global: 0.0387092\n",
      "step: 100000  d-loss: 0.0251709  g-loss: 0.0147255 k_t: -0.000816379 M_global: 0.0273049\n",
      "step: 101000  d-loss: 0.0257428  g-loss: 0.0 k_t: 0.000464094 M_global: 0.0386142\n",
      "step: 102000  d-loss: 0.0262567  g-loss: 0.0340682 k_t: -0.00121097 M_global: 0.0471759\n",
      "step: 103000  d-loss: 0.0252156  g-loss: 0.0 k_t: 0.000174358 M_global: 0.0378234\n",
      "step: 104000  d-loss: 0.0258181  g-loss: 0.0 k_t: 0.00201069 M_global: 0.0387272\n",
      "step: 105000  d-loss: 0.0250906  g-loss: 0.019579 k_t: -0.00173984 M_global: 0.0321073\n",
      "step: 106000  d-loss: 0.0249663  g-loss: 0.0 k_t: 0.00294439 M_global: 0.0374494\n",
      "step: 107000  d-loss: 0.0253533  g-loss: 0.0 k_t: -0.000267042 M_global: 0.0380299\n",
      "step: 108000  d-loss: 0.0248422  g-loss: 0.00165639 k_t: 0.000812038 M_global: 0.0356089\n",
      "step: 109000  d-loss: 0.0253029  g-loss: 0.0 k_t: 0.00298766 M_global: 0.0379544\n",
      "step: 110000  d-loss: 0.0261329  g-loss: 0.0255439 k_t: -0.0019332 M_global: 0.0385857\n",
      "step: 111000  d-loss: 0.0257211  g-loss: 0.0338335 k_t: 0.00165763 M_global: 0.0467221\n",
      "step: 112000  d-loss: 0.025834  g-loss: 0.0353509 k_t: 0.00104906 M_global: 0.0482864\n",
      "step: 113000  d-loss: 0.0256334  g-loss: 0.0339675 k_t: 0.000363743 M_global: 0.0467904\n",
      "step: 114000  d-loss: 0.0242332  g-loss: 0.0362506 k_t: 0.00156957 M_global: 0.0483957\n",
      "step: 115000  d-loss: 0.0249532  g-loss: 0.0296245 k_t: 0.000138462 M_global: 0.0421031\n",
      "step: 116000  d-loss: 0.0254072  g-loss: 0.0 k_t: 0.00310288 M_global: 0.0381109\n",
      "step: 117000  d-loss: 0.0253411  g-loss: 0.00316173 k_t: -0.000579477 M_global: 0.0348472\n",
      "step: 118000  d-loss: 0.0245177  g-loss: 0.0 k_t: 0.00222197 M_global: 0.0367765\n",
      "step: 119000  d-loss: 0.0265371  g-loss: 0.0 k_t: -0.0016956 M_global: 0.0398056\n",
      "step: 120000  d-loss: 0.0249191  g-loss: 1.18419e-06 k_t: 0.000401156 M_global: 0.0373775\n",
      "step: 121000  d-loss: 0.0251226  g-loss: 0.0 k_t: 0.00119709 M_global: 0.0376839\n",
      "step: 122000  d-loss: 0.0249189  g-loss: 0.0289824 k_t: -0.000258357 M_global: 0.0414381\n",
      "step: 123000  d-loss: 0.0247755  g-loss: 0.0 k_t: 0.00309518 M_global: 0.0371632\n",
      "step: 124000  d-loss: 0.0252535  g-loss: 0.0 k_t: -6.38936e-06 M_global: 0.0378803\n",
      "step: 125000  d-loss: 0.0259345  g-loss: 0.0 k_t: 0.00220447 M_global: 0.0389018\n",
      "step: 126000  d-loss: 0.0252692  g-loss: 0.0167505 k_t: -0.000862387 M_global: 0.0293779\n",
      "step: 127000  d-loss: 0.0257021  g-loss: 0.0 k_t: -0.000552098 M_global: 0.0385532\n",
      "step: 128000  d-loss: 0.0252719  g-loss: 0.000191909 k_t: 0.00264574 M_global: 0.0377167\n",
      "step: 129000  d-loss: 0.0253029  g-loss: 0.00256882 k_t: 0.00191442 M_global: 0.035393\n",
      "step: 130000  d-loss: 0.0263747  g-loss: 0.0363171 k_t: 0.00611439 M_global: 0.0496155\n",
      "step: 131000  d-loss: 0.0261936  g-loss: 0.0122022 k_t: 0.000707015 M_global: 0.0271012\n",
      "step: 132000  d-loss: 0.0254987  g-loss: 0.0 k_t: -0.00148296 M_global: 0.0382481\n",
      "step: 133000  d-loss: 0.0252102  g-loss: 0.0355408 k_t: 0.000542314 M_global: 0.0481556\n",
      "step: 134000  d-loss: 0.0259014  g-loss: 0.0 k_t: -0.000352067 M_global: 0.0388521\n",
      "step: 135000  d-loss: 0.0259956  g-loss: 0.0 k_t: -0.000548647 M_global: 0.0389934\n",
      "step: 136000  d-loss: 0.0255036  g-loss: 0.0325262 k_t: -0.000863711 M_global: 0.0452639\n",
      "step: 137000  d-loss: 0.0242278  g-loss: 0.0 k_t: 0.00150247 M_global: 0.0363416\n",
      "step: 138000  d-loss: 0.026362  g-loss: 8.667e-06 k_t: 0.000214113 M_global: 0.0395344\n",
      "step: 139000  d-loss: 0.0249825  g-loss: 0.0159744 k_t: -0.0013984 M_global: 0.0284545\n",
      "step: 140000  d-loss: 0.0257949  g-loss: 0.0329889 k_t: 0.000813326 M_global: 0.0458998\n",
      "step: 141000  d-loss: 0.0262254  g-loss: 0.0327209 k_t: -0.00116696 M_global: 0.0458145\n",
      "step: 142000  d-loss: 0.0250536  g-loss: 0.0 k_t: 0.000446787 M_global: 0.0375804\n",
      "step: 143000  d-loss: 0.0256471  g-loss: 0.0 k_t: -0.00103377 M_global: 0.0384707\n",
      "step: 144000  d-loss: 0.025453  g-loss: 0.0 k_t: 0.0055393 M_global: 0.0381795\n",
      "step: 145000  d-loss: 0.025726  g-loss: 8.4327e-05 k_t: -0.00134556 M_global: 0.0385045\n",
      "step: 146000  d-loss: 0.0250058  g-loss: 0.0181085 k_t: -0.000945444 M_global: 0.0306028\n",
      "step: 147000  d-loss: 0.0260463  g-loss: 0.0 k_t: 0.00171994 M_global: 0.0390694\n",
      "step: 148000  d-loss: 0.0261593  g-loss: 0.0 k_t: 0.00730396 M_global: 0.0392389\n",
      "step: 149000  d-loss: 0.0252937  g-loss: 0.0131273 k_t: 0.000643672 M_global: 0.0257784\n",
      "step: 150000  d-loss: 0.0248985  g-loss: 0.0 k_t: 0.000594092 M_global: 0.0373477\n",
      "step: 151000  d-loss: 0.0252398  g-loss: 0.0 k_t: 0.000202001 M_global: 0.0378597\n",
      "step: 152000  d-loss: 0.0254284  g-loss: 0.0199778 k_t: -0.00108985 M_global: 0.0326812\n",
      "step: 153000  d-loss: 0.0252665  g-loss: 0.0297473 k_t: 0.00312849 M_global: 0.0424271\n",
      "step: 154000  d-loss: 0.0248453  g-loss: 0.0 k_t: -0.000634862 M_global: 0.037268\n",
      "step: 155000  d-loss: 0.0266095  g-loss: 0.00290128 k_t: 0.000881518 M_global: 0.0370168\n",
      "step: 156000  d-loss: 0.0247022  g-loss: 0.0 k_t: 0.00120552 M_global: 0.0370533\n",
      "step: 157000  d-loss: 0.0251486  g-loss: 0.0 k_t: -0.00165047 M_global: 0.037723\n",
      "step: 158000  d-loss: 0.0254601  g-loss: 0.0354603 k_t: 0.00113394 M_global: 0.0482104\n",
      "step: 159000  d-loss: 0.0253868  g-loss: 0.0 k_t: -0.000405056 M_global: 0.0380803\n",
      "step: 160000  d-loss: 0.0249607  g-loss: 0.0361963 k_t: 0.00376797 M_global: 0.0487449\n",
      "step: 161000  d-loss: 0.0259352  g-loss: 0.0251202 k_t: -0.000356075 M_global: 0.0380834\n",
      "step: 162000  d-loss: 0.025194  g-loss: 0.0 k_t: 0.000108584 M_global: 0.0377909\n",
      "step: 163000  d-loss: 0.0240153  g-loss: 0.0329094 k_t: 0.000905572 M_global: 0.044932\n",
      "step: 164000  d-loss: 0.0248509  g-loss: 0.0211163 k_t: 0.00135596 M_global: 0.0335561\n",
      "step: 165000  d-loss: 0.0252175  g-loss: 0.0 k_t: 0.000714039 M_global: 0.0378263\n",
      "step: 166000  d-loss: 0.0245635  g-loss: 0.0 k_t: 0.00186952 M_global: 0.0368453\n",
      "step: 167000  d-loss: 0.0248271  g-loss: 0.0196754 k_t: 0.000442264 M_global: 0.0320933\n",
      "step: 168000  d-loss: 0.0247101  g-loss: 0.0 k_t: -0.000208385 M_global: 0.0370651\n",
      "step: 169000  d-loss: 0.0247728  g-loss: 0.00678846 k_t: 0.00168286 M_global: 0.0303878\n",
      "step: 170000  d-loss: 0.0253158  g-loss: 0.0 k_t: -0.0004567 M_global: 0.0379737\n",
      "step: 171000  d-loss: 0.0244365  g-loss: 0.0 k_t: -0.00011371 M_global: 0.0366547\n",
      "step: 172000  d-loss: 0.0241848  g-loss: 0.0349695 k_t: 5.20493e-05 M_global: 0.0470629\n",
      "step: 173000  d-loss: 0.0201117  g-loss: 0.0 k_t: 0.00200496 M_global: 0.0301676\n",
      "step: 174000  d-loss: 0.0208868  g-loss: 0.0225354 k_t: -0.000220633 M_global: 0.0329763\n",
      "step: 175000  d-loss: 0.0210135  g-loss: 0.0333238 k_t: -0.000165124 M_global: 0.0438278\n",
      "step: 176000  d-loss: 0.0203096  g-loss: 0.0 k_t: 0.00188496 M_global: 0.0304644\n",
      "step: 177000  d-loss: 0.0206345  g-loss: 0.00534376 k_t: -0.00148407 M_global: 0.0255961\n",
      "step: 178000  d-loss: 0.0196661  g-loss: 0.0 k_t: 0.00222238 M_global: 0.0294992\n",
      "step: 179000  d-loss: 0.0205977  g-loss: 0.000144462 k_t: -2.84076e-05 M_global: 0.030752\n",
      "step: 180000  d-loss: 0.0212373  g-loss: 0.0189304 k_t: -0.00105807 M_global: 0.029539\n",
      "step: 181000  d-loss: 0.0205019  g-loss: 0.0 k_t: 0.0010772 M_global: 0.0307528\n",
      "step: 182000  d-loss: 0.0204471  g-loss: 0.0 k_t: 5.58128e-05 M_global: 0.0306707\n",
      "step: 183000  d-loss: 0.020674  g-loss: 0.0 k_t: 0.000963626 M_global: 0.031011\n",
      "step: 184000  d-loss: 0.0201664  g-loss: 0.0198864 k_t: 0.000406167 M_global: 0.0299737\n",
      "step: 185000  d-loss: 0.020148  g-loss: 0.0 k_t: 0.00327848 M_global: 0.0302219\n",
      "step: 186000  d-loss: 0.0206419  g-loss: 0.021197 k_t: -0.000322066 M_global: 0.0315146\n",
      "step: 187000  d-loss: 0.0210694  g-loss: 0.0 k_t: 0.00199441 M_global: 0.031604\n",
      "step: 188000  d-loss: 0.0205137  g-loss: 0.0 k_t: 0.00035424 M_global: 0.0307705\n",
      "step: 189000  d-loss: 0.0204663  g-loss: 0.0 k_t: 0.00118228 M_global: 0.0306994\n",
      "step: 190000  d-loss: 0.0202278  g-loss: 0.0 k_t: 0.00364182 M_global: 0.0303417\n",
      "step: 191000  d-loss: 0.0198791  g-loss: 0.037095 k_t: 0.00236592 M_global: 0.0470784\n",
      "step: 192000  d-loss: 0.0210492  g-loss: 0.0206762 k_t: -0.000217446 M_global: 0.0311985\n",
      "step: 193000  d-loss: 0.0207289  g-loss: 0.0 k_t: -0.000143869 M_global: 0.0310933\n",
      "step: 194000  d-loss: 0.0204525  g-loss: 0.0 k_t: 0.00451145 M_global: 0.0306788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 195000  d-loss: 0.0205662  g-loss: 0.0 k_t: -0.00190451 M_global: 0.0308493\n",
      "step: 196000  d-loss: 0.0215916  g-loss: 0.0241414 k_t: -0.000248342 M_global: 0.0349342\n",
      "step: 197000  d-loss: 0.0207277  g-loss: 0.0 k_t: 0.0011832 M_global: 0.0310916\n",
      "step: 198000  d-loss: 0.0206551  g-loss: 0.0 k_t: 8.5749e-05 M_global: 0.0309826\n",
      "step: 199000  d-loss: 0.0202243  g-loss: 0.0 k_t: 0.000780477 M_global: 0.0303364\n",
      "step: 200000  d-loss: 0.0206251  g-loss: 0.0344209 k_t: 0.00112329 M_global: 0.0447528\n",
      "step: 201000  d-loss: 0.0201983  g-loss: 0.0 k_t: 0.00616908 M_global: 0.0302974\n",
      "step: 202000  d-loss: 0.0211724  g-loss: 0.0 k_t: 0.0164115 M_global: 0.0317585\n",
      "step: 203000  d-loss: 0.0209591  g-loss: 0.0 k_t: 0.0266533 M_global: 0.0314387\n",
      "step: 204000  d-loss: 0.0192891  g-loss: 0.0 k_t: 0.0368801 M_global: 0.0289336\n",
      "step: 205000  d-loss: 0.0189261  g-loss: 0.0586956 k_t: 0.018523 M_global: 0.0687022\n",
      "step: 206000  d-loss: 0.0200296  g-loss: 7.91627e-05 k_t: -8.78608e-05 M_global: 0.0299652\n",
      "step: 207000  d-loss: 0.0191627  g-loss: 0.0128883 k_t: -0.00062631 M_global: 0.0224656\n",
      "step: 208000  d-loss: 0.0198182  g-loss: 0.0255473 k_t: 0.000356647 M_global: 0.035461\n",
      "step: 209000  d-loss: 0.0191756  g-loss: 0.0 k_t: -0.000536581 M_global: 0.0287633\n",
      "step: 210000  d-loss: 0.0202028  g-loss: 0.0 k_t: 0.00126932 M_global: 0.0303042\n",
      "step: 211000  d-loss: 0.0198997  g-loss: 0.0241673 k_t: 0.00190863 M_global: 0.0341402\n",
      "step: 212000  d-loss: 0.0200564  g-loss: 0.0 k_t: -0.000247161 M_global: 0.0300846\n",
      "step: 213000  d-loss: 0.0199063  g-loss: 0.0 k_t: 0.009791 M_global: 0.0298595\n",
      "step: 214000  d-loss: 0.0200469  g-loss: 0.0 k_t: 0.0198278 M_global: 0.0300704\n",
      "step: 215000  d-loss: 0.0196693  g-loss: 0.0 k_t: 0.0298542 M_global: 0.0295039\n",
      "step: 216000  d-loss: 0.0198497  g-loss: 0.0 k_t: 0.039881 M_global: 0.0297746\n",
      "step: 217000  d-loss: 0.0196339  g-loss: 0.0 k_t: 0.0499034 M_global: 0.0294508\n",
      "step: 218000  d-loss: 0.0208852  g-loss: 0.0 k_t: 0.0599213 M_global: 0.0313277\n",
      "step: 219000  d-loss: 0.0197135  g-loss: 0.0 k_t: 0.0699305 M_global: 0.0295703\n",
      "step: 220000  d-loss: 0.0192177  g-loss: 0.0 k_t: 0.0799394 M_global: 0.0288265\n",
      "step: 221000  d-loss: 0.0204713  g-loss: 0.0 k_t: 0.0899482 M_global: 0.0307069\n",
      "step: 222000  d-loss: 0.0203045  g-loss: 0.0 k_t: 0.0999504 M_global: 0.0304568\n",
      "step: 223000  d-loss: 0.0199851  g-loss: 0.0 k_t: 0.109946 M_global: 0.0299777\n",
      "step: 224000  d-loss: 0.0193366  g-loss: 0.0 k_t: 0.119949 M_global: 0.029005\n",
      "step: 225000  d-loss: 0.0205172  g-loss: 0.0 k_t: 0.129945 M_global: 0.0307758\n",
      "step: 226000  d-loss: 0.0195686  g-loss: 0.0 k_t: 0.139935 M_global: 0.0293529\n",
      "step: 227000  d-loss: 0.0201447  g-loss: 0.0 k_t: 0.149925 M_global: 0.030217\n",
      "step: 228000  d-loss: 0.0199768  g-loss: 0.0 k_t: 0.159905 M_global: 0.0299653\n",
      "step: 229000  d-loss: 0.0201003  g-loss: 0.0 k_t: 0.169888 M_global: 0.0301505\n",
      "step: 230000  d-loss: 0.0192201  g-loss: 0.0 k_t: 0.179862 M_global: 0.0288302\n",
      "step: 231000  d-loss: 0.0206124  g-loss: 0.0 k_t: 0.18984 M_global: 0.0309186\n",
      "step: 232000  d-loss: 0.0195785  g-loss: 0.0 k_t: 0.199817 M_global: 0.0293677\n",
      "step: 233000  d-loss: 0.0198741  g-loss: 0.0 k_t: 0.209786 M_global: 0.0298112\n",
      "step: 234000  d-loss: 0.0194526  g-loss: 0.0 k_t: 0.219754 M_global: 0.0291789\n",
      "step: 235000  d-loss: 0.0202557  g-loss: 0.0 k_t: 0.229716 M_global: 0.0303835\n",
      "step: 236000  d-loss: 0.0203265  g-loss: 0.0 k_t: 0.239683 M_global: 0.0304898\n",
      "step: 237000  d-loss: 0.0199239  g-loss: 0.0 k_t: 0.249641 M_global: 0.0298859\n",
      "step: 238000  d-loss: 0.0198781  g-loss: 0.0 k_t: 0.259597 M_global: 0.0298171\n",
      "step: 239000  d-loss: 0.0192759  g-loss: 0.0 k_t: 0.269557 M_global: 0.0289139\n",
      "step: 240000  d-loss: 0.0201546  g-loss: 0.0 k_t: 0.279509 M_global: 0.0302319\n",
      "step: 241000  d-loss: 0.0195436  g-loss: 0.0 k_t: 0.289458 M_global: 0.0293155\n",
      "step: 242000  d-loss: 0.0192236  g-loss: 0.0 k_t: 0.29941 M_global: 0.0288353\n",
      "step: 243000  d-loss: 0.0195625  g-loss: 0.0 k_t: 0.309352 M_global: 0.0293438\n",
      "step: 244000  d-loss: 0.0194164  g-loss: 0.0 k_t: 0.319296 M_global: 0.0291246\n",
      "step: 245000  d-loss: 0.0200621  g-loss: 0.0 k_t: 0.329243 M_global: 0.0300932\n",
      "step: 246000  d-loss: 0.0199988  g-loss: 0.0 k_t: 0.33918 M_global: 0.0299981\n",
      "step: 247000  d-loss: 0.0189218  g-loss: 0.0 k_t: 0.349115 M_global: 0.0283827\n",
      "step: 248000  d-loss: 0.0197898  g-loss: 0.0 k_t: 0.359051 M_global: 0.0296847\n",
      "step: 249000  d-loss: 0.0201819  g-loss: 0.0 k_t: 0.368986 M_global: 0.0302729\n",
      "step: 250000  d-loss: 0.0186634  g-loss: 0.0 k_t: 0.378912 M_global: 0.0279951\n",
      "step: 251000  d-loss: 0.0199965  g-loss: 0.0 k_t: 0.38884 M_global: 0.0299947\n",
      "step: 252000  d-loss: 0.0198431  g-loss: 0.0 k_t: 0.398764 M_global: 0.0297646\n",
      "step: 253000  d-loss: 0.019918  g-loss: 0.0 k_t: 0.408682 M_global: 0.029877\n",
      "step: 254000  d-loss: 0.0195019  g-loss: 0.0 k_t: 0.418594 M_global: 0.0292529\n",
      "step: 255000  d-loss: 0.0202714  g-loss: 0.0 k_t: 0.428507 M_global: 0.030407\n",
      "step: 256000  d-loss: 0.0203826  g-loss: 0.0 k_t: 0.43841 M_global: 0.0305739\n",
      "step: 257000  d-loss: 0.0197195  g-loss: 0.0 k_t: 0.448315 M_global: 0.0295793\n",
      "step: 258000  d-loss: 0.019827  g-loss: 0.0 k_t: 0.458219 M_global: 0.0297405\n",
      "step: 259000  d-loss: 0.0203492  g-loss: 0.0 k_t: 0.46812 M_global: 0.0305238\n",
      "step: 260000  d-loss: 0.0204231  g-loss: 0.0 k_t: 0.478017 M_global: 0.0306346\n",
      "step: 261000  d-loss: 0.019822  g-loss: 0.0 k_t: 0.487911 M_global: 0.0297329\n",
      "step: 262000  d-loss: 0.0201298  g-loss: 0.0 k_t: 0.497806 M_global: 0.0301947\n",
      "step: 263000  d-loss: 0.0194332  g-loss: 0.0 k_t: 0.507697 M_global: 0.0291498\n",
      "step: 264000  d-loss: 0.0199128  g-loss: 0.0 k_t: 0.51759 M_global: 0.0298692\n",
      "step: 265000  d-loss: 0.0201324  g-loss: 0.0 k_t: 0.527477 M_global: 0.0301987\n",
      "step: 266000  d-loss: 0.0193191  g-loss: 0.0 k_t: 0.537358 M_global: 0.0289786\n",
      "step: 267000  d-loss: 0.0194996  g-loss: 0.0 k_t: 0.54724 M_global: 0.0292493\n",
      "step: 268000  d-loss: 0.0197188  g-loss: 0.0 k_t: 0.557126 M_global: 0.0295782\n",
      "step: 269000  d-loss: 0.018955  g-loss: 0.0 k_t: 0.567003 M_global: 0.0284325\n",
      "step: 270000  d-loss: 0.0195467  g-loss: 0.0 k_t: 0.576884 M_global: 0.02932\n",
      "step: 271000  d-loss: 0.0193784  g-loss: 0.0 k_t: 0.586758 M_global: 0.0290676\n",
      "step: 272000  d-loss: 0.0190886  g-loss: 0.0 k_t: 0.596632 M_global: 0.028633\n",
      "step: 273000  d-loss: 0.0201187  g-loss: 0.0 k_t: 0.606506 M_global: 0.030178\n",
      "step: 274000  d-loss: 0.0193779  g-loss: 0.0 k_t: 0.616376 M_global: 0.0290669\n",
      "step: 275000  d-loss: 0.0198793  g-loss: 0.0 k_t: 0.626245 M_global: 0.029819\n",
      "step: 276000  d-loss: 0.0185712  g-loss: 0.0 k_t: 0.63611 M_global: 0.0278568\n",
      "step: 277000  d-loss: 0.0197571  g-loss: 0.0 k_t: 0.645974 M_global: 0.0296356\n",
      "step: 278000  d-loss: 0.0195207  g-loss: 0.0 k_t: 0.655837 M_global: 0.0292811\n",
      "step: 279000  d-loss: 0.0191343  g-loss: 0.0 k_t: 0.6657 M_global: 0.0287015\n",
      "step: 280000  d-loss: 0.0199342  g-loss: 0.0 k_t: 0.675556 M_global: 0.0299013\n",
      "step: 281000  d-loss: 0.0186848  g-loss: 0.0 k_t: 0.685415 M_global: 0.0280271\n",
      "step: 282000  d-loss: 0.0202168  g-loss: 0.0 k_t: 0.695275 M_global: 0.0303253\n",
      "step: 283000  d-loss: 0.0202404  g-loss: 0.0 k_t: 0.705128 M_global: 0.0303606\n",
      "step: 284000  d-loss: 0.0195713  g-loss: 0.0 k_t: 0.714977 M_global: 0.029357\n",
      "step: 285000  d-loss: 0.0195894  g-loss: 0.0 k_t: 0.724831 M_global: 0.0293841\n",
      "step: 286000  d-loss: 0.019798  g-loss: 0.0 k_t: 0.734677 M_global: 0.029697\n",
      "step: 287000  d-loss: 0.0204863  g-loss: 0.0 k_t: 0.744523 M_global: 0.0307294\n",
      "step: 288000  d-loss: 0.01983  g-loss: 0.0 k_t: 0.754372 M_global: 0.0297449\n",
      "step: 289000  d-loss: 0.0196415  g-loss: 0.0 k_t: 0.764219 M_global: 0.0294622\n",
      "step: 290000  d-loss: 0.0192673  g-loss: 0.0 k_t: 0.774063 M_global: 0.028901\n",
      "step: 291000  d-loss: 0.0197685  g-loss: 0.0 k_t: 0.783899 M_global: 0.0296528\n",
      "step: 292000  d-loss: 0.0192967  g-loss: 0.0 k_t: 0.793739 M_global: 0.0289451\n",
      "step: 293000  d-loss: 0.01941  g-loss: 0.0 k_t: 0.803576 M_global: 0.029115\n",
      "step: 294000  d-loss: 0.0198779  g-loss: 0.0 k_t: 0.813412 M_global: 0.0298168\n",
      "step: 295000  d-loss: 0.0197388  g-loss: 0.0 k_t: 0.823245 M_global: 0.0296083\n",
      "step: 296000  d-loss: 0.0194368  g-loss: 0.0 k_t: 0.833076 M_global: 0.0291551\n",
      "step: 297000  d-loss: 0.0187924  g-loss: 0.0 k_t: 0.842908 M_global: 0.0281886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 298000  d-loss: 0.0204914  g-loss: 0.0 k_t: 0.852738 M_global: 0.0307371\n",
      "step: 299000  d-loss: 0.0195299  g-loss: 0.0 k_t: 0.862561 M_global: 0.0292948\n",
      "step: 300000  d-loss: 0.0198451  g-loss: 0.0 k_t: 0.87239 M_global: 0.0297676\n",
      "step: 301000  d-loss: 0.0189386  g-loss: 0.0 k_t: 0.882214 M_global: 0.0284079\n",
      "step: 302000  d-loss: 0.0206628  g-loss: 0.0 k_t: 0.89204 M_global: 0.0309942\n",
      "step: 303000  d-loss: 0.0198813  g-loss: 0.0 k_t: 0.901864 M_global: 0.0298219\n",
      "step: 304000  d-loss: 0.0198024  g-loss: 0.0 k_t: 0.911686 M_global: 0.0297036\n",
      "step: 305000  d-loss: 0.0197713  g-loss: 0.0 k_t: 0.921508 M_global: 0.029657\n",
      "step: 306000  d-loss: 0.0201381  g-loss: 0.0 k_t: 0.931325 M_global: 0.0302072\n",
      "step: 307000  d-loss: 0.0196522  g-loss: 0.0 k_t: 0.941141 M_global: 0.0294783\n",
      "step: 308000  d-loss: 0.0197748  g-loss: 0.0 k_t: 0.950954 M_global: 0.0296622\n",
      "step: 309000  d-loss: 0.019269  g-loss: 0.0 k_t: 0.960766 M_global: 0.0289035\n",
      "step: 310000  d-loss: 0.0205742  g-loss: 0.0 k_t: 0.970579 M_global: 0.0308614\n",
      "step: 311000  d-loss: 0.0188972  g-loss: 0.0 k_t: 0.980389 M_global: 0.0283458\n",
      "step: 312000  d-loss: 0.0192096  g-loss: 0.0 k_t: 0.990198 M_global: 0.0288145\n",
      "step: 313000  d-loss: 0.0194232  g-loss: 0.0 k_t: 1.00001 M_global: 0.0291348\n",
      "step: 314000  d-loss: 0.0209118  g-loss: 0.0 k_t: 1.00981 M_global: 0.0313677\n",
      "step: 315000  d-loss: 0.0196586  g-loss: 0.0 k_t: 1.01961 M_global: 0.0294879\n",
      "step: 316000  d-loss: 0.0197718  g-loss: 0.0 k_t: 1.0294 M_global: 0.0296577\n",
      "step: 317000  d-loss: 0.0201604  g-loss: 0.0 k_t: 1.03915 M_global: 0.0302406\n",
      "step: 318000  d-loss: 0.0207559  g-loss: 0.0 k_t: 1.04891 M_global: 0.0311338\n",
      "step: 319000  d-loss: 0.0190545  g-loss: 0.0 k_t: 1.05867 M_global: 0.0285817\n",
      "step: 320000  d-loss: 0.0199639  g-loss: 0.0 k_t: 1.06842 M_global: 0.0299458\n",
      "step: 321000  d-loss: 0.0191927  g-loss: 0.0 k_t: 1.07816 M_global: 0.028789\n",
      "step: 322000  d-loss: 0.0189616  g-loss: 0.0 k_t: 1.08791 M_global: 0.0284424\n",
      "step: 323000  d-loss: 0.0197497  g-loss: 0.0 k_t: 1.09765 M_global: 0.0296245\n",
      "step: 324000  d-loss: 0.020014  g-loss: 0.0 k_t: 1.1074 M_global: 0.0300211\n",
      "step: 325000  d-loss: 0.0193236  g-loss: 0.0 k_t: 1.11714 M_global: 0.0289854\n",
      "step: 326000  d-loss: 0.0194477  g-loss: 0.0 k_t: 1.12688 M_global: 0.0291715\n",
      "step: 327000  d-loss: 0.0198947  g-loss: 0.0 k_t: 1.13662 M_global: 0.029842\n",
      "step: 328000  d-loss: 0.0200715  g-loss: 0.0 k_t: 1.14635 M_global: 0.0301073\n",
      "step: 329000  d-loss: 0.0194288  g-loss: 0.0 k_t: 1.15608 M_global: 0.0291432\n",
      "step: 330000  d-loss: 0.0194827  g-loss: 0.0 k_t: 1.16581 M_global: 0.029224\n",
      "step: 331000  d-loss: 0.0199378  g-loss: 0.0 k_t: 1.17554 M_global: 0.0299068\n",
      "step: 332000  d-loss: 0.0188855  g-loss: 0.0 k_t: 1.18527 M_global: 0.0283282\n",
      "step: 333000  d-loss: 0.019431  g-loss: 0.0 k_t: 1.195 M_global: 0.0291465\n",
      "step: 334000  d-loss: 0.0182721  g-loss: 0.0 k_t: 1.20473 M_global: 0.0274082\n",
      "step: 335000  d-loss: 0.0193092  g-loss: 0.0 k_t: 1.21445 M_global: 0.0289637\n",
      "step: 336000  d-loss: 0.0194496  g-loss: 0.0 k_t: 1.22417 M_global: 0.0291743\n",
      "step: 337000  d-loss: 0.0195675  g-loss: 0.0 k_t: 1.2339 M_global: 0.0293512\n",
      "step: 338000  d-loss: 0.0195918  g-loss: 0.0 k_t: 1.24361 M_global: 0.0293877\n",
      "step: 339000  d-loss: 0.0191217  g-loss: 0.0 k_t: 1.25333 M_global: 0.0286826\n",
      "step: 340000  d-loss: 0.0195959  g-loss: 0.0 k_t: 1.26305 M_global: 0.0293939\n",
      "step: 341000  d-loss: 0.0199093  g-loss: 0.0 k_t: 1.27277 M_global: 0.0298639\n",
      "step: 342000  d-loss: 0.0202446  g-loss: 0.0 k_t: 1.28248 M_global: 0.030367\n",
      "step: 343000  d-loss: 0.0193709  g-loss: 0.0 k_t: 1.29219 M_global: 0.0290563\n",
      "step: 344000  d-loss: 0.0193093  g-loss: 0.0 k_t: 1.3019 M_global: 0.028964\n",
      "step: 345000  d-loss: 0.019779  g-loss: 0.0 k_t: 1.31162 M_global: 0.0296684\n",
      "step: 346000  d-loss: 0.0199632  g-loss: 0.0 k_t: 1.32133 M_global: 0.0299447\n",
      "step: 347000  d-loss: 0.0190172  g-loss: 0.0 k_t: 1.33104 M_global: 0.0285258\n",
      "step: 348000  d-loss: 0.0208046  g-loss: 0.0 k_t: 1.34075 M_global: 0.0312069\n",
      "step: 349000  d-loss: 0.0205497  g-loss: 0.0 k_t: 1.35045 M_global: 0.0308246\n",
      "step: 350000  d-loss: 0.0192247  g-loss: 0.0 k_t: 1.36015 M_global: 0.0288371\n",
      "step: 351000  d-loss: 0.0195988  g-loss: 0.0 k_t: 1.36986 M_global: 0.0293982\n",
      "step: 352000  d-loss: 0.0192937  g-loss: 0.0 k_t: 1.37956 M_global: 0.0289406\n",
      "step: 353000  d-loss: 0.019166  g-loss: 0.0 k_t: 1.38926 M_global: 0.028749\n",
      "step: 354000  d-loss: 0.0184002  g-loss: 0.0 k_t: 1.39896 M_global: 0.0276002\n",
      "step: 355000  d-loss: 0.0202131  g-loss: 0.0 k_t: 1.40865 M_global: 0.0303197\n",
      "step: 356000  d-loss: 0.0200175  g-loss: 0.0 k_t: 1.41835 M_global: 0.0300262\n",
      "step: 357000  d-loss: 0.0192236  g-loss: 0.0 k_t: 1.42804 M_global: 0.0288355\n",
      "step: 358000  d-loss: 0.0191288  g-loss: 0.0 k_t: 1.43774 M_global: 0.0286932\n",
      "step: 359000  d-loss: 0.0196612  g-loss: 0.0 k_t: 1.44743 M_global: 0.0294919\n",
      "step: 360000  d-loss: 0.0201616  g-loss: 0.0 k_t: 1.45712 M_global: 0.0302425\n",
      "step: 361000  d-loss: 0.0189307  g-loss: 0.0 k_t: 1.46681 M_global: 0.028396\n",
      "step: 362000  d-loss: 0.0182871  g-loss: 0.0 k_t: 1.47649 M_global: 0.0274306\n",
      "step: 363000  d-loss: 0.0195307  g-loss: 0.0 k_t: 1.48617 M_global: 0.0292961\n",
      "step: 364000  d-loss: 0.0187456  g-loss: 0.0 k_t: 1.49585 M_global: 0.0281183\n",
      "step: 365000  d-loss: 0.0189478  g-loss: 0.0 k_t: 1.50553 M_global: 0.0284217\n",
      "step: 366000  d-loss: 0.0192302  g-loss: 0.0 k_t: 1.51521 M_global: 0.0288454\n",
      "step: 367000  d-loss: 0.0196312  g-loss: 0.0 k_t: 1.52488 M_global: 0.0294469\n",
      "step: 368000  d-loss: 0.0192185  g-loss: 0.0 k_t: 1.53456 M_global: 0.0288278\n",
      "step: 369000  d-loss: 0.0189271  g-loss: 0.0 k_t: 1.54423 M_global: 0.0283906\n",
      "step: 370000  d-loss: 0.0196369  g-loss: 0.0 k_t: 1.55391 M_global: 0.0294553\n",
      "step: 371000  d-loss: 0.0190434  g-loss: 0.0 k_t: 1.56358 M_global: 0.0285652\n",
      "step: 372000  d-loss: 0.0207964  g-loss: 0.0 k_t: 1.57325 M_global: 0.0311946\n",
      "step: 373000  d-loss: 0.0194993  g-loss: 0.0 k_t: 1.58292 M_global: 0.0292489\n",
      "step: 374000  d-loss: 0.0187551  g-loss: 0.0 k_t: 1.59258 M_global: 0.0281327\n",
      "step: 375000  d-loss: 0.0195017  g-loss: 0.0 k_t: 1.60225 M_global: 0.0292525\n",
      "step: 376000  d-loss: 0.019618  g-loss: 0.0 k_t: 1.61192 M_global: 0.0294269\n",
      "step: 377000  d-loss: 0.0185682  g-loss: 0.0 k_t: 1.62158 M_global: 0.0278524\n",
      "step: 378000  d-loss: 0.0193323  g-loss: 0.0 k_t: 1.63124 M_global: 0.0289984\n",
      "step: 379000  d-loss: 0.019108  g-loss: 0.0 k_t: 1.6409 M_global: 0.0286619\n",
      "step: 380000  d-loss: 0.0198845  g-loss: 0.0 k_t: 1.65056 M_global: 0.0298267\n",
      "step: 381000  d-loss: 0.0203854  g-loss: 0.0 k_t: 1.66022 M_global: 0.0305781\n",
      "step: 382000  d-loss: 0.0202305  g-loss: 0.0 k_t: 1.66988 M_global: 0.0303457\n",
      "step: 383000  d-loss: 0.0194774  g-loss: 0.0 k_t: 1.67954 M_global: 0.029216\n",
      "step: 384000  d-loss: 0.0198568  g-loss: 0.0 k_t: 1.68919 M_global: 0.0297853\n",
      "step: 385000  d-loss: 0.018884  g-loss: 0.0 k_t: 1.69884 M_global: 0.028326\n",
      "step: 386000  d-loss: 0.0186324  g-loss: 0.0 k_t: 1.7085 M_global: 0.0279486\n",
      "step: 387000  d-loss: 0.0193571  g-loss: 0.0 k_t: 1.71815 M_global: 0.0290357\n",
      "step: 388000  d-loss: 0.019356  g-loss: 0.0 k_t: 1.7278 M_global: 0.0290341\n",
      "step: 389000  d-loss: 0.0190478  g-loss: 0.0 k_t: 1.73744 M_global: 0.0285717\n",
      "step: 390000  d-loss: 0.0199235  g-loss: 0.0 k_t: 1.74709 M_global: 0.0298852\n",
      "step: 391000  d-loss: 0.0190036  g-loss: 0.0 k_t: 1.75674 M_global: 0.0285053\n",
      "step: 392000  d-loss: 0.0183986  g-loss: 0.0 k_t: 1.76639 M_global: 0.027598\n",
      "step: 393000  d-loss: 0.0194598  g-loss: 0.0 k_t: 1.77603 M_global: 0.0291896\n",
      "step: 394000  d-loss: 0.0188094  g-loss: 0.0 k_t: 1.78568 M_global: 0.028214\n",
      "step: 395000  d-loss: 0.0190571  g-loss: 0.0 k_t: 1.79532 M_global: 0.0285857\n",
      "step: 396000  d-loss: 0.0192807  g-loss: 0.0 k_t: 1.80496 M_global: 0.028921\n",
      "step: 397000  d-loss: 0.019575  g-loss: 0.0 k_t: 1.8146 M_global: 0.0293624\n",
      "step: 398000  d-loss: 0.0185397  g-loss: 0.0 k_t: 1.82424 M_global: 0.0278096\n",
      "step: 399000  d-loss: 0.019579  g-loss: 0.0 k_t: 1.83388 M_global: 0.0293685\n",
      "step: 400000  d-loss: 0.0187146  g-loss: 0.0 k_t: 1.84352 M_global: 0.0280719\n",
      "step: 401000  d-loss: 0.0195405  g-loss: 0.0 k_t: 1.85315 M_global: 0.0293108\n",
      "step: 402000  d-loss: 0.0184598  g-loss: 0.0 k_t: 1.86279 M_global: 0.0276897\n",
      "step: 403000  d-loss: 0.018669  g-loss: 0.0 k_t: 1.87242 M_global: 0.0280035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 404000  d-loss: 0.0184393  g-loss: 0.0 k_t: 1.88205 M_global: 0.027659\n",
      "step: 405000  d-loss: 0.0199749  g-loss: 0.0 k_t: 1.89168 M_global: 0.0299624\n",
      "step: 406000  d-loss: 0.0189409  g-loss: 0.0 k_t: 1.90132 M_global: 0.0284113\n",
      "step: 407000  d-loss: 0.0188396  g-loss: 0.0 k_t: 1.91095 M_global: 0.0282594\n",
      "step: 408000  d-loss: 0.019726  g-loss: 0.0 k_t: 1.92058 M_global: 0.029589\n",
      "step: 409000  d-loss: 0.0196719  g-loss: 0.0 k_t: 1.9302 M_global: 0.0295078\n",
      "step: 410000  d-loss: 0.0191453  g-loss: 0.0 k_t: 1.93983 M_global: 0.028718\n",
      "step: 411000  d-loss: 0.0188853  g-loss: 0.0 k_t: 1.94946 M_global: 0.0283279\n",
      "step: 412000  d-loss: 0.0198223  g-loss: 0.0 k_t: 1.95909 M_global: 0.0297334\n",
      "step: 413000  d-loss: 0.0199538  g-loss: 0.0 k_t: 1.96871 M_global: 0.0299307\n",
      "step: 414000  d-loss: 0.0199298  g-loss: 0.0 k_t: 1.97833 M_global: 0.0298948\n",
      "step: 415000  d-loss: 0.0192819  g-loss: 0.0 k_t: 1.98795 M_global: 0.0289228\n",
      "step: 416000  d-loss: 0.0191513  g-loss: 0.0 k_t: 1.99758 M_global: 0.028727\n",
      "step: 417000  d-loss: 0.0195033  g-loss: 0.0 k_t: 2.0072 M_global: 0.0292549\n",
      "step: 418000  d-loss: 0.0183476  g-loss: 0.0 k_t: 2.01681 M_global: 0.0275214\n",
      "step: 419000  d-loss: 0.0191986  g-loss: 0.0 k_t: 2.02643 M_global: 0.0287978\n",
      "step: 420000  d-loss: 0.0190066  g-loss: 0.0 k_t: 2.03605 M_global: 0.0285099\n",
      "step: 421000  d-loss: 0.0189966  g-loss: 0.0 k_t: 2.04566 M_global: 0.028495\n",
      "step: 422000  d-loss: 0.0189434  g-loss: 0.0 k_t: 2.05528 M_global: 0.0284151\n",
      "step: 423000  d-loss: 0.0196258  g-loss: 0.0 k_t: 2.0649 M_global: 0.0294387\n",
      "step: 424000  d-loss: 0.0195993  g-loss: 0.0 k_t: 2.0745 M_global: 0.029399\n",
      "step: 425000  d-loss: 0.0187046  g-loss: 0.0 k_t: 2.08411 M_global: 0.0280569\n",
      "step: 426000  d-loss: 0.0194614  g-loss: 0.0 k_t: 2.09372 M_global: 0.0291921\n",
      "step: 427000  d-loss: 0.0191903  g-loss: 0.0 k_t: 2.10333 M_global: 0.0287854\n",
      "step: 428000  d-loss: 0.0197286  g-loss: 0.0 k_t: 2.11294 M_global: 0.0295929\n",
      "step: 429000  d-loss: 0.0193061  g-loss: 0.0 k_t: 2.12255 M_global: 0.0289592\n",
      "step: 430000  d-loss: 0.0195898  g-loss: 0.0 k_t: 2.13215 M_global: 0.0293847\n",
      "step: 431000  d-loss: 0.0187785  g-loss: 0.0 k_t: 2.14176 M_global: 0.0281677\n",
      "step: 432000  d-loss: 0.0196091  g-loss: 0.0 k_t: 2.15137 M_global: 0.0294136\n",
      "step: 433000  d-loss: 0.0194389  g-loss: 0.0 k_t: 2.16096 M_global: 0.0291584\n",
      "step: 434000  d-loss: 0.0191152  g-loss: 0.0 k_t: 2.17057 M_global: 0.0286727\n",
      "step: 435000  d-loss: 0.0199587  g-loss: 0.0 k_t: 2.18017 M_global: 0.0299381\n",
      "step: 436000  d-loss: 0.0189005  g-loss: 0.0 k_t: 2.18978 M_global: 0.0283508\n",
      "step: 437000  d-loss: 0.0196883  g-loss: 0.0 k_t: 2.19938 M_global: 0.0295325\n",
      "step: 438000  d-loss: 0.0189285  g-loss: 0.0 k_t: 2.20898 M_global: 0.0283927\n",
      "step: 439000  d-loss: 0.0189024  g-loss: 0.0 k_t: 2.21857 M_global: 0.0283535\n",
      "step: 440000  d-loss: 0.0190849  g-loss: 0.0 k_t: 2.22818 M_global: 0.0286274\n",
      "step: 441000  d-loss: 0.0190168  g-loss: 0.0 k_t: 2.23777 M_global: 0.0285251\n",
      "step: 442000  d-loss: 0.019125  g-loss: 0.0 k_t: 2.24736 M_global: 0.0286875\n",
      "step: 443000  d-loss: 0.0190668  g-loss: 0.0 k_t: 2.25696 M_global: 0.0286002\n",
      "step: 444000  d-loss: 0.0196259  g-loss: 0.0 k_t: 2.26655 M_global: 0.0294388\n",
      "step: 445000  d-loss: 0.0190438  g-loss: 0.0 k_t: 2.27613 M_global: 0.0285657\n",
      "step: 446000  d-loss: 0.0194552  g-loss: 0.0 k_t: 2.28571 M_global: 0.0291828\n",
      "step: 447000  d-loss: 0.0193605  g-loss: 0.0 k_t: 2.29529 M_global: 0.0290408\n",
      "step: 448000  d-loss: 0.0193741  g-loss: 0.0 k_t: 2.30487 M_global: 0.0290611\n",
      "step: 449000  d-loss: 0.019203  g-loss: 0.0 k_t: 2.31445 M_global: 0.0288045\n",
      "step: 450000  d-loss: 0.0188726  g-loss: 0.0 k_t: 2.32402 M_global: 0.0283089\n",
      "step: 451000  d-loss: 0.019078  g-loss: 0.0 k_t: 2.33359 M_global: 0.0286171\n",
      "step: 452000  d-loss: 0.0191939  g-loss: 0.0 k_t: 2.34316 M_global: 0.0287909\n",
      "step: 453000  d-loss: 0.0194042  g-loss: 0.0 k_t: 2.35274 M_global: 0.0291063\n",
      "step: 454000  d-loss: 0.0196853  g-loss: 0.0 k_t: 2.36231 M_global: 0.0295279\n",
      "step: 455000  d-loss: 0.0192332  g-loss: 0.0 k_t: 2.37188 M_global: 0.0288498\n",
      "step: 456000  d-loss: 0.0191273  g-loss: 0.0 k_t: 2.38144 M_global: 0.0286909\n",
      "step: 457000  d-loss: 0.0191931  g-loss: 0.0 k_t: 2.39101 M_global: 0.0287897\n",
      "step: 458000  d-loss: 0.0194323  g-loss: 0.0 k_t: 2.40058 M_global: 0.0291485\n",
      "step: 459000  d-loss: 0.0198308  g-loss: 0.0 k_t: 2.41015 M_global: 0.0297462\n",
      "step: 460000  d-loss: 0.0185614  g-loss: 0.0 k_t: 2.41971 M_global: 0.0278421\n",
      "step: 461000  d-loss: 0.018453  g-loss: 0.0 k_t: 2.42927 M_global: 0.0276794\n",
      "step: 462000  d-loss: 0.0193429  g-loss: 0.0 k_t: 2.43884 M_global: 0.0290143\n",
      "step: 463000  d-loss: 0.0185768  g-loss: 0.0 k_t: 2.4484 M_global: 0.0278651\n",
      "step: 464000  d-loss: 0.0189014  g-loss: 0.0 k_t: 2.45797 M_global: 0.0283521\n",
      "step: 465000  d-loss: 0.0190617  g-loss: 0.0 k_t: 2.46753 M_global: 0.0285926\n",
      "step: 466000  d-loss: 0.018497  g-loss: 0.0 k_t: 2.47709 M_global: 0.0277455\n",
      "step: 467000  d-loss: 0.019888  g-loss: 0.0 k_t: 2.48665 M_global: 0.029832\n",
      "step: 468000  d-loss: 0.019379  g-loss: 0.0 k_t: 2.49621 M_global: 0.0290685\n",
      "step: 469000  d-loss: 0.0187048  g-loss: 0.0 k_t: 2.50577 M_global: 0.0280572\n",
      "step: 470000  d-loss: 0.0195464  g-loss: 0.0 k_t: 2.51532 M_global: 0.0293196\n",
      "step: 471000  d-loss: 0.018312  g-loss: 0.0 k_t: 2.52488 M_global: 0.0274679\n",
      "step: 472000  d-loss: 0.0195913  g-loss: 0.0 k_t: 2.53443 M_global: 0.0293869\n",
      "step: 473000  d-loss: 0.0191263  g-loss: 0.0 k_t: 2.54399 M_global: 0.0286894\n",
      "step: 474000  d-loss: 0.018532  g-loss: 0.0 k_t: 2.55354 M_global: 0.027798\n",
      "step: 475000  d-loss: 0.0184686  g-loss: 0.0 k_t: 2.56308 M_global: 0.0277028\n",
      "step: 476000  d-loss: 0.0185892  g-loss: 0.0 k_t: 2.57263 M_global: 0.0278838\n",
      "step: 477000  d-loss: 0.0194531  g-loss: 0.0 k_t: 2.58217 M_global: 0.0291796\n",
      "step: 478000  d-loss: 0.0186531  g-loss: 0.0 k_t: 2.59171 M_global: 0.0279797\n",
      "step: 479000  d-loss: 0.0189935  g-loss: 0.0 k_t: 2.60125 M_global: 0.0284902\n",
      "step: 480000  d-loss: 0.0190564  g-loss: 0.0 k_t: 2.61079 M_global: 0.0285846\n",
      "step: 481000  d-loss: 0.0191151  g-loss: 0.0 k_t: 2.62032 M_global: 0.0286727\n",
      "step: 482000  d-loss: 0.0183538  g-loss: 0.0 k_t: 2.62986 M_global: 0.0275308\n",
      "step: 483000  d-loss: 0.0186905  g-loss: 0.0 k_t: 2.63939 M_global: 0.0280357\n",
      "step: 484000  d-loss: 0.0190672  g-loss: 0.0 k_t: 2.64892 M_global: 0.0286009\n",
      "step: 485000  d-loss: 0.0191127  g-loss: 0.0 k_t: 2.65846 M_global: 0.0286691\n",
      "step: 486000  d-loss: 0.0184304  g-loss: 0.0 k_t: 2.66799 M_global: 0.0276456\n",
      "step: 487000  d-loss: 0.0196068  g-loss: 0.0 k_t: 2.67752 M_global: 0.0294102\n",
      "step: 488000  d-loss: 0.019385  g-loss: 0.0 k_t: 2.68705 M_global: 0.0290775\n",
      "step: 489000  d-loss: 0.0188646  g-loss: 0.0 k_t: 2.69657 M_global: 0.0282968\n",
      "step: 490000  d-loss: 0.0194549  g-loss: 0.0 k_t: 2.7061 M_global: 0.0291823\n",
      "step: 491000  d-loss: 0.0194247  g-loss: 0.0 k_t: 2.71563 M_global: 0.029137\n",
      "step: 492000  d-loss: 0.0194464  g-loss: 0.0 k_t: 2.72516 M_global: 0.0291696\n",
      "step: 493000  d-loss: 0.0193406  g-loss: 0.0 k_t: 2.73468 M_global: 0.0290109\n",
      "step: 494000  d-loss: 0.0182834  g-loss: 0.0 k_t: 2.74421 M_global: 0.0274251\n",
      "step: 495000  d-loss: 0.0188383  g-loss: 0.0 k_t: 2.75373 M_global: 0.0282574\n",
      "step: 496000  d-loss: 0.0187513  g-loss: 0.0 k_t: 2.76326 M_global: 0.0281269\n",
      "step: 497000  d-loss: 0.018795  g-loss: 0.0 k_t: 2.77278 M_global: 0.0281925\n",
      "step: 498000  d-loss: 0.0184198  g-loss: 0.0 k_t: 2.7823 M_global: 0.0276298\n",
      "step: 499000  d-loss: 0.0188767  g-loss: 0.0 k_t: 2.79182 M_global: 0.028315\n",
      "step: 500000  d-loss: 0.0181081  g-loss: 0.0 k_t: 2.80134 M_global: 0.0271622\n"
     ]
    }
   ],
   "source": [
    "for step in range(500001):\n",
    "    batch_x = mnist.train.next_batch(batch_size)[0]\n",
    "    z_D = sample_Z(batch_size, g_dim)\n",
    "    sess.run([d_optimizer, g_optimizer], feed_dict={x_d: batch_x, x_g: z_D})\n",
    "    z_G = sample_Z(batch_size, g_dim)\n",
    "    sess.run(g_optimizer, feed_dict={x_g: z_G})\n",
    "#     k_t = np.maximum(np.minimum(1., k_t + 0.001*(sess.run(balancer, feed_dict={x_d: batch_x, x_g: z_G}))), 0.)\n",
    "    sess.run(update_k, feed_dict={x_d: batch_x, x_g: z_G})\n",
    "    if step%1000==0:\n",
    "        d_loss_train, g_loss_train, k_tt, M_global_train = sess.run([d_loss, g_loss, k_t, M_global], feed_dict=\n",
    "                            {x_d: batch_x, x_g: sample_Z(batch_size, g_dim)})\n",
    "#         print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_t,\"M_global:\", M_global_train\n",
    "        print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_tt,\"M_global:\", M_global_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAD8CAYAAADOg5fGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1b5ac34790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gg = sess.run(g_sample, feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(g_sample), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(decoder(x_g), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(x_d), feed_dict = {x_d: x_train})\n",
    "gg_pic = np.array([np.reshape(m,(28,28)) for m in gg])\n",
    "fig, ax = plt.subplots(nrows=3, ncols=3)\n",
    "for i,row in enumerate(ax):\n",
    "    for j,col in enumerate(row):\n",
    "        ax[i][j].imshow(gg_pic[i*3+j], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
