{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "batch_size = 256\n",
    "g_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 2, 2, 1], padding = 'SAME')\n",
    "def deconv2d(x, W, output_shape):\n",
    "    return tf.nn.conv2d_transpose(x, W, output_shape, strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "\n",
    "class layer:\n",
    "    def __init__(self, in_size, out_size):\n",
    "#         self.W = tf.Variable(tf.zeros([in_size, out_size]))\n",
    "        self.W = tf.Variable(tf.random_normal([in_size, out_size], mean=0.0, stddev=0.01))\n",
    "#         self.b = tf.Variable(tf.zeros([1,out_size]))\n",
    "#         self.b = tf.Variable(tf.constant(0.1, shape=[1,out_size]))\n",
    "        self.b = tf.Variable(tf.random_normal([1, out_size], mean=0.0, stddev=0.01))\n",
    "    \n",
    "        \n",
    "    def output(self, inputs, activation_function=None):\n",
    "        if activation_function == None:\n",
    "            return tf.matmul(inputs, self.W) + self.b\n",
    "        else :\n",
    "            return activation_function(tf.matmul(inputs, self.W) + self.b)\n",
    "        \n",
    "def weight_variable(shape):\n",
    "    '''Helper function to create a weight variable initialized with\n",
    "    a normal distribution\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    shape : list\n",
    "        Size of weight variable\n",
    "    '''\n",
    "    initial = tf.random_normal(shape, mean=0.0, stddev=0.01)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    '''Helper function to create a bias variable initialized with\n",
    "    a constant value.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    shape : list\n",
    "        Size of weight variable\n",
    "    '''\n",
    "    initial = tf.random_normal(shape, mean=0.0, stddev=0.01)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    \"w_d1\" : weight_variable([5, 5, 1, 32]),\n",
    "    \"w_d2\" : weight_variable([5, 5, 32, 64]),\n",
    "    \"w_d3\" : weight_variable([7 * 7 * 64, 1]),\n",
    "    \n",
    "    \"w_g1\" : weight_variable([g_dim, 4 * 4 * 64]),\n",
    "    \"w_g2\" : weight_variable([5, 5, 32, 64]),\n",
    "    \"w_g3\" : weight_variable([5, 5, 16, 32]),\n",
    "    \"w_g4\" : weight_variable([5, 5, 1, 16])\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    \"b_d1\" : bias_variable([32]),\n",
    "    \"b_d2\" : bias_variable([64]),\n",
    "    \"b_d3\" : bias_variable([1]),\n",
    "    \"b_g1\" : bias_variable([4 * 4 * 64]),\n",
    "    \"b_g2\" : bias_variable([32]),\n",
    "    \"b_g3\" : bias_variable([16]),\n",
    "    \"b_g4\" : bias_variable([1]),\n",
    "}\n",
    "\n",
    "var_d = [weights[\"w_d1\"], weights[\"w_d2\"], weights[\"w_d3\"], biases[\"b_d1\"], biases[\"b_d2\"], biases[\"b_d3\"]]\n",
    "var_g = [weights[\"w_g1\"], weights[\"w_g2\"],weights[\"w_g3\"], weights[\"w_g4\"], biases[\"b_g1\"], biases[\"b_g2\"],biases[\"b_g3\"], biases[\"b_g4\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z):\n",
    "    #100 x 1\n",
    "    h_g1 = tf.nn.relu(tf.add(tf.matmul(z, weights[\"w_g1\"]), biases[\"b_g1\"]))\n",
    "    #-1 x 4*4*128\n",
    "    h_g1_reshape = tf.reshape(h_g1, [-1, 4, 4, 64])\n",
    "    \n",
    "    output_shape_g2 = tf.stack([tf.shape(z)[0], 7, 7, 32])\n",
    "    h_g2 = tf.nn.relu(tf.add(deconv2d(h_g1_reshape, weights[\"w_g2\"], output_shape_g2), biases[\"b_g2\"]))\n",
    "    \n",
    "    output_shape_g3 = tf.stack([tf.shape(z)[0], 14, 14, 16])\n",
    "    h_g3 = tf.nn.relu(tf.add(deconv2d(h_g2, weights[\"w_g3\"], output_shape_g3), biases[\"b_g3\"]))\n",
    "    \n",
    "    output_shape_g4 = tf.stack([tf.shape(z)[0], 28, 28, 1])\n",
    "    h_g4 = tf.nn.tanh(tf.add(deconv2d(h_g3, weights[\"w_g4\"], output_shape_g4), biases[\"b_g4\"]))\n",
    "    \n",
    "    return h_g4\n",
    "\n",
    "\n",
    "def discriminator(x):\n",
    "    x_reshape = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    # 28 x 28 x 1\n",
    "    h_d1 = tf.nn.relu(tf.add(conv2d(x_reshape, weights[\"w_d1\"]), biases[\"b_d1\"]))\n",
    "    # 14 x 14 x 32\n",
    "    h_d2 = tf.nn.relu(tf.add(conv2d(h_d1, weights[\"w_d2\"]), biases[\"b_d2\"]))\n",
    "    # 7 x 7 x 64\n",
    "    h_d2_reshape = tf.reshape(h_d2, [-1, 7 * 7 * 64])\n",
    "    h_d3 = tf.nn.sigmoid(tf.add(tf.matmul(h_d2_reshape, weights[\"w_d3\"]), biases[\"b_d3\"]))\n",
    "    return h_d3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_d = tf.placeholder(tf.float32, shape = [None, 784])\n",
    "x_g = tf.placeholder(tf.float32, shape = [None, g_dim])\n",
    "\n",
    "def sample_Z(m, n):\n",
    "    return np.random.uniform(-1., 1., size=[m, n])\n",
    "\n",
    "def loss(x):\n",
    "#     return tf.reduce_mean(tf.pow(x-y, 2))\n",
    "    return tf.reduce_mean(tf.pow(x-discriminator(x), 2))\n",
    "\n",
    "def gamma(x,z):\n",
    "    return loss(generator(z))/loss(x)\n",
    "\n",
    "k_t = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g_sample = generator(x_g)\n",
    "# d_real = discriminator(x_d)\n",
    "# d_fake = discriminator(g_sample)\n",
    "\n",
    "d_loss = loss(x_d)-k_t*loss(generator(x_g))\n",
    "g_loss = loss(generator(x_g))\n",
    "\n",
    "# d_loss = -tf.reduce_mean(tf.log(d_real) + tf.log(1. - d_fake))\n",
    "# g_loss = -tf.reduce_mean(tf.log(d_fake))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 只更新 discriminator\n",
    "d_optimizer = tf.train.AdamOptimizer(0.00003).minimize(d_loss, var_list= var_d)\n",
    "# d_optimizer = tf.train.MomentumOptimizer(0.01,0.01).minimize(d_loss, var_list= var_d)\n",
    "# 只更新 generator parameters\n",
    "g_optimizer = tf.train.AdamOptimizer(0.00003).minimize(g_loss, var_list= var_g)\n",
    "# g_optimizer = tf.train.MomentumOptimizer(0.03,0.03).minimize(g_loss, var_list= var_g)\n",
    "\n",
    "balancer = gamma(x_d, x_g)*loss(x_d) - loss(generator(x_g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[256,14,14,32]\n\t [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Reshape, Variable/read)]]\n\nCaused by op u'Conv2D', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-260b1f8a7ab4>\", line 5, in <module>\n    d_loss = loss(x_d)-k_t*loss(generator(x_g))\n  File \"<ipython-input-8-1ddf8617ea59>\", line 9, in loss\n    return tf.reduce_mean(tf.pow(x-discriminator(x), 2))\n  File \"<ipython-input-5-da3b217d15cb>\", line 22, in discriminator\n    h_d1 = tf.nn.relu(tf.add(conv2d(x_reshape, weights[\"w_d1\"]), biases[\"b_d1\"]))\n  File \"<ipython-input-3-23c84b45bc14>\", line 2, in conv2d\n    return tf.nn.conv2d(x, W, strides=[1, 2, 2, 1], padding = 'SAME')\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 631, in conv2d\n    data_format=data_format, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[256,14,14,32]\n\t [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Reshape, Variable/read)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b85b2a7ea9f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mbatch_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#     _, d_loss_train = sess.run([d_optimizer, d_loss], feed_dict={x_d: batch_x, x_g: sample_Z(batch_size, g_dim)})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx_d\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_g\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msample_Z\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m#     _, g_loss_train = sess.run([g_optimizer, g_loss], feed_dict={x_g: sample_Z(batch_size, g_dim)})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx_g\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msample_Z\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[256,14,14,32]\n\t [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Reshape, Variable/read)]]\n\nCaused by op u'Conv2D', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-260b1f8a7ab4>\", line 5, in <module>\n    d_loss = loss(x_d)-k_t*loss(generator(x_g))\n  File \"<ipython-input-8-1ddf8617ea59>\", line 9, in loss\n    return tf.reduce_mean(tf.pow(x-discriminator(x), 2))\n  File \"<ipython-input-5-da3b217d15cb>\", line 22, in discriminator\n    h_d1 = tf.nn.relu(tf.add(conv2d(x_reshape, weights[\"w_d1\"]), biases[\"b_d1\"]))\n  File \"<ipython-input-3-23c84b45bc14>\", line 2, in conv2d\n    return tf.nn.conv2d(x, W, strides=[1, 2, 2, 1], padding = 'SAME')\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 631, in conv2d\n    data_format=data_format, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[256,14,14,32]\n\t [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Reshape, Variable/read)]]\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(20001):\n",
    "    batch_x = mnist.train.next_batch(batch_size)[0]\n",
    "#     _, d_loss_train = sess.run([d_optimizer, d_loss], feed_dict={x_d: batch_x, x_g: sample_Z(batch_size, g_dim)})\n",
    "    sess.run(d_optimizer, feed_dict={x_d: batch_x, x_g: sample_Z(batch_size, g_dim)})\n",
    "#     _, g_loss_train = sess.run([g_optimizer, g_loss], feed_dict={x_g: sample_Z(batch_size, g_dim)})\n",
    "    sess.run(g_optimizer, feed_dict={x_g: sample_Z(batch_size, g_dim)})\n",
    "    k_t = k_t + 0.001*(sess.run(balancer, feed_dict={x_d: batch_x, x_g: sample_Z(batch_size, g_dim)}))\n",
    "    if step%1000==0:\n",
    "        d_loss_train, g_loss_train = sess.run([d_loss, g_loss], feed_dict=\n",
    "                            {x_d: batch_x, x_g: sample_Z(batch_size, g_dim)})\n",
    "        print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train\n",
    "\n",
    "zz = sample_Z(batch_size, g_dim)\n",
    "gg = sess.run(g_sample, feed_dict = {x_g: zz})\n",
    "# gg = sess.run(g_sample, feed_dict = {x_g: sample_Z(batch_size, g_dim)})\n",
    "gg_pic = np.array([np.reshape(m,(28,28)) for m in gg])\n",
    "fig, ax = plt.subplots(nrows=3, ncols=3)\n",
    "for i,row in enumerate(ax):\n",
    "    for j,col in enumerate(row):\n",
    "        ax[i][j].imshow(gg_pic[i*3+j], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
