{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "x_train = mnist.train.images\n",
    "y_train = mnist.train.labels\n",
    "x_test = mnist.test.images\n",
    "y_test = mnist.test.labels\n",
    "batch_size = 256\n",
    "g_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 2, 2, 1], padding = 'SAME')\n",
    "def deconv2d(x, W, output_shape):\n",
    "    return tf.nn.conv2d_transpose(x, W, output_shape, strides = [1, 2, 2, 1], padding = 'SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class layer:\n",
    "    def __init__(self, in_size, out_size):\n",
    "        self.W = tf.Variable(tf.random_normal([in_size, out_size], mean=0.0, stddev=0.1))\n",
    "        self.b = tf.Variable(tf.random_normal([1, out_size], mean=0.0, stddev=0.1))\n",
    "    def output(self, inputs, activation_function=None):\n",
    "        if activation_function == None:\n",
    "            return tf.matmul(inputs, self.W) + self.b\n",
    "        else :\n",
    "            return activation_function(tf.matmul(inputs, self.W) + self.b)\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.random_normal(shape, mean=0.0, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.random_normal(shape, mean=0.0, stddev=0.1)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_e = layer(4*4*64, g_dim)\n",
    "layer_d = layer(g_dim, 4*4*64)\n",
    "layer_g = layer(g_dim, 4*4*64)\n",
    "\n",
    "encoder_var = {\n",
    "    \"W_e_conv1\" : weight_variable([3,3, 1,16]),\n",
    "    \"W_e_conv2\" : weight_variable([3,3,16,32]),\n",
    "    \"W_e_conv3\" : weight_variable([3,3,32,64]),\n",
    "    \"b_e_conv1\" : bias_variable([16]),   \n",
    "    \"b_e_conv2\" : bias_variable([32]),\n",
    "    \"b_e_conv3\" : bias_variable([64])\n",
    "}\n",
    "\n",
    "decoder_var = {\n",
    "    \"W_d_conv1\" : weight_variable([3,3,32,64]),\n",
    "    \"W_d_conv2\" : weight_variable([3,3,16,32]),\n",
    "    \"W_d_conv3\" : weight_variable([3,3, 1,16]),\n",
    "    \"b_d_conv1\" : bias_variable([32]),\n",
    "    \"b_d_conv2\" : bias_variable([16]),\n",
    "    \"b_d_conv3\" : bias_variable([1])\n",
    "}\n",
    "\n",
    "generator_var = {\n",
    "    \"W_d_conv1\" : weight_variable([3,3,32,64]),\n",
    "    \"W_d_conv2\" : weight_variable([3,3,16,32]),\n",
    "    \"W_d_conv3\" : weight_variable([3,3, 1,16]),\n",
    "    \"b_d_conv1\" : bias_variable([32]),\n",
    "    \"b_d_conv2\" : bias_variable([16]),\n",
    "    \"b_d_conv3\" : bias_variable([1])\n",
    "}\n",
    "\n",
    "var_d = [encoder_var[e] for e in encoder_var]+[decoder_var[d] for d in decoder_var]+[layer_e.W, layer_e.b, layer_d.W, layer_d.b]\n",
    "var_g = [generator_var[g] for g in generator_var]+[layer_g.W, layer_g.b]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(x):\n",
    "    x_origin = tf.reshape(x, [-1,28,28,1])      #28x28x1\n",
    "    h_e_conv1 = tf.nn.relu(tf.add(conv2d(x_origin, encoder_var[\"W_e_conv1\"]), encoder_var[\"b_e_conv1\"]))     #14x14x16\n",
    "    h_e_conv2 = tf.nn.relu(tf.add(conv2d(h_e_conv1, encoder_var[\"W_e_conv2\"]), encoder_var[\"b_e_conv2\"]))    #7x7x32\n",
    "    h_e_conv3 = tf.nn.relu(tf.add(conv2d(h_e_conv2, encoder_var[\"W_e_conv3\"]), encoder_var[\"b_e_conv3\"]))    #4x4x64\n",
    "    h_e_conv3_reshape = tf.reshape(h_e_conv3, [-1,4*4*64])\n",
    "    h_e_layer = layer_e.output(h_e_conv3_reshape, tf.nn.relu)\n",
    "#     h_e_layer = layer_e.output(h_e_conv3_reshape, tf.nn.sigmoid)\n",
    "    return h_e_layer\n",
    "    \n",
    "def decoder(z):\n",
    "    h_d_layer = layer_d.output(z, tf.nn.relu)\n",
    "#     h_d_layer = layer_d.output(z, tf.nn.sigmoid)\n",
    "    h_d_layer_reshape = tf.reshape(h_d_layer, [-1,4,4,64])\n",
    "    \n",
    "    output_shape_d_conv1 = tf.stack([tf.shape(z)[0], 7, 7, 32])\n",
    "    h_d_conv1 = tf.nn.relu(deconv2d(h_d_layer_reshape, decoder_var[\"W_d_conv1\"], output_shape_d_conv1)+decoder_var[\"b_d_conv1\"])\n",
    "\n",
    "    output_shape_d_conv1 = tf.stack([tf.shape(z)[0], 14, 14, 16])\n",
    "    h_d_conv2 = tf.nn.relu(deconv2d(h_d_conv1, decoder_var[\"W_d_conv2\"], output_shape_d_conv1)+decoder_var[\"b_d_conv2\"])\n",
    "\n",
    "    output_shape_d_conv2 = tf.stack([tf.shape(z)[0], 28, 28, 1])\n",
    "    h_d_conv3 = tf.nn.relu(deconv2d(h_d_conv2, decoder_var[\"W_d_conv3\"], output_shape_d_conv2)+decoder_var[\"b_d_conv3\"])\n",
    "    return h_d_conv3\n",
    "\n",
    "def generator(z):\n",
    "    h_d_layer = layer_g.output(z, tf.nn.relu)\n",
    "#     h_d_layer = layer_d.output(z, tf.nn.sigmoid)\n",
    "    h_d_layer_reshape = tf.reshape(h_d_layer, [-1,4,4,64])\n",
    "    \n",
    "    output_shape_d_conv1 = tf.stack([tf.shape(z)[0], 7, 7, 32])\n",
    "    h_d_conv1 = tf.nn.relu(deconv2d(h_d_layer_reshape, generator_var[\"W_d_conv1\"], output_shape_d_conv1)+generator_var[\"b_d_conv1\"])\n",
    "\n",
    "    output_shape_d_conv1 = tf.stack([tf.shape(z)[0], 14, 14, 16])\n",
    "    h_d_conv2 = tf.nn.relu(deconv2d(h_d_conv1, generator_var[\"W_d_conv2\"], output_shape_d_conv1)+generator_var[\"b_d_conv2\"])\n",
    "\n",
    "    output_shape_d_conv2 = tf.stack([tf.shape(z)[0], 28, 28, 1])\n",
    "    h_d_conv3 = tf.nn.relu(deconv2d(h_d_conv2, generator_var[\"W_d_conv3\"], output_shape_d_conv2)+generator_var[\"b_d_conv3\"])\n",
    "    return h_d_conv3\n",
    "\n",
    "def discriminator(x):\n",
    "    return decoder(encoder(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_Z(m, n):\n",
    "    return np.random.uniform(-1., 1., size=[m, n])\n",
    "\n",
    "def loss(x):\n",
    "#     return tf.reduce_mean(tf.pow(tf.reshape(x, [-1, 784]) - tf.reshape(discriminator(x), [-1, 784]), 2))\n",
    "    return tf.reduce_mean(tf.abs(tf.reshape(x, [-1, 784]) - tf.reshape(discriminator(x), [-1, 784])))\n",
    "#     return tf.pow(tf.reshape(x, [-1, 784]) - tf.reshape(discriminator(x), [-1, 784]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_d = tf.placeholder(tf.float32, shape = [None, 784])\n",
    "x_g = tf.placeholder(tf.float32, shape = [None, g_dim])\n",
    "\n",
    "gamma = 0.5\n",
    "# k_t = 0.\n",
    "k_t = tf.Variable(0.0, tf.float32)\n",
    "\n",
    "# d_loss = loss(x_d)-k_t*loss(generator(x_g))\n",
    "# d_loss = loss(x_d)\n",
    "d_loss = tf.reduce_mean(loss(x_d)-k_t*loss(generator(x_g)))\n",
    "# g_loss = loss(generator(x_g))\n",
    "g_loss = tf.reduce_mean(loss(generator(x_g)))\n",
    "\n",
    "g_sample = generator(x_g)\n",
    "\n",
    "M_global = loss(x_d) + tf.abs(gamma*loss(x_d) - loss(generator(x_g)))\n",
    "\n",
    "d_optimizer = tf.train.AdamOptimizer(0.00001).minimize(d_loss, var_list= var_d)\n",
    "g_optimizer = tf.train.AdamOptimizer(0.00001).minimize(g_loss, var_list= var_g)\n",
    "\n",
    "# balancer = gamma*loss(x_d) - loss(generator(x_g))\n",
    "balancer = tf.reduce_mean(gamma*loss(x_d) - loss(generator(x_g)))\n",
    "# update_k = k_t.assign(k_t + 0.001 * balancer)\n",
    "update_k = tf.assign(k_t, tf.clip_by_value(k_t + 0.001 * balancer, 0, 1))\n",
    "# tf.clip_by_value(self.k_t + self.lambda_k * self.balance, 0, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0  d-loss: 0.13814  g-loss: 0.0165961 k_t: 5.21346e-05 M_global: 0.190616\n",
      "step: 1000  d-loss: 0.128975  g-loss: 0.0128923 k_t: 0.0594824 M_global: 0.18172\n",
      "step: 2000  d-loss: 0.12127  g-loss: 0.0324558 k_t: 0.0996548 M_global: 0.1543\n",
      "step: 3000  d-loss: 0.103622  g-loss: 0.108275 k_t: 0.0877488 M_global: 0.164837\n",
      "step: 4000  d-loss: 0.102879  g-loss: 0.0946781 k_t: 0.0345127 M_global: 0.147751\n",
      "step: 5000  d-loss: 0.0990281  g-loss: 0.0603969 k_t: 0.012146 M_global: 0.110278\n",
      "step: 6000  d-loss: 0.0978382  g-loss: 0.0479486 k_t: 0.00697664 M_global: 0.0993105\n",
      "step: 7000  d-loss: 0.0911234  g-loss: 0.0403898 k_t: 0.013137 M_global: 0.0970913\n",
      "step: 8000  d-loss: 0.0934109  g-loss: 0.0510606 k_t: 0.00833031 M_global: 0.0979788\n",
      "step: 9000  d-loss: 0.0949561  g-loss: 0.0461363 k_t: 0.0091009 M_global: 0.0969277\n",
      "step: 10000  d-loss: 0.0903684  g-loss: 0.052445 k_t: 0.00456248 M_global: 0.0977489\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(10001):\n",
    "    batch_x = mnist.train.next_batch(batch_size)[0]\n",
    "    z_D = sample_Z(batch_size, g_dim)\n",
    "    sess.run([d_optimizer, g_optimizer], feed_dict={x_d: batch_x, x_g: z_D})\n",
    "    z_G = sample_Z(batch_size, g_dim)\n",
    "    sess.run(g_optimizer, feed_dict={x_g: z_G})\n",
    "#     k_t = np.maximum(np.minimum(1., k_t + 0.001*(sess.run(balancer, feed_dict={x_d: batch_x, x_g: z_G}))), 0.)\n",
    "    sess.run(update_k, feed_dict={x_d: batch_x, x_g: z_G})\n",
    "    if step%1000==0:\n",
    "        d_loss_train, g_loss_train, M_global_train = sess.run([d_loss, g_loss, M_global], feed_dict=\n",
    "                            {x_d: batch_x, x_g: sample_Z(batch_size, g_dim)})\n",
    "#         print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_t,\"M_global:\", M_global_train\n",
    "        print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', sess.run(k_t),\"M_global:\", M_global_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAD8CAYAAADOg5fGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAHapJREFUeJzt3XuMFfX9//HnW65yWdkVpBSXoqAY\nWAMV6NdW862mpZVWwf0WUZqArjdqrBG/2irWC2iN1ktpY2wT06JgGi+RWm1TatHy09r+bEDTRoSi\ntPGCRRGxIlhAfr5/f+wcdkV2z5wz9+H1SE72nDlzZt6cF/vZz8x8ZsbcHRERqc9BWRcgIlJkakRF\nRCJQIyoiEoEaURGRCNSIiohEoEZURCQCNaIiIhFEakTN7BQzW29mG8zsqriKkmwp1/JStvGzegfb\nm1kP4CVgCrARWAXMcve18ZUnaVOu5aVsk9Ezwmc/B2xw938CmNkDwHSgy0DM7EA/PWqLuw/Juogq\nlGvtipAr1Jitcg2Xa5TN+eHA651ebwymSddezbqAEJRr7YqQKyjbWoXKNUpPNBQzuxC4MOn1SLqU\nazkp19pFaUTfAJo7vT48mPYx7n43cDdo86AglGt5Vc1WudYuyub8KuAoMzvCzHoDZwGPxVOWZEi5\nlpeyTUDdPVF332Nm3wYeB3oAi939xdgqk0wo1/JStsmoe4hTXSvT5sFz7j4p6yLiplyVa0mFyvWA\nOmOpb9++9O3bN+syRKREDqhGVEQkbokPcUpaa2srAI888kjVeXfu3Jl0OfTq1QuADz/8MPF1ldmM\nGTMAePjhhzOupF1TUxMAW7duzbiSYrvxxhsBuPbaayMt57DDDgNg8+bNkZZz/PHHA/Dss8/WvQz1\nREVEItCBpXTpAEQ5Kddy0oElEZGkqREVEYmgNI3okUceyZFHHpl1GRKzcePGMW7cuKzLkJhNmzaN\nadOmZV1GLErTiIqIZKHwQ5wWL14MwLnnntvlPI2NjQB89NFHALz33nvJFyaRrFq1CoDJkyd3Oc+h\nhx4KdAwre/PNN5MvTCJ59913gY7fyf2pbFFWhjFFGX5UzcEHHwzAf/7zn7qXoZ6oiEgEhR/iNHDg\nQAB27doFwO7du+taTuWv3kUXXQTAwoULY6juEzQUJqSePds3kvbs2RNpOb179wbgzjvvBGDu3LnR\nCts/5ZqRBx98EIAzzzwzicVriJOISNLUiIqIROHu3T6AxcBmYE2naU3ACuDl4GdjteUEn/O8PSZM\nmOATJkxIa32rw3xPaTzKnuuMGTN8xowZB1yucWabdYb7e5x55pl+5pln5irXMD3Re4FT9pl2FfCk\nux8FPBm8lmK5F+VaVveibFMT6sCSmY0EfuPuLcHr9cBJ7r7JzIYB/8fdx4RYTvWV1ahyQOi+++4D\n4Ktf/WrVz4waNWrv88qBqc9//vMAfPDBBwAsWbIk1joDuToAkedcK8OXbrvtNqD7IWwVkyZ1fLXj\nx48HYNiwYQAMHToUgEsuuSTWOgO5yhXiyTbJA4aVA8E9evSo+pmRI0fuff7FL34RgE9/+tMAewfs\nV35/YxYq13rHiQ51903B8zeBoV3NqLsHFopyLa9Q2SrX2tXbE/23uw/q9P677t716NmO+WL/y1aL\n2bNnAx291gzkqsdSllxvvvlmAObPn59VCbnKFeLJNutcf/3rXwNw2mmnZVVCokOc3go2CQh+Rrsy\nquSFci0vZZuQejfnHwPOBm4Jfj4aW0U1qvSkzazqvGn0QBsaGgDYtm1b4utKQG5yrZyie9BB1f/O\nd9cDHTFiBACvvfZaPIUVVy6yfeGFFwA49thjq87bXQ+0ss/8nXfeiaewCKr+DzWz+4H/C4wxs41m\ndh7tQUwxs5eBLwevpUCUa3kp23RV7Ym6+6wu3vpSzLVIipRreSnbdBX+3PmCyd0BiDgoV+WahH79\n+gEdww4zoHPnRUSSVvjriVZcdtllACxatKjLeSqDdl955ZUUKpI4VA4uVIa77M+gQe0jd/79739/\n4r3KIPu33norgeokCS0tLQCMHTsWgIceeijLcqpST1REJILC90RXr14NfPyUv31V/pLddNNNqdQk\n0YUZuvbb3/4W6Dg1dOXKlZ+Y5/3330+gOqlXmFz/8Ic/APCd73yny3niuCJ9XNQTFRGJQI2oiEgE\nGuK0j8rVYf71r38lsXgNhclIwgeYlGs5aYiTiEjSCn9gKW4J9UAlYxriJElRT1REJAI1ooHjjjuO\n4447LusyZB/Tp09n+vTpdX++paVl7+BtyY+2tjba2trq/nxrayutra0xVlQ/NaIiIhEcUEfnZ8yY\nAcDDDz+cVQk6ipuAa665BoDvf//7WZWgXBNQOZnia1/7WlYlxHN03syazWylma01sxfN7NJgepOZ\nrTCzl4OfVW8jIfmhXMtJuaYvzOb8HuBydx8LHA9cbGZj0S1Yi065lpNyTVuYm9N3ftB+W4EpwHpg\nWDBtGLA+xGc97sfcuXN97ty5kZfT0NDgDQ0Nsde3z2N1rd93Wo+85Xrdddf5ddddF3k58+bN83nz\n5kVeTv/+/b1///7KNeJj0aJFvmjRosjLmTlzps+cOTPycpqbm725uTlSrjWNEw3uIPhZ4C/oFqyl\noVzLSbmmpIa/aAOA54D/CV7/e5/3383iL1stj4kTJ/rEiROzrCF3PZYy5LpgwQJfsGCBci1Zrhdc\ncIFfcMEFuc811BAnM+sFLAN+4e6/DCbrFqwFp1zLSbmmq+rmvLVf+O/nwDp3/2Gnt3JxC9YwKtce\n3LVrFwCHH3743vc2btyYSU1ZK0Ou06ZNA2D79u0AzJs3b+97P/rRjzKpKWtlyPWwww4DYM+ePQBc\nfPHFe9+76667MqmpO2H2iZ4AzAZeMLO/BtOupj2Mh4Lbsb4KzEymREmIci0n5ZqyMLdMfgbo6jLU\nugVrQSnXclKu6Sv8VZyGDx8OwBtvvNHlPJXNvgcffLDLefr06QN0bPJLtgYOHAh0f3uPyZMnA3Dt\ntdd2Oc/UqVMBWL58eYzVSZKuvvpq4OO7Z/Z14oknAvDMM8+kUlN3dO68iEgEB9S58zmgc6zLSbmW\nk65sLyKSNDWiIiIRqBEVEYlAjaiISARqREVEIlAjKiISgRpREZEI1IiKiESQ9mmfW4Adwc+iGUz0\nuj8TRyE5pFzLSbmGkOoZSwBmtrqIZ3cUte60FPX7KWrdaSnq95Nm3dqcFxGJQI2oiEgEWTSid2ew\nzjgUte60FPX7KWrdaSnq95Na3anvExURKRNtzouIRKBGVEQkgtQaUTM7xczWm9kGM7sqrfXWysya\nzWylma01sxfN7NJgepOZrTCzl4OfjVnXmhdFyFa51k65hqwhjX2iZtYDeAmYAmwEVgGz3H1t4iuv\nUXBP7mHu/ryZDQSeA04HzgG2uvstwX+oRne/MsNSc6Eo2SrX2ijX8NLqiX4O2ODu/3T33cADwPSU\n1l0Td9/k7s8Hz98H1gHDaa93STDbEtqDkoJkq1xrplxDitSI1tDdHw683un1xmBarpnZSOCzwF+A\noe6+KXjrTWBoRmUlrsbNuMJle6DmCuX+nc0q17ob0aC7fxcwFRgLzDKzsXEVljUzGwAsA+a5+7bO\n73n7PpBSjg1TruXMFcqdbaa5untdD+DzwOOdXs8H5nc3b/APOZAfb9f7faf1qCXXTvNn/b1m/ch9\nrnX+zmb9vWb9CJVrlKs47a+7/1/7zmRmFwIXAsdGWFdZvJp1ASHUmqsUI1cIka1y/ZhQuSZ+YMnd\n7/b2q6m0Jr0uSU8lVy/gFX6ka8q1dlEa0TeA5k6vDw+m7Ze7/zbCuiQ9NeUqhaJsExClEV0FHGVm\nR5hZb+As4LF4ypIMKdfyUrYJqHufqLvvMbNv037AqAew2N1fjK0yyYRyLS9lm4xUr+JkZumtLJ+e\nK+O+JuWqXEsqVK66AImISARqREVEIih8IzpixAhGjBiRdRl79ezZk549076Javm0tLTQ0tKSdRl7\nTZkyhSlTpmRdRuG1tbXR1taWdRl7DRkyhCFDhkRaRuEbURGRLOnAUrp0AKKclGs56cCSiEjS1IiK\niESgRlREJAI1oiIiERR+LM4VV1wBwO233x5pOf379wdgx44dkWuS6ObPnw/AzTff3OU8vXv3BqBX\nr15AstkNGzYMgE2bNlWZU7rzxBNPAPDlL3+5y3nGjBnzsdfr16//xDyHHHIIAO+9916M1dVHPVER\nkQgKP8Rp6tSpAIwePRqAO++8s67lVAbIX3TRRZGWU4WGwoQ0btw4AN566y0AtmzZUtdyKlsYs2bN\nAuBnP/tZDNV9gnLNSGXg/j333JPE4jXESUQkaVUbUTNbbGabzWxNp2lNZrbCzF4OfjYmW6bETbmW\nl7JNV9XNeTP7b2A7sNTdW4JptwJb3f2W4Larje5+ZdWVxbR5cPzxx+99/uyzz0ZaVmtr+11LHnnk\nkUjLCSk3m315zDVOlf8j+/7/MLO9z2PclZWbXCG+bPOYa2X33fLly9NYXTyb8+7+NLB1n8nTgSXB\n8yXA6TWXJ5lSruWlbNNV7xCnoe5eGevxJjA0pnpCqRxEAjjmmGOAjh3LnXsaXel8daCBAwcCHX/h\nzj77bADOOuuseIotlkxz7awyfKlyYKmxsfrWZ2UYEsCAAQMAOPXUUwE49tj2m812N2Sq5HKTLcDi\nxYsBOPfcc6vOO3HixL3PBw0aBMC3vvUtAL7+9a8DcNppp8VdYmiRx4m6u3fX7dctWItJuZZXd9kq\n1zqEuTk9MBJY0+n1emBY8HwYsD7kcryeR2Njozc2Ntb12c6Pk08+2U8++eTIy4nwWB3me0rrkXWu\ncT3GjRvn48aNU64xZ5vV99mnTx/v06eP33HHHX7HHXfkPtd6hzg9BpwdPD8beLTO5Ui+KNfyUrZJ\nCfHX6H5gE/AhsBE4DzgUeBJ4GXgCaMqqx7Jjxw7fsWNHbH/9oi6noaHBGxoaIv1lS6mnkutcK5JY\ndj2PXr16ea9evXKfa5zZJvE9rl271teuXRt5OWPHjvWxY8cmnXuoXKvuE3X3WV289aVqn5X8Uq7l\npWzTpTOWREQiKPy58wWTq0HZcVGuyrWkdO68iEjSCn890Yo5c+YAsHTp0i7nqVyncH/XJ5R8+tWv\nfgXA6ad3fYLNYYcdBsDmzZtTqUmiu+GGGwC47rrrPvFev379ADj00EMBeP3119MrrA7qiYqIRFD4\nnuiqVasAmDx5cpfzXHvttQA8/vjjqdQk0b3zzjtAR29kf37yk58A8OMf/xhItidaOY10+/btia3j\nQFA5BtPd6dnXXHMNAL/5zW8A9URFREpNjaiISAQa4rSPPn36ALBr164kFq+hMBkZMmQIAG+//XYS\ni1eu5aQhTiIiScvNgaXKjuY0e8b7k1APVDKWUA9URD1REZEoctMTzboHOn78eAD+9re/ZVqHxOsL\nX/gCAH/+858zrkQ6q9xdYs2aNVXm7LjtNcCOHTsAaG5uBvIx/Ek9URGRKEJcU7AZWAmsBV4ELg2m\nNwEraL8+4Qra7x6Y+vUJa3m0tbV5W1tbljXk5rqTZcr1jDPO8DPOOEO5lizXRYsW+aJFi3Kfa5ie\n6B7gcncfCxwPXGxmY4GrgCfd/SjaL/Z6VYhlSX4o13JSrikLc8vkTe7+fPD8fWAdMBzdgrXQlGs5\nKdf01TTY3sxGAk8DLcBr7j4omG7Au5XX3Xw+/MpC+spXvgLA73//+0jLGTq0/Q6ylVv0JiSXg7Lz\nmGvlltUPPPBApOWcfPLJAKxcuTLSciq3bH733Xf397ZyDWnZsmUAfOMb34i0nMGDBwOwZcuWyDV1\nI1SuoY/Om9kAYBkwz923db6AgLtuwVpUyrWclGuKQu6s7gU8Dvxvp2mFuQVr5TFq1CgfNWpU7ndU\np3gQohS5tra2emtrq3ItWa7XX3+9X3/99bnPteo+0aDr/3Ngnbv/sNNbugVrgSnXclKu6au6T9TM\nTgT+CLwAfBRMvhr4C/AQMAJ4FZjp7lurLKv7lSWkci3IyrUpe/bs2Ivxj3/8I81ScrPvrAy5VvaL\nVXLdurWjzJRP81SuMWprawPgiCOOAGDdunV737v//vvTLCWefaLu/gzQ1RVUdQvWglKu5aRc06cz\nlkREIsjNufP1Gj16NAAbNmzocp6JEycC8NRTT6VSk0RXZUgR0HFLmOXLl3c5z4QJEwD461//GmN1\nUq8wv69HHXUUAFdffXUqNUWlnqiISAS6sn26cnMAIk7KVbmWlK5sLyKSNDWiIiIRqBEVEYlAjaiI\nSARqREVEIlAjKiISgRpREZEI1IiKiESQ9mmfW4Adwc+iGUz0uj8TRyE5pFzLSbmGkOoZSwBmtrqI\nZ3cUte60FPX7KWrdaSnq95Nm3dqcFxGJQI2oiEgEWTSid2ewzjgUte60FPX7KWrdaSnq95Na3anv\nExURKRNtzouIRJBaI2pmp5jZejPbYGZXpbXeWplZs5mtNLO1ZvaimV0aTG8ysxVm9nLwszHrWvOi\nCNkq19op15A1pLE5b2Y9gJeAKcBGYBUwy93XJr7yGpnZMNrvz/28mQ0EngNOB84Btrr7LcF/qEZ3\nvzLDUnOhKNkq19oo1/DS6ol+Dtjg7v90993AA8D0lNZdE3ff5O7PB8/fB9YBw2mvd0kw2xLag5KC\nZKtca6ZcQ4rUiNbQ3R8OvN7p9cZgWq6Z2Ujgs7Tfs3uou28K3noTGJpRWYmrcTOucNkeqLlCuX9n\ns8q17kY06O7fBUwFxgKzzGxsXIVlzcwGAMuAee6+rfN73r4PpJTDGpRrOXOFcmebZa5ReqK1dPff\nAJo7vT48mJZLZtaL9kB+4e6/DCa/Fex/qeyH2ZxVfQmrdTOuMNke4LlCSX9ns8617gNLZjYDOMXd\nzw9ezwb+y92/vZ95e9K+k/qICLWWwRZ3H5J1Ed2pJdfg/Z7AhymWmEe5zxXq+p1VriFyTfzAkpld\nCDwL/L8kln/QQQdx0EGFGe76atYFxMXMLjSz1bRnm1tmhpklvRrlWk6hco1yKbxQ3X13v5vgFKwk\n7mP90Ucfxb3IA10uco2Lzsj7mKrZFiXXPInShVsFHGVmR5hZb+As4LF4ypIMKdfyUrYJqLsn6u57\nzOzbwONAD2Cxu78YW2WSCeVaXso2GalegESbBzxXxAvcVqNclWtJhcq1MEdkRETySI2oiEgEakRF\nRCIofCO6cOFCFi5cmHUZe40aNYpRo0ZlXUbhtbS00NLSknUZErPZs2cze/bsrMvYq6mpiaampkjL\nKHwjKiKSJR2dT5eO4paTci0nHZ0XEUmaGlERkQhK04jOmTOHOXPmZF2GxGzw4MEMHjw46zIkZiNH\njmTkyJFZlxGL0jSiIiJZiHIVp1x47LH26ydMmzat6rwjRowA4LXXXvvEe5XL6emqUPnw3e9+F4Bb\nb7216ryVHs0rr7ySYEUSh+XLlwMwderULucZNGgQ0PG7uG3bti7njap3794A7N69u+5lqCcqIhJB\n4Yc49e3bF4CdO3fGsrzvfe97ANx0002xLG8fGgoT0ujRowH41Kc+BcAzzzwTaXm33347AFdccUW0\nwvZPuYZU2eKrDHDfsmVLpOVdeWX7XZB/8IMfRCts/zTESUQkaVUbUTNbbGabzWxNp2lNZrbCzF4O\nfjYmW6bETbmWl7JNV9XNeTP7b2A7sNTdW4JptwJb3f2W4N7Vje5+ZdWV5fAMiHPOOQeAe++9N43V\n5Wazr+y5tra2AvDII4+ksbrc5ArxZZvHXE844QQA/vSnP6Wxung25939aWDrPpOnA0uC50uA02su\nTzKlXMtL2aar3iFOQ919U/D8TWBoTPXUXsjQ9lXPnTsXgBtuuKHqZyZOnLj3+SGHHAKw98oy3/zm\nN4Huh2CUWG5ynTSpvQNw4403AuHyOPLII/c+r2xhzZo1C+g4UFVZ3gEoF9meeOKJANx///0ANDc3\ndzc70HFwEeDggw8G4LzzzgM6DlDddtttsdZZi8jjRN3du+v2B7dMvjDqeiRdyrW8ustWudbB3as+\ngJHAmk6v1wPDgufDgPUhl+NZPtra2rytrS3LGlaH+Z7SepQl1/PPP9/PP/985Rpztlnneuqpp/qp\np56a+1zrHeL0GHB28Pxs4NE6lyP5olzLS9kmJcRfo/uBTcCHwEbgPOBQ4EngZeAJoCmrHsvOnTt9\n586dkZczZswYHzNmTC7+sqXUU8l1rhVRlzNgwAAfMGBA5OX079/f+/fvn/tc48w2z7nG9WhqavKm\npqZIuVbdJ+rus7p460vVPiv5pVzLS9mmS2csiYhEUPirOFXOnY9q/fr1sSxH4mFmsSxn+/btsSxn\nx44dsSznQBdXrnHZunXf4bS1U09URCSC0jSiCxYsYMGCBd3Oo9vwFs9JJ53ESSed1O08Rx99NEcf\nfXQ6BUkkDQ0NNDQ0cN9993Hfffd1O++UKVOYMmVKSpXVrzSNqIhIFgq/TzQYitHtvpZly5YB8Lvf\n/Q6ANWvWfGKe/v37A9r3lRerVq0CYPLkyV3O8/TTTwOwcOFCAF566aVPzNOvXz8APvjgg7hLlDpU\nMpswYUKX81x++eVAx+9t3qknKiISgRpREZEICn97kLj16dMHgF27diWx+FxddzIuRcg1Ycq1nHR7\nEBGRpBX+wFLcEuqBikhJqScqIhKBGtHAmDFjGDNmTNZlSMzGjx/P+PHjsy5D9tG3b99Ip2wfc8wx\nHHPMMTFWVD81oiIiUYS4pmAzsBJYC7wIXBpMbwJW0H59whW03z0w9esT1vJYunSpL126NMsacnPd\nyTLleskll/gll1yiXEuW66RJk3zSpEm5zzVMT3QPcLm7jwWOBy42s7HAVcCT7n4U7Rd7vSrEsiQ/\nlGs5KdeUhbll8iZ3fz54/j6wDhiObsFaaMq1nJRr+moabG9mI4GngRbgNXcfFEw34N3K624+H35l\nIc2fPx+Am2++OdJyKrdMrnZlmWoaGhoA2LZt2/7ezuWg7Dzm2tbWBsA999wTaTmVgw9///vfI9fU\nDeUaUly59u7dG4Ddu3dHrqkboXINPU7UzAYAy4B57r6t8wU/3HUL1qJSruWkXFMUcmd1L+Bx4H87\nTSvcLVgvu+wyv+yyy3K/ozrFgxClyPWEE07wE044QbmWLNfRo0f76NGjc59r1X2iQdf/58A6d/9h\np7d0C9YCU67lpFzTV3WfqJmdCPwReAH4KJh8NfAX4CFgBPAqMNPdu71hSVYXNJgzZw7QsR/l7bff\n3vveo4+m+n8pN/vOypDr8OHDATjuuOOAj++Hfuqpp9IsRbnGqLm5GYDGxkbg47m+8soraZYSzz5R\nd38G6OqKx7oFa0Ep13JSrunTGUsiIhEU/ipOM2fOBOChhx7qcp7KrT9++tOfdjnP6NGjAdiwYUOM\n1UmSpk2bBnSf6+DBgwHYsmVLKjVJ9yq7YN54440u56ncmDDqcMO0qCcqIhKBrmyfrtwcgIiTclWu\nJaUr24uIJE2NqIhIBGpERUQiUCMqIhKBGlERkQjUiIqIRKBGVAqvX79+9OvXL+sy5AClRlREJIK0\nT/vcAuwIfhbNYKLX/Zk4CsmhTHP94IMPonxcuXZNv68hpHrGEoCZrS7i2R1FrTstRf1+ilp3Wor6\n/aRZtzbnRUQiUCMqIhJBFo3o3RmsMw5FrTstRf1+ilp3Wor6/aRWd+r7REVEykSb8yIiEaTWiJrZ\nKWa23sw2mNlVaa23VmbWbGYrzWytmb1oZpcG05vMbIWZvRz8bMy61rwoQrbKtXbKNWQNaWzOm1kP\n4CVgCrARWAXMcve1ia+8RmY2jPb7cz9vZgOB54DTgXOAre5+S/AfqtHdr8yw1FwoSrbKtTbKNby0\neqKfAza4+z/dfTfwADA9pXXXxN03ufvzwfP3gXXAcNrrXRLMtoT2oKQg2SrXminXkNJqRIcDr3d6\nvTGYlmtmNhL4LO337B7q7puCt94EhmZUVt4ULlvlGopyDUkHlrpgZgOAZcA8d9/W+T1v3weiYQ0F\npFzLKctc02pE3wCaO70+PJiWS2bWi/ZAfuHuvwwmvxXsf6nsh9mcVX05U5hslWtNlGtIaTWiq4Cj\nzOwIM+sNnAU8ltK6a2JmBvwcWOfuP+z01mPA2cHzs4FH064tpwqRrXKtmXINW0Nag+3N7GvAj4Ae\nwGJ3vymVFdfIzE4E/gi8AHwUTL6a9v0sDwEjgFeBme6+NZMic6YI2SrX2inXkDXojCURkfrpwJKI\nSARqREVEIlAjKiISgRpREZEI1IiKiESgRlREJAI1oiIiEagRFRGJ4P8DVtYN1DUFOzwAAAAASUVO\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2a6ba24b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# zz = sample_Z(batch_size, g_dim)\n",
    "gg = sess.run(g_sample, feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(g_sample), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(x_d), feed_dict = {x_d: x_train})\n",
    "gg_pic = np.array([np.reshape(m,(28,28)) for m in gg])\n",
    "fig, ax = plt.subplots(nrows=3, ncols=3)\n",
    "for i,row in enumerate(ax):\n",
    "    for j,col in enumerate(row):\n",
    "        ax[i][j].imshow(gg_pic[i*3+j], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0  d-loss: 0.0910859  g-loss: 0.0525855 k_t: 0.00455554 M_global: 0.0982483\n",
      "step: 1000  d-loss: 0.0925112  g-loss: 0.0432432 k_t: 0.00203779 M_global: 0.0956558\n",
      "step: 2000  d-loss: 0.0888409  g-loss: 0.0454328 k_t: 0.00399826 M_global: 0.0899441\n",
      "step: 3000  d-loss: 0.092186  g-loss: 0.0462009 k_t: 0.00253441 M_global: 0.0923524\n",
      "step: 4000  d-loss: 0.0890407  g-loss: 0.0505442 k_t: 0.00832695 M_global: 0.0952749\n",
      "step: 5000  d-loss: 0.0857218  g-loss: 0.0424908 k_t: 0.000267211 M_global: 0.0861089\n",
      "step: 6000  d-loss: 0.086632  g-loss: 0.0437404 k_t: 0.00159074 M_global: 0.0870912\n",
      "step: 7000  d-loss: 0.0872474  g-loss: 0.0448726 k_t: 0.00331535 M_global: 0.0885706\n",
      "step: 8000  d-loss: 0.0908583  g-loss: 0.0481241 k_t: 0.00582185 M_global: 0.0936933\n",
      "step: 9000  d-loss: 0.0844391  g-loss: 0.04277 k_t: 0.0015315 M_global: 0.0850223\n",
      "step: 10000  d-loss: 0.0869261  g-loss: 0.0447336 k_t: 0.0021297 M_global: 0.0882443\n"
     ]
    }
   ],
   "source": [
    "for step in range(10001):\n",
    "    batch_x = mnist.train.next_batch(batch_size)[0]\n",
    "    z_D = sample_Z(batch_size, g_dim)\n",
    "    sess.run([d_optimizer, g_optimizer], feed_dict={x_d: batch_x, x_g: z_D})\n",
    "    z_G = sample_Z(batch_size, g_dim)\n",
    "    sess.run(g_optimizer, feed_dict={x_g: z_G})\n",
    "#     k_t = np.maximum(np.minimum(1., k_t + 0.001*(sess.run(balancer, feed_dict={x_d: batch_x, x_g: z_G}))), 0.)\n",
    "    sess.run(update_k, feed_dict={x_d: batch_x, x_g: z_G})\n",
    "    if step%1000==0:\n",
    "        d_loss_train, g_loss_train, k_tt, M_global_train = sess.run([d_loss, g_loss, k_t, M_global], feed_dict=\n",
    "                            {x_d: batch_x, x_g: sample_Z(batch_size, g_dim)})\n",
    "#         print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_t,\"M_global:\", M_global_train\n",
    "        print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_tt,\"M_global:\", M_global_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAD8CAYAAADOg5fGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2a6c084b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gg = sess.run(g_sample, feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(g_sample), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(decoder(x_g), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(x_d), feed_dict = {x_d: x_train})\n",
    "gg_pic = np.array([np.reshape(m,(28,28)) for m in gg])\n",
    "fig, ax = plt.subplots(nrows=3, ncols=3)\n",
    "for i,row in enumerate(ax):\n",
    "    for j,col in enumerate(row):\n",
    "        ax[i][j].imshow(gg_pic[i*3+j], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0  d-loss: 0.0507546  g-loss: 0.023656 k_t: 0.0461516 M_global: 0.0541136\n",
      "step: 1000  d-loss: 0.0471655  g-loss: 0.0235202 k_t: 0.0467315 M_global: 0.0488767\n",
      "step: 2000  d-loss: 0.0457362  g-loss: 0.0234209 k_t: 0.0473112 M_global: 0.0468455\n",
      "step: 3000  d-loss: 0.0470849  g-loss: 0.023409 k_t: 0.0479626 M_global: 0.0489024\n",
      "step: 4000  d-loss: 0.0473888  g-loss: 0.0228861 k_t: 0.0487873 M_global: 0.0498719\n",
      "step: 5000  d-loss: 0.0463009  g-loss: 0.0227528 k_t: 0.0499098 M_global: 0.048402\n",
      "step: 6000  d-loss: 0.0459907  g-loss: 0.0220586 k_t: 0.0510488 M_global: 0.0486166\n",
      "step: 7000  d-loss: 0.0445357  g-loss: 0.0217438 k_t: 0.0521452 M_global: 0.0467606\n",
      "step: 8000  d-loss: 0.0444641  g-loss: 0.0217497 k_t: 0.0531464 M_global: 0.0466803\n",
      "step: 9000  d-loss: 0.0449894  g-loss: 0.0222211 k_t: 0.0540908 M_global: 0.0470659\n",
      "step: 10000  d-loss: 0.0429596  g-loss: 0.0217715 k_t: 0.0550158 M_global: 0.0444646\n"
     ]
    }
   ],
   "source": [
    "for step in range(10001):\n",
    "    batch_x = mnist.train.next_batch(batch_size)[0]\n",
    "    z_D = sample_Z(batch_size, g_dim)\n",
    "    sess.run([d_optimizer, g_optimizer], feed_dict={x_d: batch_x, x_g: z_D})\n",
    "    z_G = sample_Z(batch_size, g_dim)\n",
    "    sess.run(g_optimizer, feed_dict={x_g: z_G})\n",
    "#     k_t = np.maximum(np.minimum(1., k_t + 0.001*(sess.run(balancer, feed_dict={x_d: batch_x, x_g: z_G}))), 0.)\n",
    "    sess.run(update_k, feed_dict={x_d: batch_x, x_g: z_G})\n",
    "    if step%1000==0:\n",
    "        d_loss_train, g_loss_train, k_tt, M_global_train = sess.run([d_loss, g_loss, k_t, M_global], feed_dict=\n",
    "                            {x_d: batch_x, x_g: sample_Z(batch_size, g_dim)})\n",
    "#         print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_t,\"M_global:\", M_global_train\n",
    "        print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_tt,\"M_global:\", M_global_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAD8CAYAAADOg5fGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f406354af90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gg = sess.run(g_sample, feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(g_sample), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(decoder(x_g), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(x_d), feed_dict = {x_d: x_train})\n",
    "gg_pic = np.array([np.reshape(m,(28,28)) for m in gg])\n",
    "fig, ax = plt.subplots(nrows=3, ncols=3)\n",
    "for i,row in enumerate(ax):\n",
    "    for j,col in enumerate(row):\n",
    "        ax[i][j].imshow(gg_pic[i*3+j], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0  d-loss: 0.0429454  g-loss: 0.0215675 k_t: 0.0550159 M_global: 0.0446304\n",
      "step: 1000  d-loss: 0.0443127  g-loss: 0.0215943 k_t: 0.0558566 M_global: 0.0466839\n",
      "step: 2000  d-loss: 0.0443735  g-loss: 0.021824 k_t: 0.0566229 M_global: 0.0465899\n",
      "step: 3000  d-loss: 0.0429038  g-loss: 0.0219562 k_t: 0.0572818 M_global: 0.044286\n",
      "step: 4000  d-loss: 0.042058  g-loss: 0.021586 k_t: 0.0578705 M_global: 0.0433748\n",
      "step: 5000  d-loss: 0.0429612  g-loss: 0.0219599 k_t: 0.0583521 M_global: 0.044404\n",
      "step: 6000  d-loss: 0.0423397  g-loss: 0.0221759 k_t: 0.0587459 M_global: 0.0439971\n",
      "step: 7000  d-loss: 0.0430254  g-loss: 0.0219721 k_t: 0.0590889 M_global: 0.0445135\n",
      "step: 8000  d-loss: 0.0413209  g-loss: 0.0210602 k_t: 0.0593709 M_global: 0.0427967\n",
      "step: 9000  d-loss: 0.0419871  g-loss: 0.0219238 k_t: 0.0595901 M_global: 0.0435706\n",
      "step: 10000  d-loss: 0.0422414  g-loss: 0.0208271 k_t: 0.0597809 M_global: 0.0444025\n"
     ]
    }
   ],
   "source": [
    "for step in range(10001):\n",
    "    batch_x = mnist.train.next_batch(batch_size)[0]\n",
    "    z_D = sample_Z(batch_size, g_dim)\n",
    "    sess.run([d_optimizer, g_optimizer], feed_dict={x_d: batch_x, x_g: z_D})\n",
    "    z_G = sample_Z(batch_size, g_dim)\n",
    "    sess.run(g_optimizer, feed_dict={x_g: z_G})\n",
    "#     k_t = np.maximum(np.minimum(1., k_t + 0.001*(sess.run(balancer, feed_dict={x_d: batch_x, x_g: z_G}))), 0.)\n",
    "    sess.run(update_k, feed_dict={x_d: batch_x, x_g: z_G})\n",
    "    if step%1000==0:\n",
    "        d_loss_train, g_loss_train, k_tt, M_global_train = sess.run([d_loss, g_loss, k_t, M_global], feed_dict=\n",
    "                            {x_d: batch_x, x_g: sample_Z(batch_size, g_dim)})\n",
    "#         print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_t,\"M_global:\", M_global_train\n",
    "        print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_tt,\"M_global:\", M_global_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAD8CAYAAADOg5fGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f406356c390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gg = sess.run(g_sample, feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(g_sample), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(decoder(x_g), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(x_d), feed_dict = {x_d: x_train})\n",
    "gg_pic = np.array([np.reshape(m,(28,28)) for m in gg])\n",
    "fig, ax = plt.subplots(nrows=3, ncols=3)\n",
    "for i,row in enumerate(ax):\n",
    "    for j,col in enumerate(row):\n",
    "        ax[i][j].imshow(gg_pic[i*3+j], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0  d-loss: 0.0419477  g-loss: 0.0213801 k_t: 0.0597815 M_global: 0.0434586\n",
      "step: 1000  d-loss: 0.0408291  g-loss: 0.0212278 k_t: 0.0599528 M_global: 0.0422787\n",
      "step: 2000  d-loss: 0.0421081  g-loss: 0.0210883 k_t: 0.0601166 M_global: 0.0439754\n",
      "step: 3000  d-loss: 0.0415205  g-loss: 0.0208901 k_t: 0.0602344 M_global: 0.0432782\n",
      "step: 4000  d-loss: 0.04048  g-loss: 0.0209695 k_t: 0.0603256 M_global: 0.041842\n",
      "step: 5000  d-loss: 0.0411147  g-loss: 0.0211593 k_t: 0.0603999 M_global: 0.0424298\n",
      "step: 6000  d-loss: 0.0418776  g-loss: 0.0207641 k_t: 0.0604206 M_global: 0.0439341\n",
      "step: 7000  d-loss: 0.0393454  g-loss: 0.0210414 k_t: 0.0604302 M_global: 0.0413498\n",
      "step: 8000  d-loss: 0.0398943  g-loss: 0.0203162 k_t: 0.0604251 M_global: 0.0413667\n",
      "step: 9000  d-loss: 0.0413921  g-loss: 0.021095 k_t: 0.0603752 M_global: 0.0429036\n",
      "step: 10000  d-loss: 0.0415344  g-loss: 0.0208305 k_t: 0.060274 M_global: 0.0433544\n",
      "step: 11000  d-loss: 0.0403142  g-loss: 0.0205832 k_t: 0.0600822 M_global: 0.0417431\n",
      "step: 12000  d-loss: 0.0400345  g-loss: 0.0209728 k_t: 0.0598447 M_global: 0.0416177\n",
      "step: 13000  d-loss: 0.0394388  g-loss: 0.0200437 k_t: 0.0596044 M_global: 0.0409066\n",
      "step: 14000  d-loss: 0.040975  g-loss: 0.0206329 k_t: 0.0593641 M_global: 0.0426669\n",
      "step: 15000  d-loss: 0.0393347  g-loss: 0.020396 k_t: 0.0591788 M_global: 0.0406669\n",
      "step: 16000  d-loss: 0.0405015  g-loss: 0.0206283 k_t: 0.0590222 M_global: 0.0419503\n",
      "step: 17000  d-loss: 0.0380028  g-loss: 0.0202725 k_t: 0.0589009 M_global: 0.039871\n",
      "step: 18000  d-loss: 0.0409141  g-loss: 0.0204277 k_t: 0.0587901 M_global: 0.0427449\n",
      "step: 19000  d-loss: 0.0398003  g-loss: 0.0198061 k_t: 0.058743 M_global: 0.0416396\n",
      "step: 20000  d-loss: 0.038852  g-loss: 0.0200361 k_t: 0.0587098 M_global: 0.0400503\n",
      "step: 21000  d-loss: 0.0411313  g-loss: 0.019889 k_t: 0.0587575 M_global: 0.0435608\n",
      "step: 22000  d-loss: 0.0399199  g-loss: 0.0202733 k_t: 0.0587969 M_global: 0.0413945\n",
      "step: 23000  d-loss: 0.0375631  g-loss: 0.0196658 k_t: 0.0588616 M_global: 0.0390261\n",
      "step: 24000  d-loss: 0.0392918  g-loss: 0.0195786 k_t: 0.0589635 M_global: 0.0410907\n",
      "step: 25000  d-loss: 0.0384542  g-loss: 0.0190888 k_t: 0.0590636 M_global: 0.0402838\n",
      "step: 26000  d-loss: 0.0375381  g-loss: 0.0194086 k_t: 0.0591933 M_global: 0.038752\n",
      "step: 27000  d-loss: 0.036824  g-loss: 0.0196029 k_t: 0.059289 M_global: 0.038596\n",
      "step: 28000  d-loss: 0.0366526  g-loss: 0.0192173 k_t: 0.0593901 M_global: 0.0381142\n",
      "step: 29000  d-loss: 0.0384396  g-loss: 0.0190318 k_t: 0.0594784 M_global: 0.0403256\n",
      "step: 30000  d-loss: 0.0381819  g-loss: 0.0191507 k_t: 0.059559 M_global: 0.0398331\n",
      "step: 31000  d-loss: 0.0363552  g-loss: 0.0197849 k_t: 0.0596397 M_global: 0.0385525\n",
      "step: 32000  d-loss: 0.0395838  g-loss: 0.0190852 k_t: 0.0597389 M_global: 0.0420007\n",
      "step: 33000  d-loss: 0.0377915  g-loss: 0.0188098 k_t: 0.0598615 M_global: 0.0395664\n",
      "step: 34000  d-loss: 0.0372899  g-loss: 0.0180141 k_t: 0.0602805 M_global: 0.0395496\n",
      "step: 35000  d-loss: 0.0373756  g-loss: 0.0185856 k_t: 0.0608946 M_global: 0.0391755\n",
      "step: 36000  d-loss: 0.0387112  g-loss: 0.018609 k_t: 0.0616034 M_global: 0.0411774\n",
      "step: 37000  d-loss: 0.0357913  g-loss: 0.0183599 k_t: 0.0623138 M_global: 0.0370432\n",
      "step: 38000  d-loss: 0.0384932  g-loss: 0.0181796 k_t: 0.0630057 M_global: 0.0412784\n",
      "step: 39000  d-loss: 0.0353221  g-loss: 0.0186546 k_t: 0.0636452 M_global: 0.0369093\n",
      "step: 40000  d-loss: 0.0373738  g-loss: 0.0181846 k_t: 0.0642505 M_global: 0.0396286\n",
      "step: 41000  d-loss: 0.0378697  g-loss: 0.0182826 k_t: 0.0647939 M_global: 0.0402989\n",
      "step: 42000  d-loss: 0.0359518  g-loss: 0.0179182 k_t: 0.0652581 M_global: 0.0377635\n",
      "step: 43000  d-loss: 0.0371059  g-loss: 0.0185391 k_t: 0.0657081 M_global: 0.038947\n",
      "step: 44000  d-loss: 0.0368903  g-loss: 0.0183412 k_t: 0.0660714 M_global: 0.038812\n",
      "step: 45000  d-loss: 0.0374513  g-loss: 0.0183824 k_t: 0.0663888 M_global: 0.0396251\n",
      "step: 46000  d-loss: 0.0369253  g-loss: 0.0185654 k_t: 0.0666664 M_global: 0.0386791\n",
      "step: 47000  d-loss: 0.0358668  g-loss: 0.0185572 k_t: 0.0669198 M_global: 0.0371115\n",
      "step: 48000  d-loss: 0.037543  g-loss: 0.0178119 k_t: 0.0671528 M_global: 0.0402968\n",
      "step: 49000  d-loss: 0.0373615  g-loss: 0.0185554 k_t: 0.0674156 M_global: 0.0393633\n",
      "step: 50000  d-loss: 0.0365912  g-loss: 0.0185084 k_t: 0.067655 M_global: 0.0382568\n"
     ]
    }
   ],
   "source": [
    "for step in range(50001):\n",
    "    batch_x = mnist.train.next_batch(batch_size)[0]\n",
    "    z_D = sample_Z(batch_size, g_dim)\n",
    "    sess.run([d_optimizer, g_optimizer], feed_dict={x_d: batch_x, x_g: z_D})\n",
    "    z_G = sample_Z(batch_size, g_dim)\n",
    "    sess.run(g_optimizer, feed_dict={x_g: z_G})\n",
    "#     k_t = np.maximum(np.minimum(1., k_t + 0.001*(sess.run(balancer, feed_dict={x_d: batch_x, x_g: z_G}))), 0.)\n",
    "    sess.run(update_k, feed_dict={x_d: batch_x, x_g: z_G})\n",
    "    if step%1000==0:\n",
    "        d_loss_train, g_loss_train, k_tt, M_global_train = sess.run([d_loss, g_loss, k_t, M_global], feed_dict=\n",
    "                            {x_d: batch_x, x_g: sample_Z(batch_size, g_dim)})\n",
    "#         print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_t,\"M_global:\", M_global_train\n",
    "        print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_tt,\"M_global:\", M_global_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAD8CAYAAADOg5fGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUCMqIhLD/we9pO5oTgfQJgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f40633ed650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gg = sess.run(g_sample, feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(g_sample), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(decoder(x_g), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(x_d), feed_dict = {x_d: x_train})\n",
    "gg_pic = np.array([np.reshape(m,(28,28)) for m in gg])\n",
    "fig, ax = plt.subplots(nrows=3, ncols=3)\n",
    "for i,row in enumerate(ax):\n",
    "    for j,col in enumerate(row):\n",
    "        ax[i][j].imshow(gg_pic[i*3+j], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0  d-loss: 0.0365903  g-loss: 0.0177989 k_t: 0.0676553 M_global: 0.0388929\n",
      "step: 1000  d-loss: 0.0354999  g-loss: 0.0185346 k_t: 0.0679368 M_global: 0.0369142\n",
      "step: 2000  d-loss: 0.0363987  g-loss: 0.0177708 k_t: 0.0682389 M_global: 0.0386462\n",
      "step: 3000  d-loss: 0.0352663  g-loss: 0.0183553 k_t: 0.0685713 M_global: 0.0366178\n",
      "step: 4000  d-loss: 0.0367077  g-loss: 0.0178614 k_t: 0.0689275 M_global: 0.0390468\n",
      "step: 5000  d-loss: 0.0357456  g-loss: 0.0177504 k_t: 0.0693139 M_global: 0.0377135\n",
      "step: 6000  d-loss: 0.0347282  g-loss: 0.0176971 k_t: 0.0696975 M_global: 0.0362453\n",
      "step: 7000  d-loss: 0.0349011  g-loss: 0.0180961 k_t: 0.0701025 M_global: 0.0361809\n",
      "step: 8000  d-loss: 0.0359506  g-loss: 0.0177036 k_t: 0.0704695 M_global: 0.0380937\n",
      "step: 9000  d-loss: 0.0351477  g-loss: 0.0182776 k_t: 0.0708142 M_global: 0.0364986\n",
      "step: 10000  d-loss: 0.0363142  g-loss: 0.0177883 k_t: 0.0711566 M_global: 0.0385816\n",
      "step: 11000  d-loss: 0.0347349  g-loss: 0.0181445 k_t: 0.0714399 M_global: 0.0361601\n",
      "step: 12000  d-loss: 0.0352931  g-loss: 0.0179353 k_t: 0.0716669 M_global: 0.0369324\n",
      "step: 13000  d-loss: 0.0358701  g-loss: 0.0176951 k_t: 0.0718597 M_global: 0.0380173\n",
      "step: 14000  d-loss: 0.0349151  g-loss: 0.0182169 k_t: 0.0719804 M_global: 0.0363301\n",
      "step: 15000  d-loss: 0.0360979  g-loss: 0.0175845 k_t: 0.0720364 M_global: 0.0384624\n",
      "step: 16000  d-loss: 0.0342656  g-loss: 0.0180867 k_t: 0.0720538 M_global: 0.0358711\n",
      "step: 17000  d-loss: 0.0335794  g-loss: 0.0177595 k_t: 0.0720233 M_global: 0.0351887\n",
      "step: 18000  d-loss: 0.0350281  g-loss: 0.0182276 k_t: 0.0719725 M_global: 0.0363976\n",
      "step: 19000  d-loss: 0.034401  g-loss: 0.0180643 k_t: 0.0719203 M_global: 0.0359144\n",
      "step: 20000  d-loss: 0.0354225  g-loss: 0.0179696 k_t: 0.0718762 M_global: 0.0371015\n",
      "step: 21000  d-loss: 0.0345547  g-loss: 0.0179202 k_t: 0.0718045 M_global: 0.035842\n",
      "step: 22000  d-loss: 0.0343526  g-loss: 0.0187713 k_t: 0.0717238 M_global: 0.0366208\n",
      "step: 23000  d-loss: 0.034612  g-loss: 0.0183373 k_t: 0.0716597 M_global: 0.0363003\n",
      "step: 24000  d-loss: 0.0337545  g-loss: 0.0178863 k_t: 0.0715964 M_global: 0.0354039\n",
      "step: 25000  d-loss: 0.03386  g-loss: 0.0173606 k_t: 0.0715785 M_global: 0.0352933\n",
      "step: 26000  d-loss: 0.0346801  g-loss: 0.0181101 k_t: 0.0715733 M_global: 0.0360982\n",
      "step: 27000  d-loss: 0.0346256  g-loss: 0.0179141 k_t: 0.0716078 M_global: 0.0359485\n",
      "step: 28000  d-loss: 0.0341073  g-loss: 0.0180833 k_t: 0.0716559 M_global: 0.0357848\n",
      "step: 29000  d-loss: 0.0344232  g-loss: 0.0173298 k_t: 0.0717674 M_global: 0.0361706\n",
      "step: 30000  d-loss: 0.0349511  g-loss: 0.017781 k_t: 0.0718732 M_global: 0.0365626\n",
      "step: 31000  d-loss: 0.0345478  g-loss: 0.0175951 k_t: 0.0719985 M_global: 0.0361267\n",
      "step: 32000  d-loss: 0.0344949  g-loss: 0.0172442 k_t: 0.0721915 M_global: 0.0363655\n",
      "step: 33000  d-loss: 0.0323198  g-loss: 0.0174289 k_t: 0.0724099 M_global: 0.0342198\n",
      "step: 34000  d-loss: 0.0338373  g-loss: 0.0167801 k_t: 0.0726817 M_global: 0.0358053\n",
      "step: 35000  d-loss: 0.0338004  g-loss: 0.017306 k_t: 0.0729801 M_global: 0.0352891\n",
      "step: 36000  d-loss: 0.0343338  g-loss: 0.0172968 k_t: 0.0733166 M_global: 0.0361061\n",
      "step: 37000  d-loss: 0.0341997  g-loss: 0.0172408 k_t: 0.0736529 M_global: 0.0359634\n",
      "step: 38000  d-loss: 0.0341851  g-loss: 0.0169845 k_t: 0.0739771 M_global: 0.0361778\n",
      "step: 39000  d-loss: 0.0324076  g-loss: 0.0174488 k_t: 0.0743081 M_global: 0.0343009\n",
      "step: 40000  d-loss: 0.0324733  g-loss: 0.0170627 k_t: 0.0746142 M_global: 0.033936\n",
      "step: 41000  d-loss: 0.0334794  g-loss: 0.0174614 k_t: 0.0749216 M_global: 0.0348552\n",
      "step: 42000  d-loss: 0.0340224  g-loss: 0.0173667 k_t: 0.0751976 M_global: 0.0356257\n",
      "step: 43000  d-loss: 0.033413  g-loss: 0.0177493 k_t: 0.0754747 M_global: 0.0351257\n",
      "step: 44000  d-loss: 0.0339686  g-loss: 0.0170498 k_t: 0.0757267 M_global: 0.0358398\n",
      "step: 45000  d-loss: 0.0328881  g-loss: 0.0169456 k_t: 0.0759745 M_global: 0.0343177\n",
      "step: 46000  d-loss: 0.033145  g-loss: 0.0170147 k_t: 0.0762126 M_global: 0.034648\n",
      "step: 47000  d-loss: 0.032814  g-loss: 0.0172896 k_t: 0.0764251 M_global: 0.0343573\n",
      "step: 48000  d-loss: 0.0332032  g-loss: 0.0174178 k_t: 0.076599 M_global: 0.0346865\n",
      "step: 49000  d-loss: 0.032833  g-loss: 0.0173014 k_t: 0.0767659 M_global: 0.034382\n",
      "step: 50000  d-loss: 0.0330516  g-loss: 0.0170987 k_t: 0.0769153 M_global: 0.0344514\n"
     ]
    }
   ],
   "source": [
    "for step in range(50001):\n",
    "    batch_x = mnist.train.next_batch(batch_size)[0]\n",
    "    z_D = sample_Z(batch_size, g_dim)\n",
    "    sess.run([d_optimizer, g_optimizer], feed_dict={x_d: batch_x, x_g: z_D})\n",
    "    z_G = sample_Z(batch_size, g_dim)\n",
    "    sess.run(g_optimizer, feed_dict={x_g: z_G})\n",
    "#     k_t = np.maximum(np.minimum(1., k_t + 0.001*(sess.run(balancer, feed_dict={x_d: batch_x, x_g: z_G}))), 0.)\n",
    "    sess.run(update_k, feed_dict={x_d: batch_x, x_g: z_G})\n",
    "    if step%1000==0:\n",
    "        d_loss_train, g_loss_train, k_tt, M_global_train = sess.run([d_loss, g_loss, k_t, M_global], feed_dict=\n",
    "                            {x_d: batch_x, x_g: sample_Z(batch_size, g_dim)})\n",
    "#         print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_t,\"M_global:\", M_global_train\n",
    "        print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_tt,\"M_global:\", M_global_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAD8CAYAAADOg5fGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4058e1c410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gg = sess.run(g_sample, feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(g_sample), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(decoder(x_g), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(x_d), feed_dict = {x_d: x_train})\n",
    "gg_pic = np.array([np.reshape(m,(28,28)) for m in gg])\n",
    "fig, ax = plt.subplots(nrows=3, ncols=3)\n",
    "for i,row in enumerate(ax):\n",
    "    for j,col in enumerate(row):\n",
    "        ax[i][j].imshow(gg_pic[i*3+j], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0  d-loss: 0.0335229  g-loss: 0.0173816 k_t: 0.0769159 M_global: 0.0349082\n",
      "step: 1000  d-loss: 0.0331007  g-loss: 0.0167656 k_t: 0.0770265 M_global: 0.0348225\n",
      "step: 2000  d-loss: 0.0329962  g-loss: 0.0169634 k_t: 0.0771322 M_global: 0.0344935\n",
      "step: 3000  d-loss: 0.0339379  g-loss: 0.0174793 k_t: 0.0772279 M_global: 0.0354524\n",
      "step: 4000  d-loss: 0.032591  g-loss: 0.0171546 k_t: 0.0772742 M_global: 0.0341129\n",
      "step: 5000  d-loss: 0.0318654  g-loss: 0.017427 k_t: 0.0773098 M_global: 0.0340333\n",
      "step: 6000  d-loss: 0.0343606  g-loss: 0.0169322 k_t: 0.0773495 M_global: 0.0365732\n",
      "step: 7000  d-loss: 0.0333369  g-loss: 0.016951 k_t: 0.0773504 M_global: 0.0350212\n",
      "step: 8000  d-loss: 0.0322722  g-loss: 0.0172425 k_t: 0.077345 M_global: 0.0340454\n",
      "step: 9000  d-loss: 0.034358  g-loss: 0.0171107 k_t: 0.0773293 M_global: 0.036411\n",
      "step: 10000  d-loss: 0.0335352  g-loss: 0.0173735 k_t: 0.077301 M_global: 0.0349437\n",
      "step: 11000  d-loss: 0.0314661  g-loss: 0.0168503 k_t: 0.0772433 M_global: 0.0332342\n",
      "step: 12000  d-loss: 0.033266  g-loss: 0.0175619 k_t: 0.0771874 M_global: 0.0348727\n",
      "step: 13000  d-loss: 0.0322467  g-loss: 0.0179532 k_t: 0.0771233 M_global: 0.0347689\n",
      "step: 14000  d-loss: 0.0334284  g-loss: 0.017133 k_t: 0.0770468 M_global: 0.0349896\n",
      "step: 15000  d-loss: 0.0322639  g-loss: 0.0172741 k_t: 0.0769636 M_global: 0.0340708\n",
      "step: 16000  d-loss: 0.0328651  g-loss: 0.0170131 k_t: 0.0768778 M_global: 0.0342464\n",
      "step: 17000  d-loss: 0.0324232  g-loss: 0.0180038 k_t: 0.0768048 M_global: 0.0349068\n",
      "step: 18000  d-loss: 0.033359  g-loss: 0.0173005 k_t: 0.0767103 M_global: 0.0347287\n",
      "step: 19000  d-loss: 0.0332428  g-loss: 0.0179717 k_t: 0.076607 M_global: 0.0352815\n",
      "step: 20000  d-loss: 0.0316852  g-loss: 0.0171522 k_t: 0.0765117 M_global: 0.033651\n",
      "step: 21000  d-loss: 0.0317293  g-loss: 0.0165859 k_t: 0.0764265 M_global: 0.0330843\n",
      "step: 22000  d-loss: 0.0330435  g-loss: 0.016986 k_t: 0.0763242 M_global: 0.0345239\n",
      "step: 23000  d-loss: 0.0329895  g-loss: 0.0165996 k_t: 0.0762265 M_global: 0.0347827\n",
      "step: 24000  d-loss: 0.0330426  g-loss: 0.016643 k_t: 0.0761404 M_global: 0.0348217\n",
      "step: 25000  d-loss: 0.0330279  g-loss: 0.0168095 k_t: 0.076068 M_global: 0.0346503\n",
      "step: 26000  d-loss: 0.0318414  g-loss: 0.0170079 k_t: 0.075985 M_global: 0.0335748\n",
      "step: 27000  d-loss: 0.0305759  g-loss: 0.0170461 k_t: 0.0759149 M_global: 0.0329811\n",
      "step: 28000  d-loss: 0.0321965  g-loss: 0.016924 k_t: 0.0758532 M_global: 0.0336641\n",
      "step: 29000  d-loss: 0.0332261  g-loss: 0.0168261 k_t: 0.075759 M_global: 0.0349251\n",
      "step: 30000  d-loss: 0.0313753  g-loss: 0.0172355 k_t: 0.0756709 M_global: 0.0335752\n",
      "step: 31000  d-loss: 0.0329755  g-loss: 0.0168375 k_t: 0.0755894 M_global: 0.0345349\n",
      "step: 32000  d-loss: 0.0328555  g-loss: 0.0165409 k_t: 0.0755302 M_global: 0.0346163\n",
      "step: 33000  d-loss: 0.0333691  g-loss: 0.0168681 k_t: 0.0754709 M_global: 0.0350951\n",
      "step: 34000  d-loss: 0.0313018  g-loss: 0.0174329 k_t: 0.0753929 M_global: 0.033741\n",
      "step: 35000  d-loss: 0.0340153  g-loss: 0.0167893 k_t: 0.0753358 M_global: 0.0361309\n",
      "step: 36000  d-loss: 0.0326113  g-loss: 0.0163683 k_t: 0.0752831 M_global: 0.0343971\n",
      "step: 37000  d-loss: 0.0321919  g-loss: 0.0166596 k_t: 0.0752597 M_global: 0.033509\n",
      "step: 38000  d-loss: 0.0320182  g-loss: 0.016504 k_t: 0.0752376 M_global: 0.0333859\n",
      "step: 39000  d-loss: 0.0325155  g-loss: 0.0168546 k_t: 0.0752247 M_global: 0.0338204\n",
      "step: 40000  d-loss: 0.0311389  g-loss: 0.016983 k_t: 0.0751923 M_global: 0.0331909\n",
      "step: 41000  d-loss: 0.0326878  g-loss: 0.0167258 k_t: 0.075172 M_global: 0.0341919\n",
      "step: 42000  d-loss: 0.0308337  g-loss: 0.016965 k_t: 0.0751443 M_global: 0.0330193\n",
      "step: 43000  d-loss: 0.0327577  g-loss: 0.0167683 k_t: 0.0751169 M_global: 0.0342576\n",
      "step: 44000  d-loss: 0.0317151  g-loss: 0.0166872 k_t: 0.0751142 M_global: 0.0331714\n",
      "step: 45000  d-loss: 0.0323717  g-loss: 0.0169005 k_t: 0.0751154 M_global: 0.0337211\n",
      "step: 46000  d-loss: 0.0324622  g-loss: 0.0164873 k_t: 0.0750791 M_global: 0.0340628\n",
      "step: 47000  d-loss: 0.0324451  g-loss: 0.0161 k_t: 0.0750372 M_global: 0.0343799\n",
      "step: 48000  d-loss: 0.0322855  g-loss: 0.0166045 k_t: 0.0750303 M_global: 0.0336925\n",
      "step: 49000  d-loss: 0.0321148  g-loss: 0.0162954 k_t: 0.0750114 M_global: 0.0337104\n",
      "step: 50000  d-loss: 0.0318037  g-loss: 0.0163732 k_t: 0.0749734 M_global: 0.0331738\n"
     ]
    }
   ],
   "source": [
    "for step in range(50001):\n",
    "    batch_x = mnist.train.next_batch(batch_size)[0]\n",
    "    z_D = sample_Z(batch_size, g_dim)\n",
    "    sess.run([d_optimizer, g_optimizer], feed_dict={x_d: batch_x, x_g: z_D})\n",
    "    z_G = sample_Z(batch_size, g_dim)\n",
    "    sess.run(g_optimizer, feed_dict={x_g: z_G})\n",
    "#     k_t = np.maximum(np.minimum(1., k_t + 0.001*(sess.run(balancer, feed_dict={x_d: batch_x, x_g: z_G}))), 0.)\n",
    "    sess.run(update_k, feed_dict={x_d: batch_x, x_g: z_G})\n",
    "    if step%1000==0:\n",
    "        d_loss_train, g_loss_train, k_tt, M_global_train = sess.run([d_loss, g_loss, k_t, M_global], feed_dict=\n",
    "                            {x_d: batch_x, x_g: sample_Z(batch_size, g_dim)})\n",
    "#         print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_t,\"M_global:\", M_global_train\n",
    "        print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_tt,\"M_global:\", M_global_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAD8CAYAAADOg5fGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f40583ef790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gg = sess.run(g_sample, feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(g_sample), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(decoder(x_g), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(x_d), feed_dict = {x_d: x_train})\n",
    "gg_pic = np.array([np.reshape(m,(28,28)) for m in gg])\n",
    "fig, ax = plt.subplots(nrows=3, ncols=3)\n",
    "for i,row in enumerate(ax):\n",
    "    for j,col in enumerate(row):\n",
    "        ax[i][j].imshow(gg_pic[i*3+j], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0  d-loss: 0.0313479  g-loss: 0.0164356 k_t: 0.0749729 M_global: 0.0327257\n",
      "step: 1000  d-loss: 0.0312832  g-loss: 0.0169356 k_t: 0.0749738 M_global: 0.0332121\n",
      "step: 2000  d-loss: 0.0320246  g-loss: 0.0161842 k_t: 0.0749702 M_global: 0.0336726\n",
      "step: 3000  d-loss: 0.0319954  g-loss: 0.0164385 k_t: 0.0749566 M_global: 0.0334029\n",
      "step: 4000  d-loss: 0.0299797  g-loss: 0.0165709 k_t: 0.0749766 M_global: 0.0321819\n",
      "step: 5000  d-loss: 0.0322626  g-loss: 0.0167049 k_t: 0.0749797 M_global: 0.0335678\n",
      "step: 6000  d-loss: 0.031619  g-loss: 0.0161312 k_t: 0.075 M_global: 0.0331121\n",
      "step: 7000  d-loss: 0.0316163  g-loss: 0.016221 k_t: 0.0750552 M_global: 0.0330296\n",
      "step: 8000  d-loss: 0.0319319  g-loss: 0.0164224 k_t: 0.0751143 M_global: 0.0333258\n",
      "step: 9000  d-loss: 0.03079  g-loss: 0.0160931 k_t: 0.0751474 M_global: 0.0320928\n",
      "step: 10000  d-loss: 0.0316821  g-loss: 0.0161411 k_t: 0.0752023 M_global: 0.0332029\n",
      "step: 11000  d-loss: 0.0317341  g-loss: 0.0165513 k_t: 0.075301 M_global: 0.0330415\n",
      "step: 12000  d-loss: 0.0314559  g-loss: 0.0163254 k_t: 0.0753948 M_global: 0.0327047\n",
      "step: 13000  d-loss: 0.0308546  g-loss: 0.0163492 k_t: 0.0755022 M_global: 0.0323937\n",
      "step: 14000  d-loss: 0.0321092  g-loss: 0.0163894 k_t: 0.0756382 M_global: 0.0336339\n",
      "step: 15000  d-loss: 0.0308253  g-loss: 0.0163422 k_t: 0.0757895 M_global: 0.0323741\n",
      "step: 16000  d-loss: 0.0307608  g-loss: 0.0161868 k_t: 0.0759445 M_global: 0.0321819\n",
      "step: 17000  d-loss: 0.0321897  g-loss: 0.0164772 k_t: 0.0761151 M_global: 0.0336886\n",
      "step: 18000  d-loss: 0.0309086  g-loss: 0.0159629 k_t: 0.0762611 M_global: 0.032226\n",
      "step: 19000  d-loss: 0.032235  g-loss: 0.0162312 k_t: 0.0764218 M_global: 0.0339819\n",
      "step: 20000  d-loss: 0.031871  g-loss: 0.0157407 k_t: 0.0765788 M_global: 0.0338738\n",
      "step: 21000  d-loss: 0.0316439  g-loss: 0.0160618 k_t: 0.0766908 M_global: 0.0332516\n",
      "step: 22000  d-loss: 0.0311608  g-loss: 0.0159443 k_t: 0.0768513 M_global: 0.0326349\n",
      "step: 23000  d-loss: 0.0318557  g-loss: 0.0165539 k_t: 0.0769753 M_global: 0.033141\n",
      "step: 24000  d-loss: 0.030291  g-loss: 0.0163912 k_t: 0.0770763 M_global: 0.0321684\n",
      "step: 25000  d-loss: 0.0306222  g-loss: 0.0161779 k_t: 0.0771925 M_global: 0.0321134\n",
      "step: 26000  d-loss: 0.0305711  g-loss: 0.0159263 k_t: 0.0772897 M_global: 0.0318273\n",
      "step: 27000  d-loss: 0.0291683  g-loss: 0.0164423 k_t: 0.0773734 M_global: 0.0316625\n",
      "step: 28000  d-loss: 0.0309022  g-loss: 0.0166586 k_t: 0.0775015 M_global: 0.0327552\n",
      "step: 29000  d-loss: 0.0291174  g-loss: 0.0159459 k_t: 0.0776501 M_global: 0.0311237\n",
      "step: 30000  d-loss: 0.0306647  g-loss: 0.0163507 k_t: 0.0778896 M_global: 0.0323199\n",
      "step: 31000  d-loss: 0.0296096  g-loss: 0.0157776 k_t: 0.0782157 M_global: 0.0311994\n",
      "step: 32000  d-loss: 0.0313243  g-loss: 0.0156321 k_t: 0.0786077 M_global: 0.0331976\n",
      "step: 33000  d-loss: 0.0318182  g-loss: 0.0152944 k_t: 0.0790656 M_global: 0.0342468\n",
      "step: 34000  d-loss: 0.0309848  g-loss: 0.0156594 k_t: 0.0794695 M_global: 0.0326846\n",
      "step: 35000  d-loss: 0.0312414  g-loss: 0.0159631 k_t: 0.0798378 M_global: 0.0328107\n",
      "step: 36000  d-loss: 0.0308923  g-loss: 0.0162467 k_t: 0.0801441 M_global: 0.0323439\n",
      "step: 37000  d-loss: 0.0300985  g-loss: 0.0158136 k_t: 0.0804173 M_global: 0.0314987\n",
      "step: 38000  d-loss: 0.0301877  g-loss: 0.0163672 k_t: 0.0806596 M_global: 0.0321211\n",
      "step: 39000  d-loss: 0.0322893  g-loss: 0.0159591 k_t: 0.0808223 M_global: 0.0344096\n",
      "step: 40000  d-loss: 0.0303102  g-loss: 0.0154047 k_t: 0.0809488 M_global: 0.031931\n",
      "step: 41000  d-loss: 0.0305209  g-loss: 0.0158551 k_t: 0.0810377 M_global: 0.0318535\n",
      "step: 42000  d-loss: 0.0304875  g-loss: 0.0164668 k_t: 0.0810958 M_global: 0.0323782\n",
      "step: 43000  d-loss: 0.0306149  g-loss: 0.0157986 k_t: 0.0811176 M_global: 0.0320461\n",
      "step: 44000  d-loss: 0.0306202  g-loss: 0.0162713 k_t: 0.081112 M_global: 0.0322413\n",
      "step: 45000  d-loss: 0.0307552  g-loss: 0.0157213 k_t: 0.0810993 M_global: 0.032324\n",
      "step: 46000  d-loss: 0.0312216  g-loss: 0.0160354 k_t: 0.0810662 M_global: 0.032747\n",
      "step: 47000  d-loss: 0.0311832  g-loss: 0.0155914 k_t: 0.0810387 M_global: 0.0330787\n",
      "step: 48000  d-loss: 0.0315767  g-loss: 0.0158359 k_t: 0.0809873 M_global: 0.033453\n",
      "step: 49000  d-loss: 0.0296132  g-loss: 0.016285 k_t: 0.0808925 M_global: 0.0317502\n",
      "step: 50000  d-loss: 0.0303575  g-loss: 0.0158089 k_t: 0.0808493 M_global: 0.0316446\n"
     ]
    }
   ],
   "source": [
    "for step in range(50001):\n",
    "    batch_x = mnist.train.next_batch(batch_size)[0]\n",
    "    z_D = sample_Z(batch_size, g_dim)\n",
    "    sess.run([d_optimizer, g_optimizer], feed_dict={x_d: batch_x, x_g: z_D})\n",
    "    z_G = sample_Z(batch_size, g_dim)\n",
    "    sess.run(g_optimizer, feed_dict={x_g: z_G})\n",
    "#     k_t = np.maximum(np.minimum(1., k_t + 0.001*(sess.run(balancer, feed_dict={x_d: batch_x, x_g: z_G}))), 0.)\n",
    "    sess.run(update_k, feed_dict={x_d: batch_x, x_g: z_G})\n",
    "    if step%1000==0:\n",
    "        d_loss_train, g_loss_train, k_tt, M_global_train = sess.run([d_loss, g_loss, k_t, M_global], feed_dict=\n",
    "                            {x_d: batch_x, x_g: sample_Z(batch_size, g_dim)})\n",
    "#         print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_t,\"M_global:\", M_global_train\n",
    "        print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_tt,\"M_global:\", M_global_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAD8CAYAAADOg5fGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIhKDGlERkRjUiIqIxKBGVEQkhv8HKI5umc914u0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4058d25c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gg = sess.run(g_sample, feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(g_sample), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(decoder(x_g), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(x_d), feed_dict = {x_d: x_train})\n",
    "gg_pic = np.array([np.reshape(m,(28,28)) for m in gg])\n",
    "fig, ax = plt.subplots(nrows=3, ncols=3)\n",
    "for i,row in enumerate(ax):\n",
    "    for j,col in enumerate(row):\n",
    "        ax[i][j].imshow(gg_pic[i*3+j], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0  d-loss: 0.0307634  g-loss: 0.0168936 k_t: 0.00964507 M_global: 0.0323568\n",
      "step: 1000  d-loss: 0.0315141  g-loss: 0.0217758 k_t: 0.00785393 M_global: 0.0376183\n",
      "step: 2000  d-loss: 0.0321538  g-loss: 0.0140907 k_t: 0.00615741 M_global: 0.0342701\n",
      "step: 3000  d-loss: 0.0317924  g-loss: 0.0173982 k_t: 0.00678315 M_global: 0.0333534\n",
      "step: 4000  d-loss: 0.0315408  g-loss: 0.0101243 k_t: 0.00806059 M_global: 0.0373092\n",
      "step: 5000  d-loss: 0.0310727  g-loss: 0.0117967 k_t: 0.0125216 M_global: 0.0350339\n",
      "step: 6000  d-loss: 0.0313728  g-loss: 0.0288112 k_t: 0.01244 M_global: 0.0446768\n",
      "step: 7000  d-loss: 0.0314398  g-loss: 0.0129572 k_t: 0.00968117 M_global: 0.0343907\n",
      "step: 8000  d-loss: 0.0320332  g-loss: 0.0161761 k_t: 0.010428 M_global: 0.032277\n",
      "step: 9000  d-loss: 0.0323819  g-loss: 0.0118645 k_t: 0.0117357 M_global: 0.0369171\n",
      "step: 10000  d-loss: 0.0312243  g-loss: 0.0155916 k_t: 0.0151511 M_global: 0.0315993\n",
      "step: 11000  d-loss: 0.0314078  g-loss: 0.0160842 k_t: 0.0123776 M_global: 0.0318877\n",
      "step: 12000  d-loss: 0.0310555  g-loss: 0.0179329 k_t: 0.00857294 M_global: 0.0335375\n",
      "step: 13000  d-loss: 0.0308451  g-loss: 0.0107721 k_t: 0.0102083 M_global: 0.0356605\n",
      "step: 14000  d-loss: 0.0320187  g-loss: 0.0163293 k_t: 0.011763 M_global: 0.0324347\n",
      "step: 15000  d-loss: 0.0314414  g-loss: 0.0176759 k_t: 0.00824149 M_global: 0.0334695\n",
      "step: 16000  d-loss: 0.0315852  g-loss: 0.0189753 k_t: 0.00536353 M_global: 0.0348188\n",
      "step: 17000  d-loss: 0.0322808  g-loss: 0.0203321 k_t: 0.0045768 M_global: 0.036519\n",
      "step: 18000  d-loss: 0.0316204  g-loss: 0.0164119 k_t: 0.00404475 M_global: 0.0322553\n",
      "step: 19000  d-loss: 0.0327314  g-loss: 0.0160517 k_t: 0.0051565 M_global: 0.0331695\n",
      "step: 20000  d-loss: 0.0303623  g-loss: 0.00866553 k_t: 0.00785095 M_global: 0.03698\n",
      "step: 21000  d-loss: 0.0298707  g-loss: 0.0173587 k_t: 0.0105862 M_global: 0.0323859\n",
      "step: 22000  d-loss: 0.0305926  g-loss: 0.0295485 k_t: 0.0117189 M_global: 0.045018\n",
      "step: 23000  d-loss: 0.0307057  g-loss: 0.0214932 k_t: 0.00325404 M_global: 0.036881\n",
      "step: 24000  d-loss: 0.0291855  g-loss: 0.014157 k_t: 0.00589771 M_global: 0.0297466\n",
      "step: 25000  d-loss: 0.0312942  g-loss: 0.0171751 k_t: 0.00343001 M_global: 0.0328516\n",
      "step: 26000  d-loss: 0.0300018  g-loss: 0.0119906 k_t: 0.00495349 M_global: 0.0331013\n",
      "step: 27000  d-loss: 0.0321033  g-loss: 0.0197795 k_t: 0.00346511 M_global: 0.0358654\n",
      "step: 28000  d-loss: 0.0291778  g-loss: 0.014978 k_t: 0.00194655 M_global: 0.0295814\n",
      "step: 29000  d-loss: 0.0306509  g-loss: 0.013272 k_t: 0.00413402 M_global: 0.0327867\n",
      "step: 30000  d-loss: 0.0304703  g-loss: 0.0166445 k_t: 0.0036568 M_global: 0.0319101\n",
      "step: 31000  d-loss: 0.0299408  g-loss: 0.0162303 k_t: 0.00246938 M_global: 0.0312207\n",
      "step: 32000  d-loss: 0.0300515  g-loss: 0.0144479 k_t: 0.00214363 M_global: 0.0306758\n",
      "step: 33000  d-loss: 0.0304843  g-loss: 0.0133888 k_t: 0.00357791 M_global: 0.0324095\n",
      "step: 34000  d-loss: 0.031473  g-loss: 0.0160472 k_t: 0.00431691 M_global: 0.0318183\n",
      "step: 35000  d-loss: 0.0292763  g-loss: 0.0161606 k_t: 0.00261334 M_global: 0.0308199\n",
      "step: 36000  d-loss: 0.0309453  g-loss: 0.0156018 k_t: 0.00287211 M_global: 0.0310969\n",
      "step: 37000  d-loss: 0.0298825  g-loss: 0.0126916 k_t: 0.00262536 M_global: 0.0321821\n",
      "step: 38000  d-loss: 0.0308433  g-loss: 0.0164099 k_t: 0.00288409 M_global: 0.0318552\n",
      "step: 39000  d-loss: 0.0308676  g-loss: 0.0148164 k_t: 0.00332221 M_global: 0.0315587\n",
      "step: 40000  d-loss: 0.0310951  g-loss: 0.0157457 k_t: 0.00290718 M_global: 0.0313161\n",
      "step: 41000  d-loss: 0.0302491  g-loss: 0.0111173 k_t: 0.00275463 M_global: 0.0343023\n",
      "step: 42000  d-loss: 0.0320089  g-loss: 0.0165339 k_t: 0.00401819 M_global: 0.0325716\n",
      "step: 43000  d-loss: 0.0307227  g-loss: 0.0145616 k_t: 0.00414816 M_global: 0.0316131\n",
      "step: 44000  d-loss: 0.0302126  g-loss: 0.0144344 k_t: 0.00410711 M_global: 0.0309733\n",
      "step: 45000  d-loss: 0.0304505  g-loss: 0.0159429 k_t: 0.00322932 M_global: 0.0311938\n",
      "step: 46000  d-loss: 0.0292778  g-loss: 0.0147921 k_t: 0.00288803 M_global: 0.0294524\n",
      "step: 47000  d-loss: 0.0302089  g-loss: 0.0102792 k_t: 0.00460949 M_global: 0.0351052\n",
      "step: 48000  d-loss: 0.0304661  g-loss: 0.00912728 k_t: 0.012456 M_global: 0.0367424\n",
      "step: 49000  d-loss: 0.0311227  g-loss: 0.00848623 k_t: 0.0187676 M_global: 0.0384368\n",
      "step: 50000  d-loss: 0.0323803  g-loss: 0.00638299 k_t: 0.0251632 M_global: 0.0424284\n",
      "step: 51000  d-loss: 0.0308143  g-loss: 0.00259162 k_t: 0.0351117 M_global: 0.0437663\n",
      "step: 52000  d-loss: 0.0295916  g-loss: 0.0937069 k_t: 0.00230244 M_global: 0.108611\n",
      "step: 53000  d-loss: 0.0318553  g-loss: 0.0421202 k_t: -0.000921669 M_global: 0.0580284\n",
      "step: 54000  d-loss: 0.0313179  g-loss: 0.0442691 k_t: -0.000182454 M_global: 0.059924\n",
      "step: 55000  d-loss: 0.0304912  g-loss: 0.0462324 k_t: -0.000172984 M_global: 0.061474\n",
      "step: 56000  d-loss: 0.0317595  g-loss: 0.0323417 k_t: -0.000963535 M_global: 0.0482058\n",
      "step: 57000  d-loss: 0.0318056  g-loss: 0.000719398 k_t: -0.000914702 M_global: 0.046988\n",
      "step: 58000  d-loss: 0.0315239  g-loss: 0.000396279 k_t: 0.000337448 M_global: 0.0468898\n",
      "step: 59000  d-loss: 0.0296527  g-loss: 0.0345636 k_t: 0.00135345 M_global: 0.0494133\n",
      "step: 60000  d-loss: 0.0298038  g-loss: 0.0118544 k_t: -0.00102624 M_global: 0.0328331\n",
      "step: 61000  d-loss: 0.0308955  g-loss: 0.000246376 k_t: 0.000690698 M_global: 0.0460972\n",
      "step: 62000  d-loss: 0.0305871  g-loss: 0.0420312 k_t: 0.000371368 M_global: 0.0573326\n",
      "step: 63000  d-loss: 0.0300104  g-loss: 0.00137734 k_t: -0.00041364 M_global: 0.0436374\n",
      "step: 64000  d-loss: 0.0310563  g-loss: 0.0393882 k_t: 0.000612327 M_global: 0.0549284\n",
      "step: 65000  d-loss: 0.0317121  g-loss: 0.0125983 k_t: -0.000899888 M_global: 0.0349528\n",
      "step: 66000  d-loss: 0.0320414  g-loss: 0.0 k_t: 0.000519528 M_global: 0.048062\n",
      "step: 67000  d-loss: 0.0303351  g-loss: 0.0383688 k_t: -0.000122382 M_global: 0.053534\n",
      "step: 68000  d-loss: 0.0310702  g-loss: 0.000254993 k_t: -0.000277881 M_global: 0.0463503\n",
      "step: 69000  d-loss: 0.0295542  g-loss: 0.0372531 k_t: 0.00102596 M_global: 0.0520493\n",
      "step: 70000  d-loss: 0.0304551  g-loss: 0.0252508 k_t: -0.000755031 M_global: 0.0404688\n",
      "step: 71000  d-loss: 0.0292799  g-loss: 0.0 k_t: 0.00029039 M_global: 0.0439199\n",
      "step: 72000  d-loss: 0.0317028  g-loss: 0.00379502 k_t: 0.00101663 M_global: 0.043765\n",
      "step: 73000  d-loss: 0.0298539  g-loss: 0.0313973 k_t: -0.000517405 M_global: 0.0463161\n",
      "step: 74000  d-loss: 0.031469  g-loss: 0.0 k_t: -0.000549957 M_global: 0.0472035\n",
      "step: 75000  d-loss: 0.0303683  g-loss: 0.0185356 k_t: 0.00114463 M_global: 0.0337304\n",
      "step: 76000  d-loss: 0.0313916  g-loss: 0.0226851 k_t: -0.000779806 M_global: 0.038372\n",
      "step: 77000  d-loss: 0.0296866  g-loss: 0.0 k_t: 0.000281491 M_global: 0.04453\n",
      "step: 78000  d-loss: 0.0308213  g-loss: 0.0 k_t: 9.95568e-05 M_global: 0.0462319\n",
      "step: 79000  d-loss: 0.0294815  g-loss: 0.000624049 k_t: 0.00108876 M_global: 0.0435992\n",
      "step: 80000  d-loss: 0.0318431  g-loss: 0.0381262 k_t: 0.0010081 M_global: 0.054067\n",
      "step: 81000  d-loss: 0.0309897  g-loss: 0.037922 k_t: 0.00042828 M_global: 0.053425\n",
      "step: 82000  d-loss: 0.0320211  g-loss: 0.000977947 k_t: -0.000669024 M_global: 0.0470527\n",
      "step: 83000  d-loss: 0.0311799  g-loss: 0.0 k_t: -0.000332697 M_global: 0.0467699\n",
      "step: 84000  d-loss: 0.0317426  g-loss: 0.0 k_t: 5.5284e-05 M_global: 0.0476139\n",
      "step: 85000  d-loss: 0.0303445  g-loss: 0.0 k_t: -5.99669e-05 M_global: 0.0455168\n",
      "step: 86000  d-loss: 0.0318187  g-loss: 0.0 k_t: 0.000640951 M_global: 0.0477281\n",
      "step: 87000  d-loss: 0.0314194  g-loss: 0.0375265 k_t: 0.0003993 M_global: 0.0532437\n",
      "step: 88000  d-loss: 0.0306265  g-loss: 0.0312967 k_t: -0.000581781 M_global: 0.0466008\n",
      "step: 89000  d-loss: 0.0301616  g-loss: 0.0315937 k_t: -0.000777215 M_global: 0.0466622\n",
      "step: 90000  d-loss: 0.0299954  g-loss: 0.0350136 k_t: -0.000315442 M_global: 0.0500058\n",
      "step: 91000  d-loss: 0.0303127  g-loss: 0.0323699 k_t: -0.000462929 M_global: 0.0475188\n",
      "step: 92000  d-loss: 0.0302987  g-loss: 0.0309278 k_t: -0.000750724 M_global: 0.0460655\n",
      "step: 93000  d-loss: 0.029694  g-loss: 0.037896 k_t: 0.000606235 M_global: 0.0527545\n",
      "step: 94000  d-loss: 0.0306608  g-loss: 0.0375797 k_t: 0.000380871 M_global: 0.0529172\n",
      "step: 95000  d-loss: 0.0307677  g-loss: 0.0296748 k_t: -0.00062303 M_global: 0.0450494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 96000  d-loss: 0.0297082  g-loss: 0.0363576 k_t: 0.00100751 M_global: 0.05123\n",
      "step: 97000  d-loss: 0.0295528  g-loss: 0.0376114 k_t: 0.000454865 M_global: 0.0523964\n",
      "step: 98000  d-loss: 0.0302055  g-loss: 1.40374e-05 k_t: 0.00086221 M_global: 0.0452943\n",
      "step: 99000  d-loss: 0.029992  g-loss: 0.0 k_t: 0.00144157 M_global: 0.044988\n",
      "step: 100000  d-loss: 0.0305125  g-loss: 8.62144e-07 k_t: -0.000211251 M_global: 0.0457679\n"
     ]
    }
   ],
   "source": [
    "for step in range(100001):\n",
    "    batch_x = mnist.train.next_batch(batch_size)[0]\n",
    "    z_D = sample_Z(batch_size, g_dim)\n",
    "    sess.run([d_optimizer, g_optimizer], feed_dict={x_d: batch_x, x_g: z_D})\n",
    "    z_G = sample_Z(batch_size, g_dim)\n",
    "    sess.run(g_optimizer, feed_dict={x_g: z_G})\n",
    "#     k_t = np.maximum(np.minimum(1., k_t + 0.001*(sess.run(balancer, feed_dict={x_d: batch_x, x_g: z_G}))), 0.)\n",
    "    sess.run(update_k, feed_dict={x_d: batch_x, x_g: z_G})\n",
    "    if step%1000==0:\n",
    "        d_loss_train, g_loss_train, k_tt, M_global_train = sess.run([d_loss, g_loss, k_t, M_global], feed_dict=\n",
    "                            {x_d: batch_x, x_g: sample_Z(batch_size, g_dim)})\n",
    "#         print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_t,\"M_global:\", M_global_train\n",
    "        print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_tt,\"M_global:\", M_global_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAD8CAYAAADOg5fGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1b5ae60950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gg = sess.run(g_sample, feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(g_sample), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(decoder(x_g), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(x_d), feed_dict = {x_d: x_train})\n",
    "gg_pic = np.array([np.reshape(m,(28,28)) for m in gg])\n",
    "fig, ax = plt.subplots(nrows=3, ncols=3)\n",
    "for i,row in enumerate(ax):\n",
    "    for j,col in enumerate(row):\n",
    "        ax[i][j].imshow(gg_pic[i*3+j], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0  d-loss: 0.0302666  g-loss: 3.32747e-05 k_t: -0.000196151 M_global: 0.0453666\n",
      "step: 1000  d-loss: 0.030076  g-loss: 0.0 k_t: -0.000212417 M_global: 0.0451141\n",
      "step: 2000  d-loss: 0.0304685  g-loss: 0.0357063 k_t: -0.000165151 M_global: 0.0509376\n",
      "step: 3000  d-loss: 0.0288192  g-loss: 0.0137574 k_t: 0.00130985 M_global: 0.0294984\n",
      "step: 4000  d-loss: 0.028956  g-loss: 0.0371196 k_t: 0.000855876 M_global: 0.0516135\n",
      "step: 5000  d-loss: 0.0296152  g-loss: 0.0 k_t: 0.0017007 M_global: 0.0444228\n",
      "step: 6000  d-loss: 0.0291948  g-loss: 0.0188446 k_t: -0.00104597 M_global: 0.0334322\n",
      "step: 7000  d-loss: 0.0294825  g-loss: 0.0102495 k_t: -0.00103003 M_global: 0.0339584\n",
      "step: 8000  d-loss: 0.0293925  g-loss: 0.032814 k_t: -0.000347795 M_global: 0.0475046\n",
      "step: 9000  d-loss: 0.0315898  g-loss: 3.93555e-05 k_t: 0.00210848 M_global: 0.0473454\n",
      "step: 10000  d-loss: 0.0290327  g-loss: 0.0359668 k_t: -0.000188326 M_global: 0.0504798\n",
      "step: 11000  d-loss: 0.0303848  g-loss: 0.0363901 k_t: 0.00067783 M_global: 0.0515948\n",
      "step: 12000  d-loss: 0.0289879  g-loss: 0.000418192 k_t: -0.00127336 M_global: 0.0430628\n",
      "step: 13000  d-loss: 0.0300718  g-loss: 0.0323686 k_t: 0.00132722 M_global: 0.047426\n",
      "step: 14000  d-loss: 0.0307298  g-loss: 0.0 k_t: 0.00117212 M_global: 0.0460946\n",
      "step: 15000  d-loss: 0.0296681  g-loss: 0.0148493 k_t: -0.00105167 M_global: 0.0296755\n",
      "step: 16000  d-loss: 0.0304059  g-loss: 0.0376773 k_t: 0.000823509 M_global: 0.0528957\n",
      "step: 17000  d-loss: 0.0292474  g-loss: 0.0 k_t: -0.000583199 M_global: 0.0438711\n",
      "step: 18000  d-loss: 0.0293184  g-loss: 0.0259463 k_t: -0.00106902 M_global: 0.0405917\n",
      "step: 19000  d-loss: 0.0300874  g-loss: 0.0363374 k_t: 0.000443523 M_global: 0.0513891\n",
      "step: 20000  d-loss: 0.0305651  g-loss: 0.0 k_t: 0.000309928 M_global: 0.0458476\n",
      "step: 21000  d-loss: 0.0306486  g-loss: 2.52656e-05 k_t: 0.000693632 M_global: 0.0459477\n",
      "step: 22000  d-loss: 0.0302826  g-loss: 0.0319286 k_t: -0.000529931 M_global: 0.0470614\n",
      "step: 23000  d-loss: 0.0297569  g-loss: 0.00845734 k_t: 0.00230671 M_global: 0.0362072\n",
      "step: 24000  d-loss: 0.0295291  g-loss: 0.00031037 k_t: -0.00076732 M_global: 0.0439829\n",
      "step: 25000  d-loss: 0.0314702  g-loss: 0.0137618 k_t: -0.00112635 M_global: 0.0334201\n",
      "step: 26000  d-loss: 0.0310706  g-loss: 0.0384355 k_t: 0.000626756 M_global: 0.0539828\n",
      "step: 27000  d-loss: 0.0318591  g-loss: 0.0 k_t: -0.00101064 M_global: 0.0477887\n",
      "step: 28000  d-loss: 0.0297139  g-loss: 0.0 k_t: 0.000229083 M_global: 0.0445709\n",
      "step: 29000  d-loss: 0.0290555  g-loss: 0.028287 k_t: 0.00188504 M_global: 0.0428414\n",
      "step: 30000  d-loss: 0.0287262  g-loss: 0.0 k_t: -0.000120673 M_global: 0.0430893\n",
      "step: 31000  d-loss: 0.0307006  g-loss: 0.0358275 k_t: 4.2914e-05 M_global: 0.0511785\n",
      "step: 32000  d-loss: 0.0293939  g-loss: 7.18462e-06 k_t: 0.00119377 M_global: 0.0440837\n",
      "step: 33000  d-loss: 0.0284991  g-loss: 0.0 k_t: -0.000284293 M_global: 0.0427486\n",
      "step: 34000  d-loss: 0.0290151  g-loss: 0.032117 k_t: -0.000662394 M_global: 0.0466139\n",
      "step: 35000  d-loss: 0.02845  g-loss: 0.0 k_t: 0.00070067 M_global: 0.042675\n",
      "step: 36000  d-loss: 0.0293452  g-loss: 0.034637 k_t: -0.000169839 M_global: 0.0493066\n",
      "step: 37000  d-loss: 0.0297192  g-loss: 0.0 k_t: -0.000903434 M_global: 0.0445787\n",
      "step: 38000  d-loss: 0.0305688  g-loss: 0.0339229 k_t: 0.00107735 M_global: 0.0492255\n",
      "step: 39000  d-loss: 0.0300033  g-loss: 0.0 k_t: 0.000311886 M_global: 0.0450049\n",
      "step: 40000  d-loss: 0.0301239  g-loss: 0.0319399 k_t: 0.00204494 M_global: 0.0470345\n",
      "step: 41000  d-loss: 0.0289942  g-loss: 0.0213479 k_t: -0.00132622 M_global: 0.0358308\n",
      "step: 42000  d-loss: 0.0309308  g-loss: 0.0 k_t: 0.00106205 M_global: 0.0463961\n",
      "step: 43000  d-loss: 0.0294935  g-loss: 0.0360763 k_t: 0.000348407 M_global: 0.0508294\n",
      "step: 44000  d-loss: 0.0291966  g-loss: 0.0125785 k_t: -0.00122361 M_global: 0.0311933\n",
      "step: 45000  d-loss: 0.029193  g-loss: 0.0 k_t: -9.82779e-06 M_global: 0.0437895\n",
      "step: 46000  d-loss: 0.0285099  g-loss: 0.0281319 k_t: -0.000721737 M_global: 0.0423767\n",
      "step: 47000  d-loss: 0.0292171  g-loss: 0.00724065 k_t: 0.00171947 M_global: 0.0366037\n",
      "step: 48000  d-loss: 0.0292407  g-loss: 0.0135084 k_t: -0.00131629 M_global: 0.030326\n",
      "step: 49000  d-loss: 0.0279056  g-loss: 0.0 k_t: -0.000891358 M_global: 0.0418583\n",
      "step: 50000  d-loss: 0.0309137  g-loss: 0.0336712 k_t: -0.000540882 M_global: 0.049119\n",
      "step: 51000  d-loss: 0.028026  g-loss: 0.0 k_t: 0.000949338 M_global: 0.0420389\n",
      "step: 52000  d-loss: 0.0286299  g-loss: 0.0362901 k_t: 0.000874939 M_global: 0.0506209\n",
      "step: 53000  d-loss: 0.0287179  g-loss: 0.0356866 k_t: 0.000107606 M_global: 0.0500475\n",
      "step: 54000  d-loss: 0.0292462  g-loss: 0.0 k_t: -0.000571967 M_global: 0.0438693\n",
      "step: 55000  d-loss: 0.0287249  g-loss: 0.0215682 k_t: -0.00141065 M_global: 0.0359155\n",
      "step: 56000  d-loss: 0.0299784  g-loss: 0.0 k_t: 0.000381862 M_global: 0.0449676\n",
      "step: 57000  d-loss: 0.0298289  g-loss: 0.0 k_t: 0.000167318 M_global: 0.0447433\n",
      "step: 58000  d-loss: 0.0283918  g-loss: 0.0325178 k_t: 0.00152191 M_global: 0.0467384\n",
      "step: 59000  d-loss: 0.0276639  g-loss: 0.0360312 k_t: 0.000505934 M_global: 0.0498722\n",
      "step: 60000  d-loss: 0.0288719  g-loss: 0.0364066 k_t: 0.00178797 M_global: 0.0508751\n",
      "step: 61000  d-loss: 0.029411  g-loss: 0.0283118 k_t: -0.0012007 M_global: 0.0430003\n",
      "step: 62000  d-loss: 0.0281022  g-loss: 0.0 k_t: 4.08811e-05 M_global: 0.0421533\n",
      "step: 63000  d-loss: 0.0287502  g-loss: 0.0359043 k_t: 0.00169919 M_global: 0.0503099\n",
      "step: 64000  d-loss: 0.0288514  g-loss: 0.0302003 k_t: -0.000966731 M_global: 0.0446114\n",
      "step: 65000  d-loss: 0.0281391  g-loss: 0.0 k_t: 0.000502729 M_global: 0.0422087\n",
      "step: 66000  d-loss: 0.029044  g-loss: 0.0329498 k_t: 0.00155436 M_global: 0.0474974\n",
      "step: 67000  d-loss: 0.0284825  g-loss: 0.0 k_t: -0.00127666 M_global: 0.0427238\n",
      "step: 68000  d-loss: 0.0283996  g-loss: 0.0 k_t: -0.00107109 M_global: 0.0425995\n",
      "step: 69000  d-loss: 0.0277273  g-loss: 0.0 k_t: -0.000977844 M_global: 0.0415909\n",
      "step: 70000  d-loss: 0.0291727  g-loss: 0.0 k_t: 0.00097093 M_global: 0.0437591\n",
      "step: 71000  d-loss: 0.0279168  g-loss: 0.0225258 k_t: -0.0013099 M_global: 0.0364694\n",
      "step: 72000  d-loss: 0.0281398  g-loss: 5.72671e-05 k_t: -0.00132666 M_global: 0.0421523\n",
      "step: 73000  d-loss: 0.0281028  g-loss: 0.0 k_t: -0.0010872 M_global: 0.0421541\n",
      "step: 74000  d-loss: 0.0280841  g-loss: 0.0 k_t: 0.000125269 M_global: 0.0421261\n",
      "step: 75000  d-loss: 0.0289152  g-loss: 0.00797312 k_t: 0.0023715 M_global: 0.035428\n",
      "step: 76000  d-loss: 0.0289195  g-loss: 0.0289189 k_t: 0.00160452 M_global: 0.0434018\n",
      "step: 77000  d-loss: 0.0278696  g-loss: 0.000286915 k_t: 0.00106981 M_global: 0.041518\n",
      "step: 78000  d-loss: 0.0278721  g-loss: 0.04178 k_t: 0.000602703 M_global: 0.0557287\n",
      "step: 79000  d-loss: 0.0284932  g-loss: 0.000566574 k_t: 0.00185688 M_global: 0.0421749\n",
      "step: 80000  d-loss: 0.0292405  g-loss: 0.0087666 k_t: -0.00134753 M_global: 0.0350765\n",
      "step: 81000  d-loss: 0.0273022  g-loss: 0.025725 k_t: -0.00153026 M_global: 0.0393565\n",
      "step: 82000  d-loss: 0.0282162  g-loss: 0.0 k_t: -0.000774711 M_global: 0.0423243\n",
      "step: 83000  d-loss: 0.0294109  g-loss: 0.0 k_t: -0.00139682 M_global: 0.0441163\n",
      "step: 84000  d-loss: 0.0283499  g-loss: 0.0 k_t: -0.000338462 M_global: 0.0425249\n",
      "step: 85000  d-loss: 0.0277469  g-loss: 0.04672 k_t: 0.00642351 M_global: 0.0607435\n",
      "step: 86000  d-loss: 0.0276824  g-loss: 0.0313103 k_t: 0.000916242 M_global: 0.0451659\n",
      "step: 87000  d-loss: 0.0262192  g-loss: 0.0 k_t: -0.00138256 M_global: 0.0393289\n",
      "step: 88000  d-loss: 0.0286912  g-loss: 0.0362224 k_t: -0.00108293 M_global: 0.0505484\n",
      "step: 89000  d-loss: 0.026745  g-loss: 0.0405723 k_t: 0.00162683 M_global: 0.0539778\n",
      "step: 90000  d-loss: 0.0289311  g-loss: 0.024818 k_t: 0.00251974 M_global: 0.0393148\n",
      "step: 91000  d-loss: 0.0271719  g-loss: 0.0090027 k_t: 0.00185153 M_global: 0.0317801\n",
      "step: 92000  d-loss: 0.0286522  g-loss: 0.0 k_t: 0.00099922 M_global: 0.0429784\n",
      "step: 93000  d-loss: 0.0282981  g-loss: 0.0 k_t: -0.000360158 M_global: 0.0424471\n",
      "step: 94000  d-loss: 0.027133  g-loss: 0.0 k_t: 0.000786011 M_global: 0.0406994\n",
      "step: 95000  d-loss: 0.0282252  g-loss: 0.0 k_t: -0.000710784 M_global: 0.0423378\n",
      "step: 96000  d-loss: 0.0282041  g-loss: 0.0 k_t: -0.000503346 M_global: 0.0423062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 97000  d-loss: 0.027872  g-loss: 0.0 k_t: -0.0010185 M_global: 0.041808\n",
      "step: 98000  d-loss: 0.0278294  g-loss: 0.0 k_t: -0.00053671 M_global: 0.0417441\n",
      "step: 99000  d-loss: 0.0276932  g-loss: 0.0 k_t: -0.00148112 M_global: 0.0415398\n",
      "step: 100000  d-loss: 0.0272787  g-loss: 0.0374983 k_t: -0.000812262 M_global: 0.0511224\n"
     ]
    }
   ],
   "source": [
    "for step in range(100001):\n",
    "    batch_x = mnist.train.next_batch(batch_size)[0]\n",
    "    z_D = sample_Z(batch_size, g_dim)\n",
    "    sess.run([d_optimizer, g_optimizer], feed_dict={x_d: batch_x, x_g: z_D})\n",
    "    z_G = sample_Z(batch_size, g_dim)\n",
    "    sess.run(g_optimizer, feed_dict={x_g: z_G})\n",
    "#     k_t = np.maximum(np.minimum(1., k_t + 0.001*(sess.run(balancer, feed_dict={x_d: batch_x, x_g: z_G}))), 0.)\n",
    "    sess.run(update_k, feed_dict={x_d: batch_x, x_g: z_G})\n",
    "    if step%1000==0:\n",
    "        d_loss_train, g_loss_train, k_tt, M_global_train = sess.run([d_loss, g_loss, k_t, M_global], feed_dict=\n",
    "                            {x_d: batch_x, x_g: sample_Z(batch_size, g_dim)})\n",
    "#         print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_t,\"M_global:\", M_global_train\n",
    "        print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_tt,\"M_global:\", M_global_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAD8CAYAAADOg5fGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAD9dJREFUeJzt3U+oXeV+xvHvr1FHcZDoJYSYGgeZ\nBDoIXLy34FTIdZK0lGIGJYIlEwXlOjC384Ij6eROAoacgSiFCGZQkBgCdtKQP4g1CTFBECMnppIW\ngxNN++vgLC/nBpOz1n73ftdeb74fWOy11z6e9bqenCdrr32y3shMJEmz+YuxByBJU2aJSlIBS1SS\nCliiklTAEpWkApaoJBWwRCWpQFGJRsS+iLgaEdcj4si8BqVxmWu7zHb+YtZfto+ITcAXwPPADeAc\ncDAzL89veKrNXNtltovxSMF/+yxwPTO/BIiI94H9wH0DiYiH/Z9HfZeZvxp7EBsw1+GmkCsMzNZc\n++Va8nZ+B/D1uuc3um26v6/GHkAP5jrcFHIFsx2qV64lZ6K9RMRh4PCi96O6zLVN5jpcSYl+A+xc\n9/ypbtufycyjwFHw7cFEmGu7NszWXIcreTt/DtgdEc9ExGPAi8DJ+QxLIzLXdpntAsx8JpqZdyPi\nVeAjYBNwLDMvzW1kGoW5tstsF2PmX3GaaWe+PbiQmb8eexDzZq7m2qheufovliSpgCUqSQUsUUkq\nYIlKUgFLVJIKWKKSVMASlaQClqgkFbBEJamAJSpJBSxRSSpgiUpSAUtUkgpYopJUYMMSjYhjEXEr\nIj5ft21rRJyKiGvd45bFDlPzZq7tMtu6+pyJHgf23bPtCHA6M3cDp7vnmpbjmGurjmO21WxYopn5\nCXD7ns37gZVufQU4MOdxacHMtV1mW9es04Nsy8zVbv0msO1+X+jsgZNiru3qla25Dlc8ZXJm5oOm\nEXD2wGky13Y9KFtzHW7WT+e/jYjtAN3jrfkNSSMy13aZ7YLMWqIngUPd+iHgw/kMRyMz13aZ7aJk\n5gMX4D1gFfgJuAG8DDzB2id814CPga0bfZ/ue+VDvpzvc5xqLObaZq7zzHYJjuvYS69cnTK5LqfW\nbZO5tskpkyVp0SxRSSpgiUpSAUtUkgpYopJUwBKVpAKWqCQVsEQlqYAlKkkFLFFJKmCJSlIBS1SS\nCliiklTAEpWkAn2mTN4ZEWci4nJEXIqI17rtTsE6YebaJnOtr8+Z6F3gjczcA/wWeCUi9uAUrFNn\nrm0y18r6TJm8mpkXu/U7wBVgB07BOmnm2iZzrW/QbJ8RsQvYC5zFKVibYa5tMtdKBszbshm4APxt\n9/x/7nn9v52zZVpz8ZiruZprea69Pp2PiEeBE8C7mflBt9kpWCfOXNtkrnX1+XQ+gHeAK5n59rqX\nnIJ1wsy1TeY6gh6n9M+xdmr7GfBpt7yAU7Au7O1Bpbd75mqu5jqHXJ0yuS6n1m2TubbJKZMladEs\nUUkqYIlKUgFLVJIKWKKSVMASlaQClqgkFbBEJamAJSpJBSxRSSpgiUpSgUE3ZZ6D74AfusepeZLy\ncT89j4EsIXNtk7n2UPUGJAARcX6KN2uY6rhrmerxmeq4a5nq8ak5bt/OS1IBS1SSCoxRokdH2Oc8\nTHXctUz1+Ex13LVM9fhUG3f1a6KS1BLfzktSAUtUkgpUK9GI2BcRVyPiekQcqbXfoSJiZ0SciYjL\nEXEpIl7rtm+NiFMRca173DL2WJfFFLI11+HMtecYalwTjYhNwBfA88AN4BxwMDMvL3znA3Vzcm/P\nzIsR8ThwATgAvATczsy3uj9QWzLzzRGHuhSmkq25DmOu/dU6E30WuJ6ZX2bmj8D7wP5K+x4kM1cz\n82K3fge4Auxgbbwr3ZetsBaUJpKtuQ5mrj0VleiA0/0dwNfrnt/oti21iNgF7AXOAtsyc7V76Saw\nbaRhLdzAt3GTy/ZhzRXa/pkdK9eZS7Q73f8j8DtgD3AwIvbMa2Bji4jNwAng9cz8fv1ruXYNpMnf\nDTPXNnOFtrMdNdfMnGkB/hr4aN3zPwB/eNDXdv8jD/PyX7Me71rLkFzXff3Yx3XsZelznfFnduzj\nOvbSK9eSuzj90un+b+79oog4DBwG/qpgX634auwB9DA0V00jV+iRrbn+mV65LvyDpcw8mmt3U/mb\nRe9L9fyca07wDj+6P3MdrqREvwF2rnv+VLftF2XmvxXsS/UMylWTYrYLUFKi54DdEfFMRDwGvAic\nnM+wNCJzbZfZLsDM10Qz825EvMraB0abgGOZeWluI9MozLVdZrsYVe/iFBH1dracLrR4rclczbVR\nvXL1BiSSVMASlaQClqgkFbBEJamAJSpJBSxRSSpgiUpSAUtUkgpYopJUwBKVpAKWqCQVsEQlqYAl\nKkkFNizRiDgWEbci4vN127ZGxKmIuNY9blnsMDVv5tous62rz5nocWDfPduOAKczczdwunuuaTmO\nubbqOGZbzYYlmpmfALfv2bwfWOnWV4ADcx6XFsxc22W2dc16TXRbZq526zeBbXMaj8Zlru0y2wUp\nmTIZgMzMB90B2ylYp8lc2/WgbM11uFnPRL+NiO0A3eOt+32hU7BOirm2q1e25jrcrCV6EjjUrR8C\nPpzPcDQyc22X2S5KZj5wAd4DVoGfgBvAy8ATrH3Cdw34GNi60ffpvlc+5Mv5PsepxmKubeY6z2yX\n4LiOvfTK1dk+63JWyDaZa5uc7VOSFs0SlaQClqgkFbBEJamAJSpJBSxRSSpgiUpSAUtUkgpYopJU\nwBKVpAKWqCQVsEQlqYAlKkkFLFFJKtBnyuSdEXEmIi5HxKWIeK3b7hSsE2aubTLX+vqcid4F3sjM\nPcBvgVciYg9OwTp15tomc62sz5TJq5l5sVu/A1wBduAUrJNmrm0y1/oGXRONiF3AXuAsTsHaDHNt\nk7nW0XvK5IjYDJwAXs/M7yPiT69lOgXrVJlrm8y1op4TXz0KfAT8ft22q8D2bn07cNWJryY3oZm5\nmqu5Fuba59P5AN4BrmTm2+tecgrWCTPXNpnrCHr8bfQca638GfBpt7yAU7Au7G+2Smcr5mqu5jqH\nXJ0yuS6n1m2TubbJKZMladEsUUkqYIlKUgFLVJIKWKKSVMASlaQClqgkFbBEJamAJSpJBSxRSSpg\niUpSAUtUkgr0vinznHwH/NA9Ts2TlI/76XkMZAmZa5vMtYeqd3ECiIjzU7zjzVTHXctUj89Ux13L\nVI9PzXH7dl6SCliiklRgjBI9OsI+52Gq465lqsdnquOuZarHp9q4q18TlaSW+HZekgpUK9GI2BcR\nVyPiekQcqbXfoSJiZ0SciYjLEXEpIl7rtm+NiFMRca173DL2WJfFFLI11+HMtecYarydj4hNwBfA\n88AN4BxwMDMvL3znA0XEdtbm574YEY8DF4ADwEvA7cx8q/sDtSUz3xxxqEthKtma6zDm2l+tM9Fn\ngeuZ+WVm/gi8D+yvtO9BMnM1My9263eAK8AO1sa70n3ZCmtBaSLZmutg5tpTUYkOON3fAXy97vmN\nbttSi4hdwF7gLLAtM1e7l24C20Ya1sINfBs3uWwf1lyh7Z/ZsXKduUS70/0/Ar8D9gAHI2LPvAY2\ntojYDJwAXs/M79e/lmvXQJr8tQZzbTNXaDvbMXMtORMdcrr/DbBz3fOnum1LKSIeZS2QdzPzg27z\nt931l5+vw9waa3wLNvRt3GSyfchzhUZ/ZsfOdeYPliLi74B9mfmP3fN/AH6Tma/+wtc+wtpF6mcK\nxtqC7zLzV2MP4kGG5Nq9/gjwU8UhLqOlzxVm+pk11x65LvyDpYg4DPwH8L+L3tcEfDX2AOYlIg5H\nxHnWsn3YmWubeuVaUqK9Tvcz82hm/jozdxfsS/UMzXVyd/h5iG2YrbkOV1Ki54DdEfFMRDwGvAic\nnM+wNCJzbZfZLsDMN2XOzLsR8SrwEbAJOJaZl+Y2Mo3CXNtltotR9QYkEdHsr4/0dKHFt0nmaq6N\n6pWrNyCRpAKWqCQVsEQlqYAlKkkFLFFJKmCJSlIBS1SSCliiklTAEpWkApaoJBWwRCWpgCUqSQUs\nUUkqYIlKUoENSzQijkXErYj4fN22rRFxKiKudY9bFjtMzZu5tsts6+pzJnoc2HfPtiPA6W7Kj9Pd\nc03Lccy1Vccx22o2LNHM/AS4fc/m/cBKt74CHJjzuLRg5tous61r1mui2zJztVu/CWyb03g0LnNt\nl9kuyMxzLP0sM/NB0wh0UyYfLt2P6jLXdj0oW3MdbtYz0W8jYjtA93jrfl/oFKyTYq7t6pWtuQ43\na4meBA5164eAD+czHI3MXNtltouSmQ9cgPeAVeAn4AbwMvAEa5/wXQM+BrZu9H2675UP+XK+z3Gq\nsZhrm7nOM9slOK5jL71ydcrkupxat03m2ianTJakRbNEJamAJSpJBSxRSSpgiUpSAUtUkgpYopJU\nwBKVpAKWqCQVsEQlqYAlKkkFLFFJKmCJSlIBS1SSCvSZMnlnRJyJiMsRcSkiXuu2OwXrhJlrm8y1\nvj5noneBNzJzD/Bb4JWI2INTsE6dubbJXCvrM2XyamZe7NbvAFeAHTgF66SZa5vMtb5B10QjYhew\nFziLU7A2w1zbZK519J4yOSI2AyeA1zPz+4j402uZTsE6VebaJnOtqOfEV48CHwG/X7ftKrC9W98O\nXHXiq8lNaGau5mquhbn2+XQ+gHeAK5n59rqXnIJ1wsy1TeY6gh5/Gz3HWit/BnzaLS/gFKwL+5ut\n0tmKuZqruc4hV6dMrsupddtkrm1yymRJWjRLVJIKWKKSVMASlaQClqgkFbBEJamAJSpJBSxRSSpg\niUpSAUtUkgpYopJUwBKVpAK9b8o8J98BP3SPU/Mk5eN+eh4DWULm2iZz7aHqXZwAIuL8FO94M9Vx\n1zLV4zPVcdcy1eNTc9y+nZekApaoJBUYo0SPjrDPeZjquGuZ6vGZ6rhrmerxqTbu6tdEJaklvp2X\npALVSjQi9kXE1Yi4HhFHau13qIjYGRFnIuJyRFyKiNe67Vsj4lREXOset4w91mUxhWzNdThz7TmG\nGm/nI2IT8AXwPHADOAcczMzLC9/5QBGxnbX5uS9GxOPABeAA8BJwOzPf6v5AbcnMN0cc6lKYSrbm\nOoy59lfrTPRZ4HpmfpmZPwLvA/sr7XuQzFzNzIvd+h3gCrCDtfGudF+2wlpQmki25jqYufZUq0R3\nAF+ve36j27bUImIXsBc4C2zLzNXupZvAtpGGtWwml6259mKuPfnB0n1ExGbgBPB6Zn6//rVcuwbi\nrzVMkLm2acxca5XoN8DOdc+f6rYtpYh4lLVA3s3MD7rN33bXX36+DnNrrPEtmclka66DmGtPtUr0\nHLA7Ip6JiMeAF4GTlfY9SEQE8A5wJTPfXvfSSeBQt34I+LD22JbUJLI118HMte8Yav2yfUS8APwL\nsAk4lpn/XGXHA0XEc8C/A/8J/F+3+Z9Yu87yr8BfAl8Bf5+Zt0cZ5JKZQrbmOpy59hyD/2JJkmbn\nB0uSVMASlaQClqgkFbBEJamAJSpJBSxRSSpgiUpSAUtUkgr8P1Ju0HbB/VOLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1b5a25cc90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gg = sess.run(g_sample, feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(g_sample), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(decoder(x_g), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(x_d), feed_dict = {x_d: x_train})\n",
    "gg_pic = np.array([np.reshape(m,(28,28)) for m in gg])\n",
    "fig, ax = plt.subplots(nrows=3, ncols=3)\n",
    "for i,row in enumerate(ax):\n",
    "    for j,col in enumerate(row):\n",
    "        ax[i][j].imshow(gg_pic[i*3+j], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0  d-loss: 0.028183  g-loss: 0.0370366 k_t: -0.000835222 M_global: 0.0511126\n",
      "step: 1000  d-loss: 0.027264  g-loss: 0.025989 k_t: -0.00173008 M_global: 0.0395985\n",
      "step: 2000  d-loss: 0.0287475  g-loss: 0.0 k_t: -0.00147514 M_global: 0.0431212\n",
      "step: 3000  d-loss: 0.0281996  g-loss: 0.0297466 k_t: 0.000601366 M_global: 0.0438554\n",
      "step: 4000  d-loss: 0.0269658  g-loss: 0.0271674 k_t: -0.001614 M_global: 0.0406284\n",
      "step: 5000  d-loss: 0.027706  g-loss: 0.0389232 k_t: -7.57431e-06 M_global: 0.052776\n",
      "step: 6000  d-loss: 0.0285723  g-loss: 0.031883 k_t: 0.00182798 M_global: 0.0461983\n",
      "step: 7000  d-loss: 0.0284994  g-loss: 0.041886 k_t: 0.000421054 M_global: 0.0561445\n",
      "step: 8000  d-loss: 0.0275893  g-loss: 0.000112811 k_t: 0.00226066 M_global: 0.0412716\n",
      "step: 9000  d-loss: 0.0272828  g-loss: 5.38603e-05 k_t: 0.00107521 M_global: 0.0408705\n",
      "step: 10000  d-loss: 0.0273722  g-loss: 0.00750861 k_t: 0.00199594 M_global: 0.0335722\n",
      "step: 11000  d-loss: 0.0283885  g-loss: 0.0408211 k_t: 0.000131002 M_global: 0.055018\n",
      "step: 12000  d-loss: 0.0280382  g-loss: 0.0 k_t: -0.000310011 M_global: 0.0420574\n",
      "step: 13000  d-loss: 0.0271422  g-loss: 0.0 k_t: 0.00189195 M_global: 0.0407134\n",
      "step: 14000  d-loss: 0.0289036  g-loss: 0.0270174 k_t: -0.0010577 M_global: 0.0414549\n",
      "step: 15000  d-loss: 0.028074  g-loss: 0.0 k_t: 0.00175336 M_global: 0.042111\n",
      "step: 16000  d-loss: 0.0284468  g-loss: 0.0 k_t: 0.000911632 M_global: 0.0426702\n",
      "step: 17000  d-loss: 0.0291293  g-loss: 0.0 k_t: -0.00105946 M_global: 0.043694\n",
      "step: 18000  d-loss: 0.0291973  g-loss: 0.0 k_t: -5.44807e-05 M_global: 0.043796\n",
      "step: 19000  d-loss: 0.0271448  g-loss: 8.25644e-05 k_t: 0.000275446 M_global: 0.0406346\n",
      "step: 20000  d-loss: 0.0260307  g-loss: 0.0246578 k_t: 0.00218832 M_global: 0.0377001\n",
      "step: 21000  d-loss: 0.0271186  g-loss: 0.0396859 k_t: 0.000274155 M_global: 0.0532507\n",
      "step: 22000  d-loss: 0.0275634  g-loss: 0.0 k_t: -0.000426011 M_global: 0.0413452\n",
      "step: 23000  d-loss: 0.0281452  g-loss: 0.0 k_t: 0.00021008 M_global: 0.0422179\n",
      "step: 24000  d-loss: 0.0273295  g-loss: 0.000308362 k_t: 0.000386132 M_global: 0.0406861\n",
      "step: 25000  d-loss: 0.0283735  g-loss: 0.00149457 k_t: -0.00123138 M_global: 0.0410629\n",
      "step: 26000  d-loss: 0.0263371  g-loss: 0.0 k_t: -0.00138186 M_global: 0.0395057\n",
      "step: 27000  d-loss: 0.0267464  g-loss: 0.0403797 k_t: 0.00193345 M_global: 0.053792\n",
      "step: 28000  d-loss: 0.0274152  g-loss: 0.0 k_t: 0.00291007 M_global: 0.0411229\n",
      "step: 29000  d-loss: 0.0272441  g-loss: 0.0 k_t: 0.00152602 M_global: 0.0408661\n",
      "step: 30000  d-loss: 0.0268536  g-loss: 0.0 k_t: 0.00179014 M_global: 0.0402804\n",
      "step: 31000  d-loss: 0.0284979  g-loss: 0.022612 k_t: -0.00136843 M_global: 0.0368454\n",
      "step: 32000  d-loss: 0.0270157  g-loss: 0.0410221 k_t: 0.00221251 M_global: 0.0545754\n",
      "step: 33000  d-loss: 0.0270995  g-loss: 0.0399245 k_t: 0.00143008 M_global: 0.0535027\n",
      "step: 34000  d-loss: 0.0279985  g-loss: 0.0128918 k_t: 0.00257831 M_global: 0.0291559\n",
      "step: 35000  d-loss: 0.0266586  g-loss: 0.0103235 k_t: -0.00200322 M_global: 0.0296334\n",
      "step: 36000  d-loss: 0.0282618  g-loss: 0.0 k_t: -0.000309247 M_global: 0.0423927\n",
      "step: 37000  d-loss: 0.0270542  g-loss: 0.0326801 k_t: -0.000785479 M_global: 0.0461944\n",
      "step: 38000  d-loss: 0.0267273  g-loss: 0.0409523 k_t: 0.00202232 M_global: 0.0543573\n",
      "step: 39000  d-loss: 0.0272877  g-loss: 0.0279664 k_t: 0.00238551 M_global: 0.0416436\n",
      "step: 40000  d-loss: 0.0267341  g-loss: 0.039185 k_t: 0.0002582 M_global: 0.0525571\n",
      "step: 41000  d-loss: 0.0269303  g-loss: 0.0 k_t: -0.000832244 M_global: 0.0403954\n",
      "step: 42000  d-loss: 0.027209  g-loss: 0.0 k_t: 0.00098168 M_global: 0.0408135\n",
      "step: 43000  d-loss: 0.027384  g-loss: 0.0382268 k_t: 8.05452e-06 M_global: 0.051919\n",
      "step: 44000  d-loss: 0.0275388  g-loss: 0.0213563 k_t: -0.00168473 M_global: 0.0351077\n",
      "step: 45000  d-loss: 0.0279664  g-loss: 0.036922 k_t: -0.000111816 M_global: 0.0509031\n",
      "step: 46000  d-loss: 0.0279576  g-loss: 0.0 k_t: -0.00012171 M_global: 0.0419364\n",
      "step: 47000  d-loss: 0.0271879  g-loss: 0.0334359 k_t: -0.00136455 M_global: 0.0470071\n",
      "step: 48000  d-loss: 0.0265631  g-loss: 0.0 k_t: 0.0036038 M_global: 0.0398446\n",
      "step: 49000  d-loss: 0.0281885  g-loss: 0.0 k_t: -0.00077973 M_global: 0.0422828\n",
      "step: 50000  d-loss: 0.026526  g-loss: 0.036134 k_t: -0.000610585 M_global: 0.049386\n",
      "step: 51000  d-loss: 0.0274841  g-loss: 0.0377054 k_t: 0.00239361 M_global: 0.0514925\n",
      "step: 52000  d-loss: 0.0283618  g-loss: 0.0 k_t: -9.80096e-05 M_global: 0.0425427\n",
      "step: 53000  d-loss: 0.0268945  g-loss: 0.0 k_t: 0.000762613 M_global: 0.0403417\n",
      "step: 54000  d-loss: 0.0280835  g-loss: 0.038033 k_t: -1.50872e-05 M_global: 0.0520744\n",
      "step: 55000  d-loss: 0.0281563  g-loss: 0.0 k_t: 0.000538267 M_global: 0.0422345\n",
      "step: 56000  d-loss: 0.0270839  g-loss: 0.0 k_t: -0.00178492 M_global: 0.0406258\n",
      "step: 57000  d-loss: 0.0273024  g-loss: 0.0279369 k_t: -0.000712224 M_global: 0.0415781\n",
      "step: 58000  d-loss: 0.0270954  g-loss: 0.0392551 k_t: 0.00114156 M_global: 0.0528252\n",
      "step: 59000  d-loss: 0.0276253  g-loss: 0.0 k_t: 0.000934441 M_global: 0.041438\n",
      "step: 60000  d-loss: 0.0269552  g-loss: 0.0414866 k_t: 0.00514457 M_global: 0.0550709\n",
      "step: 61000  d-loss: 0.0279559  g-loss: 0.0270835 k_t: 0.000559118 M_global: 0.0410691\n",
      "step: 62000  d-loss: 0.0253924  g-loss: 0.0383058 k_t: 0.000714286 M_global: 0.0510157\n",
      "step: 63000  d-loss: 0.0273064  g-loss: 0.0 k_t: 0.00158329 M_global: 0.0409596\n",
      "step: 64000  d-loss: 0.0274698  g-loss: 0.0 k_t: -0.00100742 M_global: 0.0412047\n",
      "step: 65000  d-loss: 0.0273803  g-loss: 0.029292 k_t: 0.00145583 M_global: 0.0430035\n",
      "step: 66000  d-loss: 0.0274345  g-loss: 0.0 k_t: 0.00130092 M_global: 0.0411517\n",
      "step: 67000  d-loss: 0.0269311  g-loss: 0.0 k_t: -0.00136739 M_global: 0.0403967\n",
      "step: 68000  d-loss: 0.0265125  g-loss: 0.0 k_t: -0.00130786 M_global: 0.0397687\n",
      "step: 69000  d-loss: 0.0265544  g-loss: 0.0 k_t: 0.000473983 M_global: 0.0398315\n",
      "step: 70000  d-loss: 0.0262528  g-loss: 0.0 k_t: 0.00542785 M_global: 0.0393792\n",
      "step: 71000  d-loss: 0.0274931  g-loss: 0.0 k_t: 0.000156919 M_global: 0.0412396\n",
      "step: 72000  d-loss: 0.0273132  g-loss: 0.0 k_t: -0.0018949 M_global: 0.0409698\n",
      "step: 73000  d-loss: 0.0280293  g-loss: 0.0 k_t: 0.0115576 M_global: 0.042044\n",
      "step: 74000  d-loss: 0.0265217  g-loss: 0.0244264 k_t: -0.000847114 M_global: 0.0376769\n",
      "step: 75000  d-loss: 0.0264683  g-loss: 0.029822 k_t: 0.000433305 M_global: 0.0430626\n",
      "step: 76000  d-loss: 0.0261686  g-loss: 0.0 k_t: 0.00288279 M_global: 0.0392529\n",
      "step: 77000  d-loss: 0.0281209  g-loss: 0.0299378 k_t: -0.00158917 M_global: 0.0439745\n",
      "step: 78000  d-loss: 0.0270544  g-loss: 0.0370898 k_t: -0.000250259 M_global: 0.0506123\n",
      "step: 79000  d-loss: 0.0266381  g-loss: 0.0 k_t: -0.00053114 M_global: 0.0399572\n",
      "step: 80000  d-loss: 0.026318  g-loss: 0.0378647 k_t: 0.000178529 M_global: 0.0510271\n",
      "step: 81000  d-loss: 0.0264189  g-loss: 0.021652 k_t: -0.00246494 M_global: 0.0348347\n",
      "step: 82000  d-loss: 0.0282285  g-loss: 0.0 k_t: 1.38748e-05 M_global: 0.0423427\n",
      "step: 83000  d-loss: 0.027054  g-loss: 0.0385213 k_t: 0.00236105 M_global: 0.0520938\n",
      "step: 84000  d-loss: 0.0271018  g-loss: 0.0 k_t: 0.00173558 M_global: 0.0406527\n",
      "step: 85000  d-loss: 0.0273959  g-loss: 0.0268211 k_t: -0.00162605 M_global: 0.0404972\n",
      "step: 86000  d-loss: 0.0261934  g-loss: 0.0393537 k_t: 0.00218101 M_global: 0.0524933\n",
      "step: 87000  d-loss: 0.0268689  g-loss: 0.010718 k_t: -0.00207554 M_global: 0.0295521\n",
      "step: 88000  d-loss: 0.0267276  g-loss: 0.0 k_t: 0.00355596 M_global: 0.0400913\n",
      "step: 89000  d-loss: 0.0268188  g-loss: 0.0 k_t: -0.000768361 M_global: 0.0402282\n",
      "step: 90000  d-loss: 0.0261807  g-loss: 0.0276666 k_t: 0.00456329 M_global: 0.04082\n",
      "step: 91000  d-loss: 0.0277443  g-loss: 0.0 k_t: -0.000196144 M_global: 0.0416164\n",
      "step: 92000  d-loss: 0.0279918  g-loss: 0.0346557 k_t: 0.00172189 M_global: 0.0486814\n",
      "step: 93000  d-loss: 0.0276733  g-loss: 0.0 k_t: 0.00114563 M_global: 0.0415099\n",
      "step: 94000  d-loss: 0.0261441  g-loss: 0.0263963 k_t: -0.00241466 M_global: 0.0394365\n",
      "step: 95000  d-loss: 0.0262781  g-loss: 0.0 k_t: 0.000229154 M_global: 0.0394171\n",
      "step: 96000  d-loss: 0.0270613  g-loss: 0.0150657 k_t: -0.00209894 M_global: 0.0285805\n",
      "step: 97000  d-loss: 0.0264904  g-loss: 0.0 k_t: 8.50794e-05 M_global: 0.0397357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 98000  d-loss: 0.0264299  g-loss: 0.0 k_t: -0.0013582 M_global: 0.0396449\n",
      "step: 99000  d-loss: 0.026554  g-loss: 0.0 k_t: 0.000287094 M_global: 0.0398309\n",
      "step: 100000  d-loss: 0.0270775  g-loss: 0.0376752 k_t: -0.000146524 M_global: 0.0512111\n"
     ]
    }
   ],
   "source": [
    "for step in range(100001):\n",
    "    batch_x = mnist.train.next_batch(batch_size)[0]\n",
    "    z_D = sample_Z(batch_size, g_dim)\n",
    "    sess.run([d_optimizer, g_optimizer], feed_dict={x_d: batch_x, x_g: z_D})\n",
    "    z_G = sample_Z(batch_size, g_dim)\n",
    "    sess.run(g_optimizer, feed_dict={x_g: z_G})\n",
    "#     k_t = np.maximum(np.minimum(1., k_t + 0.001*(sess.run(balancer, feed_dict={x_d: batch_x, x_g: z_G}))), 0.)\n",
    "    sess.run(update_k, feed_dict={x_d: batch_x, x_g: z_G})\n",
    "    if step%1000==0:\n",
    "        d_loss_train, g_loss_train, k_tt, M_global_train = sess.run([d_loss, g_loss, k_t, M_global], feed_dict=\n",
    "                            {x_d: batch_x, x_g: sample_Z(batch_size, g_dim)})\n",
    "#         print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_t,\"M_global:\", M_global_train\n",
    "        print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_tt,\"M_global:\", M_global_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAD8CAYAAADOg5fGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1b5abc0b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gg = sess.run(g_sample, feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(g_sample), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(decoder(x_g), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(x_d), feed_dict = {x_d: x_train})\n",
    "gg_pic = np.array([np.reshape(m,(28,28)) for m in gg])\n",
    "fig, ax = plt.subplots(nrows=3, ncols=3)\n",
    "for i,row in enumerate(ax):\n",
    "    for j,col in enumerate(row):\n",
    "        ax[i][j].imshow(gg_pic[i*3+j], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0  d-loss: 0.0258801  g-loss: 0.0374464 k_t: -0.000171034 M_global: 0.0503832\n",
      "step: 1000  d-loss: 0.0282302  g-loss: 0.0352172 k_t: -0.000562854 M_global: 0.0493224\n",
      "step: 2000  d-loss: 0.0277262  g-loss: 0.0020884 k_t: -0.00203683 M_global: 0.0394945\n",
      "step: 3000  d-loss: 0.0270318  g-loss: 0.0 k_t: 9.04852e-05 M_global: 0.0405476\n",
      "step: 4000  d-loss: 0.0269525  g-loss: 0.0380462 k_t: 0.00336595 M_global: 0.0515864\n",
      "step: 5000  d-loss: 0.0264395  g-loss: 0.00576342 k_t: -0.00211548 M_global: 0.0338775\n",
      "step: 6000  d-loss: 0.026651  g-loss: 0.0380733 k_t: 0.00235965 M_global: 0.0514437\n",
      "step: 7000  d-loss: 0.0255438  g-loss: 0.0 k_t: -0.00163333 M_global: 0.0383157\n",
      "step: 8000  d-loss: 0.0267887  g-loss: 0.0354036 k_t: -0.000486698 M_global: 0.0487894\n",
      "step: 9000  d-loss: 0.0273751  g-loss: 0.0 k_t: -2.15252e-07 M_global: 0.0410627\n",
      "step: 10000  d-loss: 0.0271008  g-loss: 0.0358643 k_t: -8.67419e-05 M_global: 0.0494131\n",
      "step: 11000  d-loss: 0.0269081  g-loss: 0.0 k_t: -0.000195642 M_global: 0.0403622\n",
      "step: 12000  d-loss: 0.0267891  g-loss: 0.0 k_t: 0.00163448 M_global: 0.0401837\n",
      "step: 13000  d-loss: 0.0261917  g-loss: 0.0 k_t: -0.00174561 M_global: 0.0392875\n",
      "step: 14000  d-loss: 0.027547  g-loss: 0.0 k_t: 0.000854264 M_global: 0.0413206\n",
      "step: 15000  d-loss: 0.0262152  g-loss: 0.0380811 k_t: 0.0043555 M_global: 0.0512717\n",
      "step: 16000  d-loss: 0.0273  g-loss: 0.0 k_t: 0.000417157 M_global: 0.04095\n",
      "step: 17000  d-loss: 0.0262332  g-loss: 0.023076 k_t: -0.00196647 M_global: 0.0361699\n",
      "step: 18000  d-loss: 0.0270925  g-loss: 0.0 k_t: 0.0106393 M_global: 0.0406388\n",
      "step: 19000  d-loss: 0.0277289  g-loss: 0.0154443 k_t: 0.000785007 M_global: 0.0293148\n",
      "step: 20000  d-loss: 0.0262228  g-loss: 0.0223989 k_t: 0.000885446 M_global: 0.0355202\n",
      "step: 21000  d-loss: 0.0278816  g-loss: 0.0355645 k_t: 0.000334146 M_global: 0.0495112\n",
      "step: 22000  d-loss: 0.0265791  g-loss: 0.0280198 k_t: -0.00196718 M_global: 0.0412818\n",
      "step: 23000  d-loss: 0.0268963  g-loss: 0.0 k_t: -0.000913149 M_global: 0.0403445\n",
      "step: 24000  d-loss: 0.0250476  g-loss: 0.0 k_t: 0.00268858 M_global: 0.0375714\n",
      "step: 25000  d-loss: 0.0256456  g-loss: 0.0361049 k_t: 0.000725455 M_global: 0.0489408\n",
      "step: 26000  d-loss: 0.0265964  g-loss: 0.0 k_t: 9.70725e-05 M_global: 0.0398946\n",
      "step: 27000  d-loss: 0.0263592  g-loss: 0.0382119 k_t: 0.00537435 M_global: 0.0514943\n",
      "step: 28000  d-loss: 0.0268536  g-loss: 0.0 k_t: 0.000432661 M_global: 0.0402804\n",
      "step: 29000  d-loss: 0.0261575  g-loss: 0.025311 k_t: -0.00178494 M_global: 0.0383671\n",
      "step: 30000  d-loss: 0.026898  g-loss: 0.0264894 k_t: 0.000894137 M_global: 0.0399503\n",
      "step: 31000  d-loss: 0.0258033  g-loss: 0.00103965 k_t: -0.00244765 M_global: 0.0376614\n",
      "step: 32000  d-loss: 0.0257084  g-loss: 0.0 k_t: 0.00225394 M_global: 0.0385626\n",
      "step: 33000  d-loss: 0.0261615  g-loss: 0.0363555 k_t: 0.00246996 M_global: 0.0494812\n",
      "step: 34000  d-loss: 0.0252875  g-loss: 0.0 k_t: 0.000985903 M_global: 0.0379312\n",
      "step: 35000  d-loss: 0.025836  g-loss: 0.0 k_t: 0.00472186 M_global: 0.038754\n",
      "step: 36000  d-loss: 0.0259601  g-loss: 0.000370149 k_t: 0.000584758 M_global: 0.0385703\n",
      "step: 37000  d-loss: 0.0264783  g-loss: 0.0017407 k_t: 0.00345535 M_global: 0.0379858\n",
      "step: 38000  d-loss: 0.0261683  g-loss: 0.0 k_t: 0.0068174 M_global: 0.0392525\n",
      "step: 39000  d-loss: 0.0267238  g-loss: 0.0161665 k_t: -0.000702063 M_global: 0.0295227\n",
      "step: 40000  d-loss: 0.0271385  g-loss: 0.0244009 k_t: 0.00123057 M_global: 0.0379851\n",
      "step: 41000  d-loss: 0.0253257  g-loss: 0.0180244 k_t: -0.00217754 M_global: 0.0306677\n",
      "step: 42000  d-loss: 0.0260752  g-loss: 0.0354699 k_t: 0.000806855 M_global: 0.0485218\n",
      "step: 43000  d-loss: 0.0270046  g-loss: 0.0 k_t: 0.00180692 M_global: 0.0405069\n",
      "step: 44000  d-loss: 0.0256915  g-loss: 0.0 k_t: -0.000567056 M_global: 0.0385372\n",
      "step: 45000  d-loss: 0.0262256  g-loss: 0.0 k_t: 0.00624048 M_global: 0.0393384\n",
      "step: 46000  d-loss: 0.0252527  g-loss: 0.00103798 k_t: 0.000516783 M_global: 0.0368419\n",
      "step: 47000  d-loss: 0.0273101  g-loss: 0.0 k_t: -0.00108491 M_global: 0.0409651\n",
      "step: 48000  d-loss: 0.0256195  g-loss: 0.0343533 k_t: -0.000325241 M_global: 0.0471575\n",
      "step: 49000  d-loss: 0.0268764  g-loss: 0.0216361 k_t: -0.00208069 M_global: 0.0350518\n",
      "step: 50000  d-loss: 0.0253713  g-loss: 0.0309844 k_t: -0.000687906 M_global: 0.0436594\n",
      "step: 51000  d-loss: 0.0268674  g-loss: 0.0 k_t: 0.00113341 M_global: 0.0403011\n",
      "step: 52000  d-loss: 0.0241013  g-loss: 0.0168088 k_t: -0.00126265 M_global: 0.0288488\n",
      "step: 53000  d-loss: 0.0254053  g-loss: 0.00160846 k_t: 0.000917471 M_global: 0.0365017\n",
      "step: 54000  d-loss: 0.026072  g-loss: 0.0225487 k_t: -0.00128261 M_global: 0.0355703\n",
      "step: 55000  d-loss: 0.0267449  g-loss: 0.0 k_t: 0.0108737 M_global: 0.0401173\n",
      "step: 56000  d-loss: 0.0243744  g-loss: 0.0377354 k_t: 0.00385352 M_global: 0.0499953\n",
      "step: 57000  d-loss: 0.0246597  g-loss: 0.0230181 k_t: 0.000460476 M_global: 0.0353533\n",
      "step: 58000  d-loss: 0.026838  g-loss: 0.0180263 k_t: 0.000952484 M_global: 0.0314538\n",
      "step: 59000  d-loss: 0.0261492  g-loss: 0.0 k_t: 0.00329788 M_global: 0.0392238\n",
      "step: 60000  d-loss: 0.0260734  g-loss: 0.0 k_t: 0.000780836 M_global: 0.0391102\n",
      "step: 61000  d-loss: 0.0257403  g-loss: 0.0 k_t: 0.00192728 M_global: 0.0386105\n",
      "step: 62000  d-loss: 0.0258044  g-loss: 0.0322809 k_t: 0.000609452 M_global: 0.0451929\n",
      "step: 63000  d-loss: 0.0252753  g-loss: 0.0 k_t: 0.00306515 M_global: 0.0379129\n",
      "step: 64000  d-loss: 0.0267637  g-loss: 0.0345864 k_t: -0.00024834 M_global: 0.047964\n",
      "step: 65000  d-loss: 0.0255538  g-loss: 0.0 k_t: -0.000666826 M_global: 0.0383307\n",
      "step: 66000  d-loss: 0.0267723  g-loss: 0.0 k_t: -8.27841e-05 M_global: 0.0401584\n",
      "step: 67000  d-loss: 0.0248317  g-loss: 0.0210697 k_t: 0.00299617 M_global: 0.0335171\n",
      "step: 68000  d-loss: 0.0267343  g-loss: 0.0 k_t: -0.000900814 M_global: 0.0401015\n",
      "step: 69000  d-loss: 0.0262922  g-loss: 0.0 k_t: 0.00229253 M_global: 0.0394383\n",
      "step: 70000  d-loss: 0.0254229  g-loss: 0.0298136 k_t: -0.00124109 M_global: 0.0425065\n",
      "step: 71000  d-loss: 0.0261244  g-loss: 0.0351448 k_t: 0.00182763 M_global: 0.0482391\n",
      "step: 72000  d-loss: 0.0252494  g-loss: 0.0 k_t: 0.000138732 M_global: 0.0378741\n",
      "step: 73000  d-loss: 0.0272349  g-loss: 0.0 k_t: 0.00552825 M_global: 0.0408524\n",
      "step: 74000  d-loss: 0.025921  g-loss: 0.000180141 k_t: 0.000479419 M_global: 0.0387014\n",
      "step: 75000  d-loss: 0.0252977  g-loss: 0.0 k_t: -0.000876033 M_global: 0.0379465\n",
      "step: 76000  d-loss: 0.0258622  g-loss: 0.00322911 k_t: 0.000782698 M_global: 0.035568\n",
      "step: 77000  d-loss: 0.0246204  g-loss: 0.0 k_t: 0.00321476 M_global: 0.0369305\n",
      "step: 78000  d-loss: 0.0260034  g-loss: 0.0231582 k_t: 0.000250449 M_global: 0.0361628\n",
      "step: 79000  d-loss: 0.0257234  g-loss: 0.0 k_t: -5.41264e-05 M_global: 0.0385851\n",
      "step: 80000  d-loss: 0.0251991  g-loss: 0.0352452 k_t: -0.000337994 M_global: 0.0478388\n",
      "step: 81000  d-loss: 0.0249331  g-loss: 0.00947903 k_t: -0.000907256 M_global: 0.0279078\n",
      "step: 82000  d-loss: 0.0261091  g-loss: 0.0 k_t: -0.000290825 M_global: 0.0391636\n",
      "step: 83000  d-loss: 0.0257977  g-loss: 0.0 k_t: 0.00196464 M_global: 0.0386966\n",
      "step: 84000  d-loss: 0.0256043  g-loss: 0.0 k_t: -0.000120489 M_global: 0.0384065\n",
      "step: 85000  d-loss: 0.0258155  g-loss: 0.0258569 k_t: 0.000854261 M_global: 0.0387757\n",
      "step: 86000  d-loss: 0.0261132  g-loss: 0.0 k_t: -0.000115649 M_global: 0.0391698\n",
      "step: 87000  d-loss: 0.0241899  g-loss: 0.0353028 k_t: 0.0026705 M_global: 0.0474449\n",
      "step: 88000  d-loss: 0.0253201  g-loss: 0.0 k_t: -0.000424004 M_global: 0.0379802\n",
      "step: 89000  d-loss: 0.0245675  g-loss: 0.0349663 k_t: 0.00190206 M_global: 0.0472834\n",
      "step: 90000  d-loss: 0.0259767  g-loss: 0.0 k_t: 0.00124318 M_global: 0.0389651\n",
      "step: 91000  d-loss: 0.0261452  g-loss: 0.0 k_t: 0.00464867 M_global: 0.0392177\n",
      "step: 92000  d-loss: 0.0268407  g-loss: 0.0 k_t: -0.000242075 M_global: 0.0402611\n",
      "step: 93000  d-loss: 0.025897  g-loss: 0.0156869 k_t: -0.00105966 M_global: 0.0286271\n",
      "step: 94000  d-loss: 0.0241444  g-loss: 0.0 k_t: -0.00159652 M_global: 0.0362166\n",
      "step: 95000  d-loss: 0.0256898  g-loss: 0.0 k_t: -0.000490773 M_global: 0.0385346\n",
      "step: 96000  d-loss: 0.0250853  g-loss: 0.0 k_t: 0.00112759 M_global: 0.037628\n",
      "step: 97000  d-loss: 0.0267574  g-loss: 0.0302623 k_t: 0.000738496 M_global: 0.0436522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 98000  d-loss: 0.0252193  g-loss: 0.0 k_t: 0.00170456 M_global: 0.037829\n",
      "step: 99000  d-loss: 0.0258061  g-loss: 0.0 k_t: 0.00664153 M_global: 0.0387092\n",
      "step: 100000  d-loss: 0.0251709  g-loss: 0.0147255 k_t: -0.000816379 M_global: 0.0273049\n",
      "step: 101000  d-loss: 0.0257428  g-loss: 0.0 k_t: 0.000464094 M_global: 0.0386142\n",
      "step: 102000  d-loss: 0.0262567  g-loss: 0.0340682 k_t: -0.00121097 M_global: 0.0471759\n",
      "step: 103000  d-loss: 0.0252156  g-loss: 0.0 k_t: 0.000174358 M_global: 0.0378234\n",
      "step: 104000  d-loss: 0.0258181  g-loss: 0.0 k_t: 0.00201069 M_global: 0.0387272\n",
      "step: 105000  d-loss: 0.0250906  g-loss: 0.019579 k_t: -0.00173984 M_global: 0.0321073\n",
      "step: 106000  d-loss: 0.0249663  g-loss: 0.0 k_t: 0.00294439 M_global: 0.0374494\n",
      "step: 107000  d-loss: 0.0253533  g-loss: 0.0 k_t: -0.000267042 M_global: 0.0380299\n",
      "step: 108000  d-loss: 0.0248422  g-loss: 0.00165639 k_t: 0.000812038 M_global: 0.0356089\n",
      "step: 109000  d-loss: 0.0253029  g-loss: 0.0 k_t: 0.00298766 M_global: 0.0379544\n",
      "step: 110000  d-loss: 0.0261329  g-loss: 0.0255439 k_t: -0.0019332 M_global: 0.0385857\n",
      "step: 111000  d-loss: 0.0257211  g-loss: 0.0338335 k_t: 0.00165763 M_global: 0.0467221\n",
      "step: 112000  d-loss: 0.025834  g-loss: 0.0353509 k_t: 0.00104906 M_global: 0.0482864\n",
      "step: 113000  d-loss: 0.0256334  g-loss: 0.0339675 k_t: 0.000363743 M_global: 0.0467904\n",
      "step: 114000  d-loss: 0.0242332  g-loss: 0.0362506 k_t: 0.00156957 M_global: 0.0483957\n",
      "step: 115000  d-loss: 0.0249532  g-loss: 0.0296245 k_t: 0.000138462 M_global: 0.0421031\n",
      "step: 116000  d-loss: 0.0254072  g-loss: 0.0 k_t: 0.00310288 M_global: 0.0381109\n",
      "step: 117000  d-loss: 0.0253411  g-loss: 0.00316173 k_t: -0.000579477 M_global: 0.0348472\n",
      "step: 118000  d-loss: 0.0245177  g-loss: 0.0 k_t: 0.00222197 M_global: 0.0367765\n",
      "step: 119000  d-loss: 0.0265371  g-loss: 0.0 k_t: -0.0016956 M_global: 0.0398056\n",
      "step: 120000  d-loss: 0.0249191  g-loss: 1.18419e-06 k_t: 0.000401156 M_global: 0.0373775\n",
      "step: 121000  d-loss: 0.0251226  g-loss: 0.0 k_t: 0.00119709 M_global: 0.0376839\n",
      "step: 122000  d-loss: 0.0249189  g-loss: 0.0289824 k_t: -0.000258357 M_global: 0.0414381\n",
      "step: 123000  d-loss: 0.0247755  g-loss: 0.0 k_t: 0.00309518 M_global: 0.0371632\n",
      "step: 124000  d-loss: 0.0252535  g-loss: 0.0 k_t: -6.38936e-06 M_global: 0.0378803\n",
      "step: 125000  d-loss: 0.0259345  g-loss: 0.0 k_t: 0.00220447 M_global: 0.0389018\n",
      "step: 126000  d-loss: 0.0252692  g-loss: 0.0167505 k_t: -0.000862387 M_global: 0.0293779\n",
      "step: 127000  d-loss: 0.0257021  g-loss: 0.0 k_t: -0.000552098 M_global: 0.0385532\n",
      "step: 128000  d-loss: 0.0252719  g-loss: 0.000191909 k_t: 0.00264574 M_global: 0.0377167\n",
      "step: 129000  d-loss: 0.0253029  g-loss: 0.00256882 k_t: 0.00191442 M_global: 0.035393\n",
      "step: 130000  d-loss: 0.0263747  g-loss: 0.0363171 k_t: 0.00611439 M_global: 0.0496155\n",
      "step: 131000  d-loss: 0.0261936  g-loss: 0.0122022 k_t: 0.000707015 M_global: 0.0271012\n",
      "step: 132000  d-loss: 0.0254987  g-loss: 0.0 k_t: -0.00148296 M_global: 0.0382481\n",
      "step: 133000  d-loss: 0.0252102  g-loss: 0.0355408 k_t: 0.000542314 M_global: 0.0481556\n",
      "step: 134000  d-loss: 0.0259014  g-loss: 0.0 k_t: -0.000352067 M_global: 0.0388521\n",
      "step: 135000  d-loss: 0.0259956  g-loss: 0.0 k_t: -0.000548647 M_global: 0.0389934\n",
      "step: 136000  d-loss: 0.0255036  g-loss: 0.0325262 k_t: -0.000863711 M_global: 0.0452639\n",
      "step: 137000  d-loss: 0.0242278  g-loss: 0.0 k_t: 0.00150247 M_global: 0.0363416\n",
      "step: 138000  d-loss: 0.026362  g-loss: 8.667e-06 k_t: 0.000214113 M_global: 0.0395344\n",
      "step: 139000  d-loss: 0.0249825  g-loss: 0.0159744 k_t: -0.0013984 M_global: 0.0284545\n",
      "step: 140000  d-loss: 0.0257949  g-loss: 0.0329889 k_t: 0.000813326 M_global: 0.0458998\n",
      "step: 141000  d-loss: 0.0262254  g-loss: 0.0327209 k_t: -0.00116696 M_global: 0.0458145\n",
      "step: 142000  d-loss: 0.0250536  g-loss: 0.0 k_t: 0.000446787 M_global: 0.0375804\n",
      "step: 143000  d-loss: 0.0256471  g-loss: 0.0 k_t: -0.00103377 M_global: 0.0384707\n",
      "step: 144000  d-loss: 0.025453  g-loss: 0.0 k_t: 0.0055393 M_global: 0.0381795\n",
      "step: 145000  d-loss: 0.025726  g-loss: 8.4327e-05 k_t: -0.00134556 M_global: 0.0385045\n",
      "step: 146000  d-loss: 0.0250058  g-loss: 0.0181085 k_t: -0.000945444 M_global: 0.0306028\n",
      "step: 147000  d-loss: 0.0260463  g-loss: 0.0 k_t: 0.00171994 M_global: 0.0390694\n",
      "step: 148000  d-loss: 0.0261593  g-loss: 0.0 k_t: 0.00730396 M_global: 0.0392389\n",
      "step: 149000  d-loss: 0.0252937  g-loss: 0.0131273 k_t: 0.000643672 M_global: 0.0257784\n",
      "step: 150000  d-loss: 0.0248985  g-loss: 0.0 k_t: 0.000594092 M_global: 0.0373477\n",
      "step: 151000  d-loss: 0.0252398  g-loss: 0.0 k_t: 0.000202001 M_global: 0.0378597\n",
      "step: 152000  d-loss: 0.0254284  g-loss: 0.0199778 k_t: -0.00108985 M_global: 0.0326812\n",
      "step: 153000  d-loss: 0.0252665  g-loss: 0.0297473 k_t: 0.00312849 M_global: 0.0424271\n",
      "step: 154000  d-loss: 0.0248453  g-loss: 0.0 k_t: -0.000634862 M_global: 0.037268\n",
      "step: 155000  d-loss: 0.0266095  g-loss: 0.00290128 k_t: 0.000881518 M_global: 0.0370168\n",
      "step: 156000  d-loss: 0.0247022  g-loss: 0.0 k_t: 0.00120552 M_global: 0.0370533\n",
      "step: 157000  d-loss: 0.0251486  g-loss: 0.0 k_t: -0.00165047 M_global: 0.037723\n",
      "step: 158000  d-loss: 0.0254601  g-loss: 0.0354603 k_t: 0.00113394 M_global: 0.0482104\n",
      "step: 159000  d-loss: 0.0253868  g-loss: 0.0 k_t: -0.000405056 M_global: 0.0380803\n",
      "step: 160000  d-loss: 0.0249607  g-loss: 0.0361963 k_t: 0.00376797 M_global: 0.0487449\n",
      "step: 161000  d-loss: 0.0259352  g-loss: 0.0251202 k_t: -0.000356075 M_global: 0.0380834\n",
      "step: 162000  d-loss: 0.025194  g-loss: 0.0 k_t: 0.000108584 M_global: 0.0377909\n",
      "step: 163000  d-loss: 0.0240153  g-loss: 0.0329094 k_t: 0.000905572 M_global: 0.044932\n",
      "step: 164000  d-loss: 0.0248509  g-loss: 0.0211163 k_t: 0.00135596 M_global: 0.0335561\n",
      "step: 165000  d-loss: 0.0252175  g-loss: 0.0 k_t: 0.000714039 M_global: 0.0378263\n",
      "step: 166000  d-loss: 0.0245635  g-loss: 0.0 k_t: 0.00186952 M_global: 0.0368453\n",
      "step: 167000  d-loss: 0.0248271  g-loss: 0.0196754 k_t: 0.000442264 M_global: 0.0320933\n",
      "step: 168000  d-loss: 0.0247101  g-loss: 0.0 k_t: -0.000208385 M_global: 0.0370651\n",
      "step: 169000  d-loss: 0.0247728  g-loss: 0.00678846 k_t: 0.00168286 M_global: 0.0303878\n",
      "step: 170000  d-loss: 0.0253158  g-loss: 0.0 k_t: -0.0004567 M_global: 0.0379737\n",
      "step: 171000  d-loss: 0.0244365  g-loss: 0.0 k_t: -0.00011371 M_global: 0.0366547\n",
      "step: 172000  d-loss: 0.0241848  g-loss: 0.0349695 k_t: 5.20493e-05 M_global: 0.0470629\n",
      "step: 173000  d-loss: 0.0201117  g-loss: 0.0 k_t: 0.00200496 M_global: 0.0301676\n",
      "step: 174000  d-loss: 0.0208868  g-loss: 0.0225354 k_t: -0.000220633 M_global: 0.0329763\n",
      "step: 175000  d-loss: 0.0210135  g-loss: 0.0333238 k_t: -0.000165124 M_global: 0.0438278\n",
      "step: 176000  d-loss: 0.0203096  g-loss: 0.0 k_t: 0.00188496 M_global: 0.0304644\n",
      "step: 177000  d-loss: 0.0206345  g-loss: 0.00534376 k_t: -0.00148407 M_global: 0.0255961\n",
      "step: 178000  d-loss: 0.0196661  g-loss: 0.0 k_t: 0.00222238 M_global: 0.0294992\n",
      "step: 179000  d-loss: 0.0205977  g-loss: 0.000144462 k_t: -2.84076e-05 M_global: 0.030752\n",
      "step: 180000  d-loss: 0.0212373  g-loss: 0.0189304 k_t: -0.00105807 M_global: 0.029539\n",
      "step: 181000  d-loss: 0.0205019  g-loss: 0.0 k_t: 0.0010772 M_global: 0.0307528\n",
      "step: 182000  d-loss: 0.0204471  g-loss: 0.0 k_t: 5.58128e-05 M_global: 0.0306707\n",
      "step: 183000  d-loss: 0.020674  g-loss: 0.0 k_t: 0.000963626 M_global: 0.031011\n",
      "step: 184000  d-loss: 0.0201664  g-loss: 0.0198864 k_t: 0.000406167 M_global: 0.0299737\n",
      "step: 185000  d-loss: 0.020148  g-loss: 0.0 k_t: 0.00327848 M_global: 0.0302219\n",
      "step: 186000  d-loss: 0.0206419  g-loss: 0.021197 k_t: -0.000322066 M_global: 0.0315146\n",
      "step: 187000  d-loss: 0.0210694  g-loss: 0.0 k_t: 0.00199441 M_global: 0.031604\n",
      "step: 188000  d-loss: 0.0205137  g-loss: 0.0 k_t: 0.00035424 M_global: 0.0307705\n",
      "step: 189000  d-loss: 0.0204663  g-loss: 0.0 k_t: 0.00118228 M_global: 0.0306994\n",
      "step: 190000  d-loss: 0.0202278  g-loss: 0.0 k_t: 0.00364182 M_global: 0.0303417\n",
      "step: 191000  d-loss: 0.0198791  g-loss: 0.037095 k_t: 0.00236592 M_global: 0.0470784\n",
      "step: 192000  d-loss: 0.0210492  g-loss: 0.0206762 k_t: -0.000217446 M_global: 0.0311985\n",
      "step: 193000  d-loss: 0.0207289  g-loss: 0.0 k_t: -0.000143869 M_global: 0.0310933\n",
      "step: 194000  d-loss: 0.0204525  g-loss: 0.0 k_t: 0.00451145 M_global: 0.0306788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 195000  d-loss: 0.0205662  g-loss: 0.0 k_t: -0.00190451 M_global: 0.0308493\n",
      "step: 196000  d-loss: 0.0215916  g-loss: 0.0241414 k_t: -0.000248342 M_global: 0.0349342\n",
      "step: 197000  d-loss: 0.0207277  g-loss: 0.0 k_t: 0.0011832 M_global: 0.0310916\n",
      "step: 198000  d-loss: 0.0206551  g-loss: 0.0 k_t: 8.5749e-05 M_global: 0.0309826\n",
      "step: 199000  d-loss: 0.0202243  g-loss: 0.0 k_t: 0.000780477 M_global: 0.0303364\n",
      "step: 200000  d-loss: 0.0206251  g-loss: 0.0344209 k_t: 0.00112329 M_global: 0.0447528\n",
      "step: 201000  d-loss: 0.0201983  g-loss: 0.0 k_t: 0.00616908 M_global: 0.0302974\n",
      "step: 202000  d-loss: 0.0211724  g-loss: 0.0 k_t: 0.0164115 M_global: 0.0317585\n",
      "step: 203000  d-loss: 0.0209591  g-loss: 0.0 k_t: 0.0266533 M_global: 0.0314387\n",
      "step: 204000  d-loss: 0.0192891  g-loss: 0.0 k_t: 0.0368801 M_global: 0.0289336\n",
      "step: 205000  d-loss: 0.0189261  g-loss: 0.0586956 k_t: 0.018523 M_global: 0.0687022\n",
      "step: 206000  d-loss: 0.0200296  g-loss: 7.91627e-05 k_t: -8.78608e-05 M_global: 0.0299652\n",
      "step: 207000  d-loss: 0.0191627  g-loss: 0.0128883 k_t: -0.00062631 M_global: 0.0224656\n",
      "step: 208000  d-loss: 0.0198182  g-loss: 0.0255473 k_t: 0.000356647 M_global: 0.035461\n",
      "step: 209000  d-loss: 0.0191756  g-loss: 0.0 k_t: -0.000536581 M_global: 0.0287633\n",
      "step: 210000  d-loss: 0.0202028  g-loss: 0.0 k_t: 0.00126932 M_global: 0.0303042\n",
      "step: 211000  d-loss: 0.0198997  g-loss: 0.0241673 k_t: 0.00190863 M_global: 0.0341402\n",
      "step: 212000  d-loss: 0.0200564  g-loss: 0.0 k_t: -0.000247161 M_global: 0.0300846\n",
      "step: 213000  d-loss: 0.0199063  g-loss: 0.0 k_t: 0.009791 M_global: 0.0298595\n",
      "step: 214000  d-loss: 0.0200469  g-loss: 0.0 k_t: 0.0198278 M_global: 0.0300704\n",
      "step: 215000  d-loss: 0.0196693  g-loss: 0.0 k_t: 0.0298542 M_global: 0.0295039\n",
      "step: 216000  d-loss: 0.0198497  g-loss: 0.0 k_t: 0.039881 M_global: 0.0297746\n",
      "step: 217000  d-loss: 0.0196339  g-loss: 0.0 k_t: 0.0499034 M_global: 0.0294508\n",
      "step: 218000  d-loss: 0.0208852  g-loss: 0.0 k_t: 0.0599213 M_global: 0.0313277\n",
      "step: 219000  d-loss: 0.0197135  g-loss: 0.0 k_t: 0.0699305 M_global: 0.0295703\n",
      "step: 220000  d-loss: 0.0192177  g-loss: 0.0 k_t: 0.0799394 M_global: 0.0288265\n",
      "step: 221000  d-loss: 0.0204713  g-loss: 0.0 k_t: 0.0899482 M_global: 0.0307069\n",
      "step: 222000  d-loss: 0.0203045  g-loss: 0.0 k_t: 0.0999504 M_global: 0.0304568\n",
      "step: 223000  d-loss: 0.0199851  g-loss: 0.0 k_t: 0.109946 M_global: 0.0299777\n",
      "step: 224000  d-loss: 0.0193366  g-loss: 0.0 k_t: 0.119949 M_global: 0.029005\n",
      "step: 225000  d-loss: 0.0205172  g-loss: 0.0 k_t: 0.129945 M_global: 0.0307758\n",
      "step: 226000  d-loss: 0.0195686  g-loss: 0.0 k_t: 0.139935 M_global: 0.0293529\n",
      "step: 227000  d-loss: 0.0201447  g-loss: 0.0 k_t: 0.149925 M_global: 0.030217\n",
      "step: 228000  d-loss: 0.0199768  g-loss: 0.0 k_t: 0.159905 M_global: 0.0299653\n",
      "step: 229000  d-loss: 0.0201003  g-loss: 0.0 k_t: 0.169888 M_global: 0.0301505\n",
      "step: 230000  d-loss: 0.0192201  g-loss: 0.0 k_t: 0.179862 M_global: 0.0288302\n",
      "step: 231000  d-loss: 0.0206124  g-loss: 0.0 k_t: 0.18984 M_global: 0.0309186\n",
      "step: 232000  d-loss: 0.0195785  g-loss: 0.0 k_t: 0.199817 M_global: 0.0293677\n",
      "step: 233000  d-loss: 0.0198741  g-loss: 0.0 k_t: 0.209786 M_global: 0.0298112\n",
      "step: 234000  d-loss: 0.0194526  g-loss: 0.0 k_t: 0.219754 M_global: 0.0291789\n",
      "step: 235000  d-loss: 0.0202557  g-loss: 0.0 k_t: 0.229716 M_global: 0.0303835\n",
      "step: 236000  d-loss: 0.0203265  g-loss: 0.0 k_t: 0.239683 M_global: 0.0304898\n",
      "step: 237000  d-loss: 0.0199239  g-loss: 0.0 k_t: 0.249641 M_global: 0.0298859\n",
      "step: 238000  d-loss: 0.0198781  g-loss: 0.0 k_t: 0.259597 M_global: 0.0298171\n",
      "step: 239000  d-loss: 0.0192759  g-loss: 0.0 k_t: 0.269557 M_global: 0.0289139\n",
      "step: 240000  d-loss: 0.0201546  g-loss: 0.0 k_t: 0.279509 M_global: 0.0302319\n",
      "step: 241000  d-loss: 0.0195436  g-loss: 0.0 k_t: 0.289458 M_global: 0.0293155\n",
      "step: 242000  d-loss: 0.0192236  g-loss: 0.0 k_t: 0.29941 M_global: 0.0288353\n",
      "step: 243000  d-loss: 0.0195625  g-loss: 0.0 k_t: 0.309352 M_global: 0.0293438\n",
      "step: 244000  d-loss: 0.0194164  g-loss: 0.0 k_t: 0.319296 M_global: 0.0291246\n",
      "step: 245000  d-loss: 0.0200621  g-loss: 0.0 k_t: 0.329243 M_global: 0.0300932\n",
      "step: 246000  d-loss: 0.0199988  g-loss: 0.0 k_t: 0.33918 M_global: 0.0299981\n",
      "step: 247000  d-loss: 0.0189218  g-loss: 0.0 k_t: 0.349115 M_global: 0.0283827\n",
      "step: 248000  d-loss: 0.0197898  g-loss: 0.0 k_t: 0.359051 M_global: 0.0296847\n",
      "step: 249000  d-loss: 0.0201819  g-loss: 0.0 k_t: 0.368986 M_global: 0.0302729\n",
      "step: 250000  d-loss: 0.0186634  g-loss: 0.0 k_t: 0.378912 M_global: 0.0279951\n",
      "step: 251000  d-loss: 0.0199965  g-loss: 0.0 k_t: 0.38884 M_global: 0.0299947\n",
      "step: 252000  d-loss: 0.0198431  g-loss: 0.0 k_t: 0.398764 M_global: 0.0297646\n",
      "step: 253000  d-loss: 0.019918  g-loss: 0.0 k_t: 0.408682 M_global: 0.029877\n",
      "step: 254000  d-loss: 0.0195019  g-loss: 0.0 k_t: 0.418594 M_global: 0.0292529\n",
      "step: 255000  d-loss: 0.0202714  g-loss: 0.0 k_t: 0.428507 M_global: 0.030407\n",
      "step: 256000  d-loss: 0.0203826  g-loss: 0.0 k_t: 0.43841 M_global: 0.0305739\n",
      "step: 257000  d-loss: 0.0197195  g-loss: 0.0 k_t: 0.448315 M_global: 0.0295793\n",
      "step: 258000  d-loss: 0.019827  g-loss: 0.0 k_t: 0.458219 M_global: 0.0297405\n",
      "step: 259000  d-loss: 0.0203492  g-loss: 0.0 k_t: 0.46812 M_global: 0.0305238\n",
      "step: 260000  d-loss: 0.0204231  g-loss: 0.0 k_t: 0.478017 M_global: 0.0306346\n",
      "step: 261000  d-loss: 0.019822  g-loss: 0.0 k_t: 0.487911 M_global: 0.0297329\n",
      "step: 262000  d-loss: 0.0201298  g-loss: 0.0 k_t: 0.497806 M_global: 0.0301947\n",
      "step: 263000  d-loss: 0.0194332  g-loss: 0.0 k_t: 0.507697 M_global: 0.0291498\n",
      "step: 264000  d-loss: 0.0199128  g-loss: 0.0 k_t: 0.51759 M_global: 0.0298692\n",
      "step: 265000  d-loss: 0.0201324  g-loss: 0.0 k_t: 0.527477 M_global: 0.0301987\n",
      "step: 266000  d-loss: 0.0193191  g-loss: 0.0 k_t: 0.537358 M_global: 0.0289786\n",
      "step: 267000  d-loss: 0.0194996  g-loss: 0.0 k_t: 0.54724 M_global: 0.0292493\n",
      "step: 268000  d-loss: 0.0197188  g-loss: 0.0 k_t: 0.557126 M_global: 0.0295782\n",
      "step: 269000  d-loss: 0.018955  g-loss: 0.0 k_t: 0.567003 M_global: 0.0284325\n",
      "step: 270000  d-loss: 0.0195467  g-loss: 0.0 k_t: 0.576884 M_global: 0.02932\n",
      "step: 271000  d-loss: 0.0193784  g-loss: 0.0 k_t: 0.586758 M_global: 0.0290676\n",
      "step: 272000  d-loss: 0.0190886  g-loss: 0.0 k_t: 0.596632 M_global: 0.028633\n",
      "step: 273000  d-loss: 0.0201187  g-loss: 0.0 k_t: 0.606506 M_global: 0.030178\n",
      "step: 274000  d-loss: 0.0193779  g-loss: 0.0 k_t: 0.616376 M_global: 0.0290669\n",
      "step: 275000  d-loss: 0.0198793  g-loss: 0.0 k_t: 0.626245 M_global: 0.029819\n",
      "step: 276000  d-loss: 0.0185712  g-loss: 0.0 k_t: 0.63611 M_global: 0.0278568\n",
      "step: 277000  d-loss: 0.0197571  g-loss: 0.0 k_t: 0.645974 M_global: 0.0296356\n",
      "step: 278000  d-loss: 0.0195207  g-loss: 0.0 k_t: 0.655837 M_global: 0.0292811\n",
      "step: 279000  d-loss: 0.0191343  g-loss: 0.0 k_t: 0.6657 M_global: 0.0287015\n",
      "step: 280000  d-loss: 0.0199342  g-loss: 0.0 k_t: 0.675556 M_global: 0.0299013\n",
      "step: 281000  d-loss: 0.0186848  g-loss: 0.0 k_t: 0.685415 M_global: 0.0280271\n",
      "step: 282000  d-loss: 0.0202168  g-loss: 0.0 k_t: 0.695275 M_global: 0.0303253\n",
      "step: 283000  d-loss: 0.0202404  g-loss: 0.0 k_t: 0.705128 M_global: 0.0303606\n",
      "step: 284000  d-loss: 0.0195713  g-loss: 0.0 k_t: 0.714977 M_global: 0.029357\n",
      "step: 285000  d-loss: 0.0195894  g-loss: 0.0 k_t: 0.724831 M_global: 0.0293841\n",
      "step: 286000  d-loss: 0.019798  g-loss: 0.0 k_t: 0.734677 M_global: 0.029697\n",
      "step: 287000  d-loss: 0.0204863  g-loss: 0.0 k_t: 0.744523 M_global: 0.0307294\n",
      "step: 288000  d-loss: 0.01983  g-loss: 0.0 k_t: 0.754372 M_global: 0.0297449\n",
      "step: 289000  d-loss: 0.0196415  g-loss: 0.0 k_t: 0.764219 M_global: 0.0294622\n",
      "step: 290000  d-loss: 0.0192673  g-loss: 0.0 k_t: 0.774063 M_global: 0.028901\n",
      "step: 291000  d-loss: 0.0197685  g-loss: 0.0 k_t: 0.783899 M_global: 0.0296528\n",
      "step: 292000  d-loss: 0.0192967  g-loss: 0.0 k_t: 0.793739 M_global: 0.0289451\n",
      "step: 293000  d-loss: 0.01941  g-loss: 0.0 k_t: 0.803576 M_global: 0.029115\n",
      "step: 294000  d-loss: 0.0198779  g-loss: 0.0 k_t: 0.813412 M_global: 0.0298168\n",
      "step: 295000  d-loss: 0.0197388  g-loss: 0.0 k_t: 0.823245 M_global: 0.0296083\n",
      "step: 296000  d-loss: 0.0194368  g-loss: 0.0 k_t: 0.833076 M_global: 0.0291551\n",
      "step: 297000  d-loss: 0.0187924  g-loss: 0.0 k_t: 0.842908 M_global: 0.0281886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 298000  d-loss: 0.0204914  g-loss: 0.0 k_t: 0.852738 M_global: 0.0307371\n",
      "step: 299000  d-loss: 0.0195299  g-loss: 0.0 k_t: 0.862561 M_global: 0.0292948\n",
      "step: 300000  d-loss: 0.0198451  g-loss: 0.0 k_t: 0.87239 M_global: 0.0297676\n",
      "step: 301000  d-loss: 0.0189386  g-loss: 0.0 k_t: 0.882214 M_global: 0.0284079\n",
      "step: 302000  d-loss: 0.0206628  g-loss: 0.0 k_t: 0.89204 M_global: 0.0309942\n",
      "step: 303000  d-loss: 0.0198813  g-loss: 0.0 k_t: 0.901864 M_global: 0.0298219\n",
      "step: 304000  d-loss: 0.0198024  g-loss: 0.0 k_t: 0.911686 M_global: 0.0297036\n",
      "step: 305000  d-loss: 0.0197713  g-loss: 0.0 k_t: 0.921508 M_global: 0.029657\n",
      "step: 306000  d-loss: 0.0201381  g-loss: 0.0 k_t: 0.931325 M_global: 0.0302072\n",
      "step: 307000  d-loss: 0.0196522  g-loss: 0.0 k_t: 0.941141 M_global: 0.0294783\n",
      "step: 308000  d-loss: 0.0197748  g-loss: 0.0 k_t: 0.950954 M_global: 0.0296622\n",
      "step: 309000  d-loss: 0.019269  g-loss: 0.0 k_t: 0.960766 M_global: 0.0289035\n",
      "step: 310000  d-loss: 0.0205742  g-loss: 0.0 k_t: 0.970579 M_global: 0.0308614\n",
      "step: 311000  d-loss: 0.0188972  g-loss: 0.0 k_t: 0.980389 M_global: 0.0283458\n",
      "step: 312000  d-loss: 0.0192096  g-loss: 0.0 k_t: 0.990198 M_global: 0.0288145\n",
      "step: 313000  d-loss: 0.0194232  g-loss: 0.0 k_t: 1.00001 M_global: 0.0291348\n",
      "step: 314000  d-loss: 0.0209118  g-loss: 0.0 k_t: 1.00981 M_global: 0.0313677\n",
      "step: 315000  d-loss: 0.0196586  g-loss: 0.0 k_t: 1.01961 M_global: 0.0294879\n",
      "step: 316000  d-loss: 0.0197718  g-loss: 0.0 k_t: 1.0294 M_global: 0.0296577\n",
      "step: 317000  d-loss: 0.0201604  g-loss: 0.0 k_t: 1.03915 M_global: 0.0302406\n",
      "step: 318000  d-loss: 0.0207559  g-loss: 0.0 k_t: 1.04891 M_global: 0.0311338\n",
      "step: 319000  d-loss: 0.0190545  g-loss: 0.0 k_t: 1.05867 M_global: 0.0285817\n",
      "step: 320000  d-loss: 0.0199639  g-loss: 0.0 k_t: 1.06842 M_global: 0.0299458\n",
      "step: 321000  d-loss: 0.0191927  g-loss: 0.0 k_t: 1.07816 M_global: 0.028789\n",
      "step: 322000  d-loss: 0.0189616  g-loss: 0.0 k_t: 1.08791 M_global: 0.0284424\n",
      "step: 323000  d-loss: 0.0197497  g-loss: 0.0 k_t: 1.09765 M_global: 0.0296245\n",
      "step: 324000  d-loss: 0.020014  g-loss: 0.0 k_t: 1.1074 M_global: 0.0300211\n",
      "step: 325000  d-loss: 0.0193236  g-loss: 0.0 k_t: 1.11714 M_global: 0.0289854\n",
      "step: 326000  d-loss: 0.0194477  g-loss: 0.0 k_t: 1.12688 M_global: 0.0291715\n",
      "step: 327000  d-loss: 0.0198947  g-loss: 0.0 k_t: 1.13662 M_global: 0.029842\n",
      "step: 328000  d-loss: 0.0200715  g-loss: 0.0 k_t: 1.14635 M_global: 0.0301073\n",
      "step: 329000  d-loss: 0.0194288  g-loss: 0.0 k_t: 1.15608 M_global: 0.0291432\n",
      "step: 330000  d-loss: 0.0194827  g-loss: 0.0 k_t: 1.16581 M_global: 0.029224\n",
      "step: 331000  d-loss: 0.0199378  g-loss: 0.0 k_t: 1.17554 M_global: 0.0299068\n",
      "step: 332000  d-loss: 0.0188855  g-loss: 0.0 k_t: 1.18527 M_global: 0.0283282\n",
      "step: 333000  d-loss: 0.019431  g-loss: 0.0 k_t: 1.195 M_global: 0.0291465\n",
      "step: 334000  d-loss: 0.0182721  g-loss: 0.0 k_t: 1.20473 M_global: 0.0274082\n",
      "step: 335000  d-loss: 0.0193092  g-loss: 0.0 k_t: 1.21445 M_global: 0.0289637\n",
      "step: 336000  d-loss: 0.0194496  g-loss: 0.0 k_t: 1.22417 M_global: 0.0291743\n",
      "step: 337000  d-loss: 0.0195675  g-loss: 0.0 k_t: 1.2339 M_global: 0.0293512\n",
      "step: 338000  d-loss: 0.0195918  g-loss: 0.0 k_t: 1.24361 M_global: 0.0293877\n",
      "step: 339000  d-loss: 0.0191217  g-loss: 0.0 k_t: 1.25333 M_global: 0.0286826\n",
      "step: 340000  d-loss: 0.0195959  g-loss: 0.0 k_t: 1.26305 M_global: 0.0293939\n",
      "step: 341000  d-loss: 0.0199093  g-loss: 0.0 k_t: 1.27277 M_global: 0.0298639\n",
      "step: 342000  d-loss: 0.0202446  g-loss: 0.0 k_t: 1.28248 M_global: 0.030367\n",
      "step: 343000  d-loss: 0.0193709  g-loss: 0.0 k_t: 1.29219 M_global: 0.0290563\n",
      "step: 344000  d-loss: 0.0193093  g-loss: 0.0 k_t: 1.3019 M_global: 0.028964\n",
      "step: 345000  d-loss: 0.019779  g-loss: 0.0 k_t: 1.31162 M_global: 0.0296684\n",
      "step: 346000  d-loss: 0.0199632  g-loss: 0.0 k_t: 1.32133 M_global: 0.0299447\n",
      "step: 347000  d-loss: 0.0190172  g-loss: 0.0 k_t: 1.33104 M_global: 0.0285258\n",
      "step: 348000  d-loss: 0.0208046  g-loss: 0.0 k_t: 1.34075 M_global: 0.0312069\n",
      "step: 349000  d-loss: 0.0205497  g-loss: 0.0 k_t: 1.35045 M_global: 0.0308246\n",
      "step: 350000  d-loss: 0.0192247  g-loss: 0.0 k_t: 1.36015 M_global: 0.0288371\n",
      "step: 351000  d-loss: 0.0195988  g-loss: 0.0 k_t: 1.36986 M_global: 0.0293982\n",
      "step: 352000  d-loss: 0.0192937  g-loss: 0.0 k_t: 1.37956 M_global: 0.0289406\n",
      "step: 353000  d-loss: 0.019166  g-loss: 0.0 k_t: 1.38926 M_global: 0.028749\n",
      "step: 354000  d-loss: 0.0184002  g-loss: 0.0 k_t: 1.39896 M_global: 0.0276002\n",
      "step: 355000  d-loss: 0.0202131  g-loss: 0.0 k_t: 1.40865 M_global: 0.0303197\n",
      "step: 356000  d-loss: 0.0200175  g-loss: 0.0 k_t: 1.41835 M_global: 0.0300262\n",
      "step: 357000  d-loss: 0.0192236  g-loss: 0.0 k_t: 1.42804 M_global: 0.0288355\n",
      "step: 358000  d-loss: 0.0191288  g-loss: 0.0 k_t: 1.43774 M_global: 0.0286932\n",
      "step: 359000  d-loss: 0.0196612  g-loss: 0.0 k_t: 1.44743 M_global: 0.0294919\n",
      "step: 360000  d-loss: 0.0201616  g-loss: 0.0 k_t: 1.45712 M_global: 0.0302425\n",
      "step: 361000  d-loss: 0.0189307  g-loss: 0.0 k_t: 1.46681 M_global: 0.028396\n",
      "step: 362000  d-loss: 0.0182871  g-loss: 0.0 k_t: 1.47649 M_global: 0.0274306\n",
      "step: 363000  d-loss: 0.0195307  g-loss: 0.0 k_t: 1.48617 M_global: 0.0292961\n",
      "step: 364000  d-loss: 0.0187456  g-loss: 0.0 k_t: 1.49585 M_global: 0.0281183\n",
      "step: 365000  d-loss: 0.0189478  g-loss: 0.0 k_t: 1.50553 M_global: 0.0284217\n",
      "step: 366000  d-loss: 0.0192302  g-loss: 0.0 k_t: 1.51521 M_global: 0.0288454\n",
      "step: 367000  d-loss: 0.0196312  g-loss: 0.0 k_t: 1.52488 M_global: 0.0294469\n",
      "step: 368000  d-loss: 0.0192185  g-loss: 0.0 k_t: 1.53456 M_global: 0.0288278\n",
      "step: 369000  d-loss: 0.0189271  g-loss: 0.0 k_t: 1.54423 M_global: 0.0283906\n",
      "step: 370000  d-loss: 0.0196369  g-loss: 0.0 k_t: 1.55391 M_global: 0.0294553\n",
      "step: 371000  d-loss: 0.0190434  g-loss: 0.0 k_t: 1.56358 M_global: 0.0285652\n",
      "step: 372000  d-loss: 0.0207964  g-loss: 0.0 k_t: 1.57325 M_global: 0.0311946\n",
      "step: 373000  d-loss: 0.0194993  g-loss: 0.0 k_t: 1.58292 M_global: 0.0292489\n",
      "step: 374000  d-loss: 0.0187551  g-loss: 0.0 k_t: 1.59258 M_global: 0.0281327\n",
      "step: 375000  d-loss: 0.0195017  g-loss: 0.0 k_t: 1.60225 M_global: 0.0292525\n",
      "step: 376000  d-loss: 0.019618  g-loss: 0.0 k_t: 1.61192 M_global: 0.0294269\n",
      "step: 377000  d-loss: 0.0185682  g-loss: 0.0 k_t: 1.62158 M_global: 0.0278524\n",
      "step: 378000  d-loss: 0.0193323  g-loss: 0.0 k_t: 1.63124 M_global: 0.0289984\n",
      "step: 379000  d-loss: 0.019108  g-loss: 0.0 k_t: 1.6409 M_global: 0.0286619\n",
      "step: 380000  d-loss: 0.0198845  g-loss: 0.0 k_t: 1.65056 M_global: 0.0298267\n",
      "step: 381000  d-loss: 0.0203854  g-loss: 0.0 k_t: 1.66022 M_global: 0.0305781\n",
      "step: 382000  d-loss: 0.0202305  g-loss: 0.0 k_t: 1.66988 M_global: 0.0303457\n",
      "step: 383000  d-loss: 0.0194774  g-loss: 0.0 k_t: 1.67954 M_global: 0.029216\n",
      "step: 384000  d-loss: 0.0198568  g-loss: 0.0 k_t: 1.68919 M_global: 0.0297853\n",
      "step: 385000  d-loss: 0.018884  g-loss: 0.0 k_t: 1.69884 M_global: 0.028326\n",
      "step: 386000  d-loss: 0.0186324  g-loss: 0.0 k_t: 1.7085 M_global: 0.0279486\n",
      "step: 387000  d-loss: 0.0193571  g-loss: 0.0 k_t: 1.71815 M_global: 0.0290357\n",
      "step: 388000  d-loss: 0.019356  g-loss: 0.0 k_t: 1.7278 M_global: 0.0290341\n",
      "step: 389000  d-loss: 0.0190478  g-loss: 0.0 k_t: 1.73744 M_global: 0.0285717\n",
      "step: 390000  d-loss: 0.0199235  g-loss: 0.0 k_t: 1.74709 M_global: 0.0298852\n",
      "step: 391000  d-loss: 0.0190036  g-loss: 0.0 k_t: 1.75674 M_global: 0.0285053\n",
      "step: 392000  d-loss: 0.0183986  g-loss: 0.0 k_t: 1.76639 M_global: 0.027598\n",
      "step: 393000  d-loss: 0.0194598  g-loss: 0.0 k_t: 1.77603 M_global: 0.0291896\n",
      "step: 394000  d-loss: 0.0188094  g-loss: 0.0 k_t: 1.78568 M_global: 0.028214\n",
      "step: 395000  d-loss: 0.0190571  g-loss: 0.0 k_t: 1.79532 M_global: 0.0285857\n",
      "step: 396000  d-loss: 0.0192807  g-loss: 0.0 k_t: 1.80496 M_global: 0.028921\n",
      "step: 397000  d-loss: 0.019575  g-loss: 0.0 k_t: 1.8146 M_global: 0.0293624\n",
      "step: 398000  d-loss: 0.0185397  g-loss: 0.0 k_t: 1.82424 M_global: 0.0278096\n",
      "step: 399000  d-loss: 0.019579  g-loss: 0.0 k_t: 1.83388 M_global: 0.0293685\n",
      "step: 400000  d-loss: 0.0187146  g-loss: 0.0 k_t: 1.84352 M_global: 0.0280719\n",
      "step: 401000  d-loss: 0.0195405  g-loss: 0.0 k_t: 1.85315 M_global: 0.0293108\n",
      "step: 402000  d-loss: 0.0184598  g-loss: 0.0 k_t: 1.86279 M_global: 0.0276897\n",
      "step: 403000  d-loss: 0.018669  g-loss: 0.0 k_t: 1.87242 M_global: 0.0280035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 404000  d-loss: 0.0184393  g-loss: 0.0 k_t: 1.88205 M_global: 0.027659\n",
      "step: 405000  d-loss: 0.0199749  g-loss: 0.0 k_t: 1.89168 M_global: 0.0299624\n",
      "step: 406000  d-loss: 0.0189409  g-loss: 0.0 k_t: 1.90132 M_global: 0.0284113\n",
      "step: 407000  d-loss: 0.0188396  g-loss: 0.0 k_t: 1.91095 M_global: 0.0282594\n",
      "step: 408000  d-loss: 0.019726  g-loss: 0.0 k_t: 1.92058 M_global: 0.029589\n",
      "step: 409000  d-loss: 0.0196719  g-loss: 0.0 k_t: 1.9302 M_global: 0.0295078\n",
      "step: 410000  d-loss: 0.0191453  g-loss: 0.0 k_t: 1.93983 M_global: 0.028718\n",
      "step: 411000  d-loss: 0.0188853  g-loss: 0.0 k_t: 1.94946 M_global: 0.0283279\n",
      "step: 412000  d-loss: 0.0198223  g-loss: 0.0 k_t: 1.95909 M_global: 0.0297334\n",
      "step: 413000  d-loss: 0.0199538  g-loss: 0.0 k_t: 1.96871 M_global: 0.0299307\n",
      "step: 414000  d-loss: 0.0199298  g-loss: 0.0 k_t: 1.97833 M_global: 0.0298948\n",
      "step: 415000  d-loss: 0.0192819  g-loss: 0.0 k_t: 1.98795 M_global: 0.0289228\n",
      "step: 416000  d-loss: 0.0191513  g-loss: 0.0 k_t: 1.99758 M_global: 0.028727\n",
      "step: 417000  d-loss: 0.0195033  g-loss: 0.0 k_t: 2.0072 M_global: 0.0292549\n",
      "step: 418000  d-loss: 0.0183476  g-loss: 0.0 k_t: 2.01681 M_global: 0.0275214\n",
      "step: 419000  d-loss: 0.0191986  g-loss: 0.0 k_t: 2.02643 M_global: 0.0287978\n",
      "step: 420000  d-loss: 0.0190066  g-loss: 0.0 k_t: 2.03605 M_global: 0.0285099\n",
      "step: 421000  d-loss: 0.0189966  g-loss: 0.0 k_t: 2.04566 M_global: 0.028495\n",
      "step: 422000  d-loss: 0.0189434  g-loss: 0.0 k_t: 2.05528 M_global: 0.0284151\n",
      "step: 423000  d-loss: 0.0196258  g-loss: 0.0 k_t: 2.0649 M_global: 0.0294387\n",
      "step: 424000  d-loss: 0.0195993  g-loss: 0.0 k_t: 2.0745 M_global: 0.029399\n",
      "step: 425000  d-loss: 0.0187046  g-loss: 0.0 k_t: 2.08411 M_global: 0.0280569\n",
      "step: 426000  d-loss: 0.0194614  g-loss: 0.0 k_t: 2.09372 M_global: 0.0291921\n",
      "step: 427000  d-loss: 0.0191903  g-loss: 0.0 k_t: 2.10333 M_global: 0.0287854\n",
      "step: 428000  d-loss: 0.0197286  g-loss: 0.0 k_t: 2.11294 M_global: 0.0295929\n",
      "step: 429000  d-loss: 0.0193061  g-loss: 0.0 k_t: 2.12255 M_global: 0.0289592\n",
      "step: 430000  d-loss: 0.0195898  g-loss: 0.0 k_t: 2.13215 M_global: 0.0293847\n",
      "step: 431000  d-loss: 0.0187785  g-loss: 0.0 k_t: 2.14176 M_global: 0.0281677\n",
      "step: 432000  d-loss: 0.0196091  g-loss: 0.0 k_t: 2.15137 M_global: 0.0294136\n",
      "step: 433000  d-loss: 0.0194389  g-loss: 0.0 k_t: 2.16096 M_global: 0.0291584\n",
      "step: 434000  d-loss: 0.0191152  g-loss: 0.0 k_t: 2.17057 M_global: 0.0286727\n",
      "step: 435000  d-loss: 0.0199587  g-loss: 0.0 k_t: 2.18017 M_global: 0.0299381\n",
      "step: 436000  d-loss: 0.0189005  g-loss: 0.0 k_t: 2.18978 M_global: 0.0283508\n",
      "step: 437000  d-loss: 0.0196883  g-loss: 0.0 k_t: 2.19938 M_global: 0.0295325\n",
      "step: 438000  d-loss: 0.0189285  g-loss: 0.0 k_t: 2.20898 M_global: 0.0283927\n",
      "step: 439000  d-loss: 0.0189024  g-loss: 0.0 k_t: 2.21857 M_global: 0.0283535\n",
      "step: 440000  d-loss: 0.0190849  g-loss: 0.0 k_t: 2.22818 M_global: 0.0286274\n",
      "step: 441000  d-loss: 0.0190168  g-loss: 0.0 k_t: 2.23777 M_global: 0.0285251\n",
      "step: 442000  d-loss: 0.019125  g-loss: 0.0 k_t: 2.24736 M_global: 0.0286875\n",
      "step: 443000  d-loss: 0.0190668  g-loss: 0.0 k_t: 2.25696 M_global: 0.0286002\n",
      "step: 444000  d-loss: 0.0196259  g-loss: 0.0 k_t: 2.26655 M_global: 0.0294388\n",
      "step: 445000  d-loss: 0.0190438  g-loss: 0.0 k_t: 2.27613 M_global: 0.0285657\n",
      "step: 446000  d-loss: 0.0194552  g-loss: 0.0 k_t: 2.28571 M_global: 0.0291828\n",
      "step: 447000  d-loss: 0.0193605  g-loss: 0.0 k_t: 2.29529 M_global: 0.0290408\n",
      "step: 448000  d-loss: 0.0193741  g-loss: 0.0 k_t: 2.30487 M_global: 0.0290611\n",
      "step: 449000  d-loss: 0.019203  g-loss: 0.0 k_t: 2.31445 M_global: 0.0288045\n",
      "step: 450000  d-loss: 0.0188726  g-loss: 0.0 k_t: 2.32402 M_global: 0.0283089\n",
      "step: 451000  d-loss: 0.019078  g-loss: 0.0 k_t: 2.33359 M_global: 0.0286171\n",
      "step: 452000  d-loss: 0.0191939  g-loss: 0.0 k_t: 2.34316 M_global: 0.0287909\n",
      "step: 453000  d-loss: 0.0194042  g-loss: 0.0 k_t: 2.35274 M_global: 0.0291063\n",
      "step: 454000  d-loss: 0.0196853  g-loss: 0.0 k_t: 2.36231 M_global: 0.0295279\n",
      "step: 455000  d-loss: 0.0192332  g-loss: 0.0 k_t: 2.37188 M_global: 0.0288498\n",
      "step: 456000  d-loss: 0.0191273  g-loss: 0.0 k_t: 2.38144 M_global: 0.0286909\n",
      "step: 457000  d-loss: 0.0191931  g-loss: 0.0 k_t: 2.39101 M_global: 0.0287897\n",
      "step: 458000  d-loss: 0.0194323  g-loss: 0.0 k_t: 2.40058 M_global: 0.0291485\n",
      "step: 459000  d-loss: 0.0198308  g-loss: 0.0 k_t: 2.41015 M_global: 0.0297462\n",
      "step: 460000  d-loss: 0.0185614  g-loss: 0.0 k_t: 2.41971 M_global: 0.0278421\n",
      "step: 461000  d-loss: 0.018453  g-loss: 0.0 k_t: 2.42927 M_global: 0.0276794\n",
      "step: 462000  d-loss: 0.0193429  g-loss: 0.0 k_t: 2.43884 M_global: 0.0290143\n",
      "step: 463000  d-loss: 0.0185768  g-loss: 0.0 k_t: 2.4484 M_global: 0.0278651\n",
      "step: 464000  d-loss: 0.0189014  g-loss: 0.0 k_t: 2.45797 M_global: 0.0283521\n",
      "step: 465000  d-loss: 0.0190617  g-loss: 0.0 k_t: 2.46753 M_global: 0.0285926\n",
      "step: 466000  d-loss: 0.018497  g-loss: 0.0 k_t: 2.47709 M_global: 0.0277455\n",
      "step: 467000  d-loss: 0.019888  g-loss: 0.0 k_t: 2.48665 M_global: 0.029832\n",
      "step: 468000  d-loss: 0.019379  g-loss: 0.0 k_t: 2.49621 M_global: 0.0290685\n",
      "step: 469000  d-loss: 0.0187048  g-loss: 0.0 k_t: 2.50577 M_global: 0.0280572\n",
      "step: 470000  d-loss: 0.0195464  g-loss: 0.0 k_t: 2.51532 M_global: 0.0293196\n",
      "step: 471000  d-loss: 0.018312  g-loss: 0.0 k_t: 2.52488 M_global: 0.0274679\n",
      "step: 472000  d-loss: 0.0195913  g-loss: 0.0 k_t: 2.53443 M_global: 0.0293869\n",
      "step: 473000  d-loss: 0.0191263  g-loss: 0.0 k_t: 2.54399 M_global: 0.0286894\n",
      "step: 474000  d-loss: 0.018532  g-loss: 0.0 k_t: 2.55354 M_global: 0.027798\n",
      "step: 475000  d-loss: 0.0184686  g-loss: 0.0 k_t: 2.56308 M_global: 0.0277028\n",
      "step: 476000  d-loss: 0.0185892  g-loss: 0.0 k_t: 2.57263 M_global: 0.0278838\n",
      "step: 477000  d-loss: 0.0194531  g-loss: 0.0 k_t: 2.58217 M_global: 0.0291796\n",
      "step: 478000  d-loss: 0.0186531  g-loss: 0.0 k_t: 2.59171 M_global: 0.0279797\n",
      "step: 479000  d-loss: 0.0189935  g-loss: 0.0 k_t: 2.60125 M_global: 0.0284902\n",
      "step: 480000  d-loss: 0.0190564  g-loss: 0.0 k_t: 2.61079 M_global: 0.0285846\n",
      "step: 481000  d-loss: 0.0191151  g-loss: 0.0 k_t: 2.62032 M_global: 0.0286727\n",
      "step: 482000  d-loss: 0.0183538  g-loss: 0.0 k_t: 2.62986 M_global: 0.0275308\n",
      "step: 483000  d-loss: 0.0186905  g-loss: 0.0 k_t: 2.63939 M_global: 0.0280357\n",
      "step: 484000  d-loss: 0.0190672  g-loss: 0.0 k_t: 2.64892 M_global: 0.0286009\n",
      "step: 485000  d-loss: 0.0191127  g-loss: 0.0 k_t: 2.65846 M_global: 0.0286691\n",
      "step: 486000  d-loss: 0.0184304  g-loss: 0.0 k_t: 2.66799 M_global: 0.0276456\n",
      "step: 487000  d-loss: 0.0196068  g-loss: 0.0 k_t: 2.67752 M_global: 0.0294102\n",
      "step: 488000  d-loss: 0.019385  g-loss: 0.0 k_t: 2.68705 M_global: 0.0290775\n",
      "step: 489000  d-loss: 0.0188646  g-loss: 0.0 k_t: 2.69657 M_global: 0.0282968\n",
      "step: 490000  d-loss: 0.0194549  g-loss: 0.0 k_t: 2.7061 M_global: 0.0291823\n",
      "step: 491000  d-loss: 0.0194247  g-loss: 0.0 k_t: 2.71563 M_global: 0.029137\n",
      "step: 492000  d-loss: 0.0194464  g-loss: 0.0 k_t: 2.72516 M_global: 0.0291696\n",
      "step: 493000  d-loss: 0.0193406  g-loss: 0.0 k_t: 2.73468 M_global: 0.0290109\n",
      "step: 494000  d-loss: 0.0182834  g-loss: 0.0 k_t: 2.74421 M_global: 0.0274251\n",
      "step: 495000  d-loss: 0.0188383  g-loss: 0.0 k_t: 2.75373 M_global: 0.0282574\n",
      "step: 496000  d-loss: 0.0187513  g-loss: 0.0 k_t: 2.76326 M_global: 0.0281269\n",
      "step: 497000  d-loss: 0.018795  g-loss: 0.0 k_t: 2.77278 M_global: 0.0281925\n",
      "step: 498000  d-loss: 0.0184198  g-loss: 0.0 k_t: 2.7823 M_global: 0.0276298\n",
      "step: 499000  d-loss: 0.0188767  g-loss: 0.0 k_t: 2.79182 M_global: 0.028315\n",
      "step: 500000  d-loss: 0.0181081  g-loss: 0.0 k_t: 2.80134 M_global: 0.0271622\n"
     ]
    }
   ],
   "source": [
    "for step in range(500001):\n",
    "    batch_x = mnist.train.next_batch(batch_size)[0]\n",
    "    z_D = sample_Z(batch_size, g_dim)\n",
    "    sess.run([d_optimizer, g_optimizer], feed_dict={x_d: batch_x, x_g: z_D})\n",
    "    z_G = sample_Z(batch_size, g_dim)\n",
    "    sess.run(g_optimizer, feed_dict={x_g: z_G})\n",
    "#     k_t = np.maximum(np.minimum(1., k_t + 0.001*(sess.run(balancer, feed_dict={x_d: batch_x, x_g: z_G}))), 0.)\n",
    "    sess.run(update_k, feed_dict={x_d: batch_x, x_g: z_G})\n",
    "    if step%1000==0:\n",
    "        d_loss_train, g_loss_train, k_tt, M_global_train = sess.run([d_loss, g_loss, k_t, M_global], feed_dict=\n",
    "                            {x_d: batch_x, x_g: sample_Z(batch_size, g_dim)})\n",
    "#         print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_t,\"M_global:\", M_global_train\n",
    "        print 'step:', step, ' d-loss:', d_loss_train, ' g-loss:', g_loss_train, 'k_t:', k_tt,\"M_global:\", M_global_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAD8CAYAAADOg5fGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1b5ac34790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gg = sess.run(g_sample, feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(g_sample), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(decoder(x_g), feed_dict = {x_g: zz})\n",
    "# gg = sess.run(discriminator(x_d), feed_dict = {x_d: x_train})\n",
    "gg_pic = np.array([np.reshape(m,(28,28)) for m in gg])\n",
    "fig, ax = plt.subplots(nrows=3, ncols=3)\n",
    "for i,row in enumerate(ax):\n",
    "    for j,col in enumerate(row):\n",
    "        ax[i][j].imshow(gg_pic[i*3+j], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
