{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "x_train = mnist.train.images\n",
    "y_train = mnist.train.labels\n",
    "x_test = mnist.test.images\n",
    "y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for NN layers\n",
    "class layer:\n",
    "    def __init__(self, inputs, in_size, out_size, activation_function=None):\n",
    "#         self.W = tf.Variable(tf.zeros([in_size, out_size]))\n",
    "        self.W = tf.Variable(tf.random_normal([in_size, out_size]))\n",
    "        self.b = tf.Variable(tf.zeros([1,out_size]))\n",
    "        self.Wx_plus_b = tf.matmul(inputs, self.W) + self.b\n",
    "        self.activation_function = activation_function\n",
    "    def output(self):\n",
    "        if self.activation_function == None:\n",
    "            result = self.Wx_plus_b\n",
    "        else :\n",
    "            result = self.activation_function(self.Wx_plus_b)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for convolution\n",
    "class convolution:\n",
    "    def __init__(self, shape):\n",
    "        self.W = tf.Variable(tf.truncated_normal(shape=shape, stddev=0.1))\n",
    "        self.b = tf.Variable(tf.constant(0.1, shape=[shape[3]]))\n",
    "    def conv2d(self, inputs, padding='SAME'):\n",
    "        return tf.nn.conv2d(inputs, self.W, strides=[1,1,1,1], padding=padding)\n",
    "    def max_pooling_nxn(self, inputs, n):\n",
    "        return tf.nn.max_pool(inputs, ksize=[1,n,n,1], strides=[1,n,n,1], padding='SAME')\n",
    "    def conv_and_pooling(self, inputs, activation_function=None, pooling_size=2):\n",
    "        if activation_function==None:\n",
    "            h_conv =self.conv2d(inputs)+self.b\n",
    "        else:\n",
    "            h_conv = activation_function(self.conv2d(inputs)+self.b)    \n",
    "        return self.max_pooling_nxn(h_conv, pooling_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "#for dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "#dealing eith inputs. \n",
    "# -1 for not considering input number of images\n",
    "# 28,28 size per iamge\n",
    "# 1 for channel. 1 for grayscale ; 3 for color image\n",
    "x_image=tf.reshape(x,[-1,28,28,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#AlexNet => 5 convolution layers & 3 fully connected neural network\n",
    "\n",
    "conv1 = convolution([3,3,1,24])\n",
    "conv2 = convolution([3,3,24,48])\n",
    "conv3 = convolution([3,3,48,144])\n",
    "# conv4 = convolution([3,3,96,192])\n",
    "# conv5 = convolution([3,3,192,192])\n",
    "\n",
    "output_conv1 = conv1.conv_and_pooling(x_image, tf.nn.relu)\n",
    "output_conv2 = conv2.conv_and_pooling(output_conv1, tf.nn.relu)\n",
    "output_conv3 = conv3.conv_and_pooling(output_conv2, tf.nn.relu, pooling_size=2)\n",
    "# output_conv4 = conv4.conv_and_pooling(output_conv3, tf.nn.relu, pooling_size=1)\n",
    "# output_conv5 = conv5.conv_and_pooling(output_conv4, tf.nn.relu, pooling_size=1)\n",
    "\n",
    "# h_pool_flat = tf.reshape(output_conv2, [-1,7*7*40])\n",
    "h_pool_flat = tf.reshape(output_conv3, [-1,4*4*144])\n",
    "\n",
    "# layer1 = layer(h_pool_flat, 7*7*64, 500, tf.nn.relu)\n",
    "# layer1 = layer(h_pool_flat, 7*7*64, 10, tf.nn.softmax)\n",
    "# layer1 = layer(h_pool_flat, 7*7*40, 10, tf.nn.softmax)\n",
    "layer1 = layer(h_pool_flat, 4*4*144, 100, tf.nn.sigmoid)\n",
    "# layer2 = layer(layer1.output(), 400, 100, tf.nn.sigmoid)\n",
    "layer3 = layer(layer1.output(), 100, 10, tf.nn.softmax)\n",
    "# layer2 = layer(layer1.output(), 500, 100, tf.nn.relu)\n",
    "# layer3 = layer(layer2.output(), 100, 10, tf.nn.softmax)\n",
    "\n",
    "# loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=layer1.output()))\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=layer3.output()))\n",
    "# train_step = tf.train.GradientDescentOptimizer(0.3).minimize(loss)\n",
    "# train_step =  tf.train.MomentumOptimizer(0.005 , 0.9).minimize(loss)\n",
    "train_step = tf.train.AdamOptimizer(0.003).minimize(loss)\n",
    "\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(layer3.output(), 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "batch_size = 100\n",
    "batches = x_train.shape[0]//batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start 0\n",
      "epoch: 0 loss: 1.84368 accuracy: 0.610073\n",
      "start 1\n",
      "start 2\n",
      "epoch: 2 loss: 1.6747 accuracy: 0.784782\n",
      "start 3\n",
      "start 4\n",
      "epoch: 4 loss: 1.59326 accuracy: 0.873637\n",
      "start 5\n",
      "start 6\n",
      "epoch: 6 loss: 1.48915 accuracy: 0.975455\n",
      "start 7\n",
      "start 8\n",
      "epoch: 8 loss: 1.48703 accuracy: 0.977382\n",
      "start 9\n",
      "start 10\n",
      "epoch: 10 loss: 1.4909 accuracy: 0.972709\n",
      "start 11\n",
      "start 12\n",
      "epoch: 12 loss: 1.48575 accuracy: 0.977418\n",
      "start 13\n",
      "start 14\n",
      "epoch: 14 loss: 1.4932 accuracy: 0.969928\n",
      "start 15\n",
      "start 16\n",
      "epoch: 16 loss: 1.48647 accuracy: 0.976691\n",
      "start 17\n",
      "start 18\n",
      "epoch: 18 loss: 1.49037 accuracy: 0.972818\n",
      "start 19\n",
      "start 20\n",
      "epoch: 20 loss: 1.48718 accuracy: 0.976073\n",
      "start 21\n",
      "start 22\n",
      "epoch: 22 loss: 1.48819 accuracy: 0.974637\n",
      "start 23\n",
      "start 24\n",
      "epoch: 24 loss: 1.49065 accuracy: 0.973182\n",
      "start 25\n",
      "start 26\n",
      "epoch: 26 loss: 1.52268 accuracy: 0.939109\n",
      "start 27\n",
      "start 28\n",
      "epoch: 28 loss: 1.48568 accuracy: 0.976546\n",
      "start 29\n",
      "start 30\n",
      "epoch: 30 loss: 1.48685 accuracy: 0.975455\n",
      "Test accuracy: 0.9781\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(31):\n",
    "    print \"start \"+str(epoch)\n",
    "    for batch in range(batches):\n",
    "        sess.run(train_step, feed_dict={x: x_train[batch_size*batch:batch_size*(batch+1)], y: y_train[batch_size*batch:batch_size*(batch+1)]})\n",
    "    if epoch%2==0:\n",
    "        print \"epoch: \"+str(epoch)+\" loss: \"+str(sess.run(loss, feed_dict={x: x_train, y: y_train}))+\" accuracy: \"+str(sess.run(accuracy, feed_dict={x: x_train, y: y_train}))\n",
    "print \"Test accuracy: \"+str(sess.run(accuracy, feed_dict={x: x_test, y: y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start 0\n",
      "epoch: 0 loss: 1.49242 accuracy: 0.970764\n",
      "start 1\n",
      "start 2\n",
      "epoch: 2 loss: 1.48951 accuracy: 0.973691\n",
      "start 3\n",
      "start 4\n",
      "epoch: 4 loss: 1.49271 accuracy: 0.970219\n",
      "start 5\n",
      "start 6\n",
      "epoch: 6 loss: 1.49432 accuracy: 0.969509\n",
      "start 7\n",
      "start 8\n",
      "epoch: 8 loss: 1.50694 accuracy: 0.956582\n",
      "start 9\n",
      "start 10\n",
      "epoch: 10 loss: 1.49721 accuracy: 0.965691\n",
      "start 11\n",
      "start 12\n",
      "epoch: 12 loss: 1.49082 accuracy: 0.972109\n",
      "start 13\n",
      "start 14\n",
      "epoch: 14 loss: 1.50147 accuracy: 0.961891\n",
      "start 15\n",
      "start 16\n",
      "epoch: 16 loss: 1.50071 accuracy: 0.961709\n",
      "start 17\n",
      "start 18\n",
      "epoch: 18 loss: 1.49137 accuracy: 0.9712\n",
      "start 19\n",
      "start 20\n",
      "epoch: 20 loss: 1.49353 accuracy: 0.969382\n",
      "start 21\n",
      "start 22\n",
      "epoch: 22 loss: 1.50799 accuracy: 0.956346\n",
      "start 23\n",
      "start 24\n",
      "epoch: 24 loss: 1.49539 accuracy: 0.967746\n",
      "start 25\n",
      "start 26\n",
      "epoch: 26 loss: 1.50548 accuracy: 0.958637\n",
      "start 27\n",
      "start 28\n",
      "epoch: 28 loss: 1.49989 accuracy: 0.963309\n",
      "start 29\n",
      "start 30\n",
      "epoch: 30 loss: 1.52904 accuracy: 0.9358\n",
      "start 31\n",
      "start 32\n",
      "epoch: 32 loss: 1.5015 accuracy: 0.961673\n",
      "start 33\n",
      "start 34\n",
      "epoch: 34 loss: 1.50093 accuracy: 0.962582\n",
      "start 35\n",
      "start 36\n",
      "epoch: 36 loss: 1.49368 accuracy: 0.968455\n",
      "start 37\n",
      "start 38\n",
      "epoch: 38 loss: 1.50217 accuracy: 0.960782\n",
      "start 39\n",
      "start 40\n",
      "epoch: 40 loss: 1.50423 accuracy: 0.957709\n",
      "start 41\n",
      "start 42\n",
      "epoch: 42 loss: 1.49492 accuracy: 0.967455\n",
      "start 43\n",
      "start 44\n",
      "epoch: 44 loss: 1.50848 accuracy: 0.954673\n",
      "start 45\n",
      "start 46\n",
      "epoch: 46 loss: 1.50866 accuracy: 0.954782\n",
      "start 47\n",
      "start 48\n",
      "epoch: 48 loss: 1.49798 accuracy: 0.964491\n",
      "start 49\n",
      "start 50\n",
      "epoch: 50 loss: 1.49107 accuracy: 0.970909\n",
      "Test accuracy: 0.9751\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(51):\n",
    "    print \"start \"+str(epoch)\n",
    "    for batch in range(batches):\n",
    "        sess.run(train_step, feed_dict={x: x_train[batch_size*batch:batch_size*(batch+1)], y: y_train[batch_size*batch:batch_size*(batch+1)]})\n",
    "    if epoch%2==0:\n",
    "        print \"epoch: \"+str(epoch)+\" loss: \"+str(sess.run(loss, feed_dict={x: x_train, y: y_train}))+\" accuracy: \"+str(sess.run(accuracy, feed_dict={x: x_train, y: y_train}))\n",
    "print \"Test accuracy: \"+str(sess.run(accuracy, feed_dict={x: x_test, y: y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
